/**
 * æ±ç”¨AIå‡¦ç†ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ v1.0
 * 
 * ğŸ¯ ç”¨é€”: ã‚ã‚‰ã‚†ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã§AIå‡¦ç†ã‚’åŠ¹ç‡çš„ã«å®Ÿè£…
 * âœ… Ollamaå¯¾å¿œ
 * âœ… Claude APIå¯¾å¿œ  
 * âœ… å‡¦ç†æ™‚é–“æœ€é©åŒ–
 * âœ… ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
 */

class UniversalAIProcessor {
    constructor(config = {}) {
        this.config = {
            // AI ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®š
            provider: config.provider || 'ollama', // 'ollama' | 'claude' | 'openai'
            
            // Ollamaè¨­å®š
            ollamaUrl: config.ollamaUrl || 'http://localhost:11434',
            ollamaModel: config.ollamaModel || 'phi3:mini', // è»½é‡ãƒ¢ãƒ‡ãƒ«
            
            // Claude APIè¨­å®š
            claudeApiKey: config.claudeApiKey || process.env.CLAUDE_API_KEY,
            claudeModel: config.claudeModel || 'claude-3-haiku-20240307', // æœ€é«˜é€Ÿ
            
            // å‡¦ç†è¨­å®š
            timeout: config.timeout || 30000,
            retryCount: config.retryCount || 3,
            batchSize: config.batchSize || 10,
            
            // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®š
            enableCache: config.enableCache !== false,
            enableBatch: config.enableBatch !== false,
            enableFallback: config.enableFallback !== false
        };
        
        this.cache = new Map();
        this.stats = {
            totalRequests: 0,
            successCount: 0,
            errorCount: 0,
            cacheHits: 0,
            avgResponseTime: 0
        };
    }
    
    /**
     * ğŸš€ ãƒ¡ã‚¤ãƒ³å‡¦ç†é–¢æ•° - ã‚ã‚‰ã‚†ã‚‹AIå‡¦ç†ã«å¯¾å¿œ
     */
    async processWithAI(data, processingType, options = {}) {
        const startTime = Date.now();
        
        try {
            // ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’çµ±ä¸€
            const normalizedData = this.normalizeInput(data);
            
            // å‡¦ç†ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
            const prompt = this.generatePrompt(normalizedData, processingType, options);
            
            // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
            if (this.config.enableCache) {
                const cached = this.getCachedResult(prompt);
                if (cached) {
                    this.stats.cacheHits++;
                    return cached;
                }
            }
            
            // AIå‡¦ç†å®Ÿè¡Œ
            const result = await this.executeAIProcessing(prompt, options);
            
            // çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
            if (this.config.enableCache && result.success) {
                this.setCachedResult(prompt, result);
            }
            
            // çµ±è¨ˆæ›´æ–°
            this.updateStats(Date.now() - startTime, true);
            
            return result;
            
        } catch (error) {
            this.updateStats(Date.now() - startTime, false);
            
            // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
            if (this.config.enableFallback) {
                return this.fallbackProcessing(data, processingType, options);
            }
            
            throw error;
        }
    }
    
    /**
     * ğŸ“Š ãƒãƒƒãƒå‡¦ç†ï¼ˆå¤§é‡ãƒ‡ãƒ¼ã‚¿å¯¾å¿œï¼‰
     */
    async processBatch(dataArray, processingType, options = {}) {
        if (!this.config.enableBatch || dataArray.length <= this.config.batchSize) {
            // å°é‡ãƒ‡ãƒ¼ã‚¿ã¯å€‹åˆ¥å‡¦ç†
            const results = [];
            for (const item of dataArray) {
                const result = await this.processWithAI(item, processingType, options);
                results.push(result);
                
                // CPUè² è·è»½æ¸›
                if (results.length % 10 === 0) {
                    await this.sleep(100);
                }
            }
            return results;
        }
        
        // å¤§é‡ãƒ‡ãƒ¼ã‚¿ã¯ãƒãƒ£ãƒ³ã‚¯å‡¦ç†
        const chunks = this.createChunks(dataArray, this.config.batchSize);
        const allResults = [];
        
        for (let i = 0; i < chunks.length; i++) {
            console.log(`ğŸ”„ ãƒãƒƒãƒå‡¦ç† ${i + 1}/${chunks.length}`);
            
            const chunkResults = await Promise.allSettled(
                chunks[i].map(item => this.processWithAI(item, processingType, options))
            );
            
            const successResults = chunkResults
                .filter(result => result.status === 'fulfilled')
                .map(result => result.value);
                
            allResults.push(...successResults);
            
            // ãƒãƒ£ãƒ³ã‚¯é–“ã§ä¼‘æ†©
            if (i < chunks.length - 1) {
                await this.sleep(1000);
            }
        }
        
        return allResults;
    }
    
    /**
     * ğŸ¯ å‡¦ç†ã‚¿ã‚¤ãƒ—åˆ¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
     */
    generatePrompt(data, processingType, options) {
        const prompts = {
            // å•†å“é–¢é€£
            'product_title_optimize': `å•†å“ã‚¿ã‚¤ãƒˆãƒ«ã‚’æœ€é©åŒ–ã—ã¦ãã ã•ã„: "${data.title}"`,
            'product_description': `å•†å“èª¬æ˜ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚å•†å“å: "${data.title}", ã‚«ãƒ†ã‚´ãƒª: "${data.category}"`,
            'product_seo_keywords': `SEOã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’5å€‹ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚å•†å“: "${data.title}"`,
            
            // ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†
            'text_summarize': `ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¦ç´„ã—ã¦ãã ã•ã„: "${data.text}"`,
            'text_translate': `ä»¥ä¸‹ã‚’${options.targetLang || 'è‹±èª'}ã«ç¿»è¨³ã—ã¦ãã ã•ã„: "${data.text}"`,
            'text_improve': `ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ”¹å–„ã—ã¦ãã ã•ã„: "${data.text}"`,
            
            // ãƒ‡ãƒ¼ã‚¿åˆ†æ
            'data_analysis': `ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã¦ãã ã•ã„: ${JSON.stringify(data)}`,
            'category_classify': `ä»¥ä¸‹ã®ã‚¢ã‚¤ãƒ†ãƒ ã®ã‚«ãƒ†ã‚´ãƒªã‚’åˆ¤å®šã—ã¦ãã ã•ã„: "${data.item}"`,
            'sentiment_analysis': `ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã®æ„Ÿæƒ…åˆ†æã‚’ã—ã¦ãã ã•ã„: "${data.text}"`,
            
            // ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ
            'content_generate': `${options.contentType || 'ãƒ–ãƒ­ã‚°è¨˜äº‹'}ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚ãƒ†ãƒ¼ãƒ: "${data.theme}"`,
            'email_compose': `${options.emailType || 'ãƒ“ã‚¸ãƒã‚¹'}ãƒ¡ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚ä»¶å: "${data.subject}"`,
            
            // æ±ç”¨å‡¦ç†
            'custom': options.customPrompt || data.prompt || 'å‡¦ç†ã—ã¦ãã ã•ã„'
        };
        
        return prompts[processingType] || prompts.custom;
    }
    
    /**
     * ğŸ¤– AIå‡¦ç†å®Ÿè¡Œï¼ˆãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆ¥ï¼‰
     */
    async executeAIProcessing(prompt, options) {
        switch (this.config.provider) {
            case 'ollama':
                return await this.processWithOllama(prompt, options);
            case 'claude':
                return await this.processWithClaude(prompt, options);
            case 'openai':
                return await this.processWithOpenAI(prompt, options);
            default:
                throw new Error(`Unsupported AI provider: ${this.config.provider}`);
        }
    }
    
    /**
     * ğŸ¦™ Ollamaå‡¦ç†
     */
    async processWithOllama(prompt, options) {
        const payload = {
            model: this.config.ollamaModel,
            prompt: prompt,
            stream: false,
            options: {
                temperature: options.temperature || 0.3,
                num_ctx: options.contextLength || 2048,
                num_predict: options.maxTokens || 200,
                top_p: options.topP || 0.9
            }
        };
        
        const response = await this.fetchWithTimeout(
            `${this.config.ollamaUrl}/api/generate`,
            {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            }
        );
        
        if (!response.ok) {
            throw new Error(`Ollama API Error: ${response.status}`);
        }
        
        const result = await response.json();
        
        return {
            success: true,
            result: result.response,
            provider: 'ollama',
            model: this.config.ollamaModel,
            tokens: result.eval_count || 0
        };
    }
    
    /**
     * ğŸ¤– Claude APIå‡¦ç†
     */
    async processWithClaude(prompt, options) {
        if (!this.config.claudeApiKey) {
            throw new Error('Claude API key not configured');
        }
        
        const payload = {
            model: this.config.claudeModel,
            max_tokens: options.maxTokens || 1000,
            messages: [{ role: 'user', content: prompt }],
            temperature: options.temperature || 0.3
        };
        
        const response = await this.fetchWithTimeout(
            'https://api.anthropic.com/v1/messages',
            {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'x-api-key': this.config.claudeApiKey,
                    'anthropic-version': '2023-06-01'
                },
                body: JSON.stringify(payload)
            }
        );
        
        if (!response.ok) {
            throw new Error(`Claude API Error: ${response.status}`);
        }
        
        const result = await response.json();
        
        return {
            success: true,
            result: result.content[0].text,
            provider: 'claude',
            model: this.config.claudeModel,
            tokens: result.usage?.total_tokens || 0
        };
    }
    
    /**
     * ğŸ›¡ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
     */
    fallbackProcessing(data, processingType, options) {
        const fallbackResults = {
            'product_title_optimize': data.title || data,
            'text_summarize': data.text?.substring(0, 100) + '...' || data,
            'category_classify': 'General',
            'sentiment_analysis': 'Neutral'
        };
        
        return {
            success: true,
            result: fallbackResults[processingType] || data,
            provider: 'fallback',
            fallback: true
        };
    }
    
    // ========================================
    // ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
    // ========================================
    
    normalizeInput(data) {
        if (typeof data === 'string') {
            return { text: data };
        }
        return data;
    }
    
    async fetchWithTimeout(url, options) {
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), this.config.timeout);
        
        try {
            const response = await fetch(url, {
                ...options,
                signal: controller.signal
            });
            clearTimeout(timeoutId);
            return response;
        } catch (error) {
            clearTimeout(timeoutId);
            throw error;
        }
    }
    
    createChunks(array, size) {
        const chunks = [];
        for (let i = 0; i < array.length; i += size) {
            chunks.push(array.slice(i, i + size));
        }
        return chunks;
    }
    
    sleep(ms) {
        return new Promise(resolve => setTimeout(resolve, ms));
    }
    
    getCachedResult(key) {
        return this.cache.get(key);
    }
    
    setCachedResult(key, value) {
        // LRUã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        if (this.cache.size >= 1000) {
            const firstKey = this.cache.keys().next().value;
            this.cache.delete(firstKey);
        }
        this.cache.set(key, value);
    }
    
    updateStats(responseTime, success) {
        this.stats.totalRequests++;
        if (success) {
            this.stats.successCount++;
        } else {
            this.stats.errorCount++;
        }
        
        // ç§»å‹•å¹³å‡ã§å¿œç­”æ™‚é–“ã‚’æ›´æ–°
        this.stats.avgResponseTime = 
            (this.stats.avgResponseTime * (this.stats.totalRequests - 1) + responseTime) / 
            this.stats.totalRequests;
    }
    
    getStats() {
        return {
            ...this.stats,
            successRate: (this.stats.successCount / this.stats.totalRequests * 100).toFixed(1) + '%',
            cacheHitRate: (this.stats.cacheHits / this.stats.totalRequests * 100).toFixed(1) + '%'
        };
    }
}

// ä½¿ç”¨ä¾‹ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
if (typeof module !== 'undefined' && module.exports) {
    module.exports = UniversalAIProcessor;
}

if (typeof window !== 'undefined') {
    window.UniversalAIProcessor = UniversalAIProcessor;
}