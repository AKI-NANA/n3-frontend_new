#!/usr/bin/env python3
"""
âœ… å“è³ªä¿è¨¼Hooks
Universal Hooks - ã‚³ãƒ¼ãƒ‰å“è³ªãƒ»ãƒ†ã‚¹ãƒˆãƒ»æ¨™æº–æº–æ‹ ç¢ºèª

ãƒ•ã‚¡ã‚¤ãƒ«: ~/.claude/hooks/universal/quality_assurance.py
"""

import os
import re
import json
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime

class QualityAssuranceHooks:
    """å“è³ªä¿è¨¼Hooks"""
    
    def __init__(self, project_path: str = "."):
        self.project_path = Path(project_path).resolve()
        self.hooks_name = "Quality Assurance"
        self.auto_answers = self.load_auto_answers()
        
    def load_auto_answers(self) -> Dict:
        """è‡ªå‹•å›ç­”ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿"""
        try:
            answers_path = Path("~/.claude/database/auto_answers.json").expanduser()
            if answers_path.exists():
                with open(answers_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except:
            pass
        return {}
    
    def execute_hooks(self, project_analysis: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """å“è³ªä¿è¨¼ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
        
        print(f"âœ… {self.hooks_name} å®Ÿè¡Œä¸­...")
        
        result = {
            "timestamp": datetime.now().isoformat(),
            "hooks_name": self.hooks_name,
            "project_path": str(self.project_path),
            "project_type": project_analysis.get("project_type", {}).get("primary_type", "unknown") if project_analysis else "unknown",
            "quality_checks": {},
            "issues_found": [],
            "recommendations": [],
            "auto_answers_applied": [],
            "questions_for_human": [],
            "overall_score": 0
        }
        
        try:
            # å“è³ªãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
            quality_checks = {
                "coding_standards": self._check_coding_standards(),
                "documentation": self._check_documentation(),
                "testing_framework": self._check_testing_framework(),
                "error_handling": self._check_error_handling(),
                "performance": self._check_performance(),
                "maintainability": self._check_maintainability(),
                "code_organization": self._check_code_organization(),
                "best_practices": self._check_best_practices()
            }
            
            result["quality_checks"] = quality_checks
            result["overall_score"] = self._calculate_quality_score(quality_checks)
            
            # å•é¡Œç‚¹ãƒ»æ¨å¥¨äº‹é …ç”Ÿæˆ
            result["issues_found"] = self._collect_quality_issues(quality_checks)
            result["recommendations"] = self._generate_quality_recommendations(quality_checks)
            
            # è‡ªå‹•å›ç­”é©ç”¨
            result["auto_answers_applied"] = self.apply_auto_answers(result["project_type"])
            
            # äººé–“ã¸ã®è³ªå•ç”Ÿæˆ
            result["questions_for_human"] = self._generate_human_questions(quality_checks, result["project_type"])
            
            print(f"âœ… {self.hooks_name} å®Œäº† - ã‚¹ã‚³ã‚¢: {result['overall_score']}/100")
            return result
            
        except Exception as e:
            result["error"] = str(e)
            result["overall_score"] = 0
            print(f"âŒ {self.hooks_name} ã‚¨ãƒ©ãƒ¼: {e}")
            return result
    
    def _check_coding_standards(self) -> Dict[str, Any]:
        """ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„ãƒã‚§ãƒƒã‚¯"""
        
        standards_compliance = []
        issues = []
        php_files = list(self.project_path.rglob("*.php"))
        js_files = list(self.project_path.rglob("*.js"))
        
        # PHP ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„ãƒã‚§ãƒƒã‚¯
        for php_file in php_files[:10]:  # æœ€åˆã®10ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚µãƒ³ãƒ—ãƒ«
            try:
                content = php_file.read_text(encoding='utf-8')
                
                # PSRæº–æ‹ ãƒã‚§ãƒƒã‚¯
                if re.search(r'<\?php\s*\n', content):
                    standards_compliance.append("PHP opening tag (PSR-1)")
                
                # å‘½åè¦å‰‡ãƒã‚§ãƒƒã‚¯
                if re.search(r'class\s+[A-Z][A-Za-z0-9]*', content):
                    standards_compliance.append("Class naming (PascalCase)")
                
                if re.search(r'function\s+[a-z][A-Za-z0-9]*', content):
                    standards_compliance.append("Function naming (camelCase)")
                
                # ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆãƒã‚§ãƒƒã‚¯ï¼ˆ4ã‚¹ãƒšãƒ¼ã‚¹æ¨å¥¨ï¼‰
                lines = content.split('\n')
                inconsistent_indent = False
                for line in lines:
                    if line.startswith(' '):
                        if not (len(line) - len(line.lstrip())) % 4 == 0:
                            inconsistent_indent = True
                            break
                
                if inconsistent_indent:
                    issues.append(f"Inconsistent indentation: {php_file.name}")
                
                # é•·ã„è¡Œã®ãƒã‚§ãƒƒã‚¯ï¼ˆ120æ–‡å­—åˆ¶é™ï¼‰
                long_lines = [i+1 for i, line in enumerate(lines) if len(line) > 120]
                if long_lines:
                    issues.append(f"Long lines (>120 chars): {php_file.name}")
                
            except:
                continue
        
        # JavaScript ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„ãƒã‚§ãƒƒã‚¯
        for js_file in js_files[:5]:  # æœ€åˆã®5ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚µãƒ³ãƒ—ãƒ«
            try:
                content = js_file.read_text(encoding='utf-8')
                
                # ES6+ æ©Ÿèƒ½ã®ä½¿ç”¨
                if 'const ' in content or 'let ' in content:
                    standards_compliance.append("Modern JavaScript (ES6+)")
                
                # ã‚»ãƒŸã‚³ãƒ­ãƒ³ã®ä½¿ç”¨
                semicolon_lines = len([line for line in content.split('\n') 
                                     if line.strip().endswith(';') and 
                                     not line.strip().startswith('//')])
                total_statements = len([line for line in content.split('\n') 
                                      if line.strip() and 
                                      not line.strip().startswith('//') and
                                      not line.strip().startswith('/*')])
                
                if total_statements > 0 and semicolon_lines / total_statements > 0.8:
                    standards_compliance.append("Consistent semicolon usage")
                
            except:
                continue
        
        # ã‚³ãƒ¼ãƒ‰æ•´å½¢ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨ç¢ºèª
        formatter_configs = []
        for config_file in [".prettierrc", ".eslintrc", "phpcs.xml", ".php_cs"]:
            if (self.project_path / config_file).exists():
                formatter_configs.append(config_file)
        
        if formatter_configs:
            standards_compliance.append(f"Code formatting tools: {', '.join(formatter_configs)}")
        
        compliance_score = len(set(standards_compliance))
        issues_count = len(issues)
        
        status = "pass" if compliance_score >= 4 and issues_count <= 2 else "warning" if compliance_score >= 2 else "fail"
        
        return {
            "status": status,
            "compliance": list(set(standards_compliance)),
            "issues": issues,
            "formatter_configs": formatter_configs,
            "score": f"{compliance_score}/6",
            "message": f"ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„: {status}"
        }
    
    def _check_documentation(self) -> Dict[str, Any]:
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå“è³ªãƒã‚§ãƒƒã‚¯"""
        
        documentation_files = []
        inline_docs = []
        api_docs = []
        
        # READMEãƒ•ã‚¡ã‚¤ãƒ«
        readme_files = list(self.project_path.rglob("README*"))
        documentation_files.extend([str(f) for f in readme_files])
        
        # ãã®ä»–ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
        doc_patterns = ["*.md", "docs/*", "doc/*", "documentation/*"]
        for pattern in doc_patterns:
            doc_files = list(self.project_path.rglob(pattern))
            documentation_files.extend([str(f) for f in doc_files if f not in readme_files])
        
        # ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆPHPDocã€JSDocï¼‰
        code_files = list(self.project_path.rglob("*.php")) + list(self.project_path.rglob("*.js"))
        
        for code_file in code_files[:10]:  # ã‚µãƒ³ãƒ—ãƒ«
            try:
                content = code_file.read_text(encoding='utf-8')
                
                # PHPDoc
                if re.search(r'/\*\*.*@param.*\*/', content, re.DOTALL):
                    inline_docs.append(f"PHPDoc: {code_file.name}")
                
                # JSDoc
                if re.search(r'/\*\*.*@param.*\*/', content, re.DOTALL) and code_file.suffix == '.js':
                    inline_docs.append(f"JSDoc: {code_file.name}")
                
                # ã‚³ãƒ¡ãƒ³ãƒˆç‡
                comment_lines = len(re.findall(r'^\s*(/\*|\*|//)', content, re.MULTILINE))
                total_lines = len(content.split('\n'))
                
                if total_lines > 0 and comment_lines / total_lines > 0.1:
                    inline_docs.append(f"Good comment ratio: {code_file.name}")
                
            except:
                continue
        
        # API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
        api_doc_files = list(self.project_path.rglob("*api*")) + list(self.project_path.rglob("*swagger*"))
        api_docs.extend([str(f) for f in api_doc_files if f.suffix in ['.md', '.yml', '.yaml', '.json']])
        
        doc_score = len(documentation_files) + len(set(inline_docs)) + len(api_docs)
        status = "pass" if doc_score >= 5 else "warning" if doc_score >= 2 else "fail"
        
        return {
            "status": status,
            "documentation_files": list(set(documentation_files)),
            "inline_docs": list(set(inline_docs)),
            "api_docs": api_docs,
            "score": f"{doc_score}/10",
            "message": f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: {status}"
        }
    
    def _check_testing_framework(self) -> Dict[str, Any]:
        """ãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãƒã‚§ãƒƒã‚¯"""
        
        test_frameworks = []
        test_files = []
        test_configs = []
        
        # PHPãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
        if (self.project_path / "phpunit.xml").exists():
            test_frameworks.append("PHPUnit")
            test_configs.append("phpunit.xml")
        
        # JavaScriptãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
        package_json = self.project_path / "package.json"
        if package_json.exists():
            try:
                content = package_json.read_text(encoding='utf-8')
                js_test_frameworks = ['jest', 'mocha', 'jasmine', 'cypress', 'playwright']
                for framework in js_test_frameworks:
                    if framework in content.lower():
                        test_frameworks.append(framework.title())
            except:
                pass
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        test_dirs = ["tests", "test", "__tests__", "spec"]
        for test_dir in test_dirs:
            test_path = self.project_path / test_dir
            if test_path.exists() and test_path.is_dir():
                test_files.extend([str(f) for f in test_path.rglob("*.php")])
                test_files.extend([str(f) for f in test_path.rglob("*.js")])
        
        # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³
        test_patterns = ["*Test.php", "*test.js", "*.test.js", "*.spec.js"]
        for pattern in test_patterns:
            test_files.extend([str(f) for f in self.project_path.rglob(pattern)])
        
        test_files = list(set(test_files))
        
        # ã‚«ãƒãƒ¬ãƒƒã‚¸è¨­å®š
        coverage_configs = []
        if (self.project_path / ".coveralls.yml").exists():
            coverage_configs.append("Coveralls")
        if (self.project_path / "codecov.yml").exists():
            coverage_configs.append("Codecov")
        
        framework_count = len(test_frameworks)
        test_file_count = len(test_files)
        
        status = "pass" if framework_count >= 1 and test_file_count >= 3 else "warning" if framework_count >= 1 or test_file_count >= 1 else "fail"
        
        return {
            "status": status,
            "frameworks": test_frameworks,
            "test_files": test_files,
            "test_configs": test_configs,
            "coverage_configs": coverage_configs,
            "test_file_count": test_file_count,
            "message": f"ãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯: {status}"
        }
    
    def _check_error_handling(self) -> Dict[str, Any]:
        """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒã‚§ãƒƒã‚¯"""
        
        error_handling = []
        exception_patterns = []
        
        php_files = list(self.project_path.rglob("*.php"))
        js_files = list(self.project_path.rglob("*.js"))
        
        # PHP ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
        for php_file in php_files[:10]:
            try:
                content = php_file.read_text(encoding='utf-8')
                
                # try-catch ã®ä½¿ç”¨
                if re.search(r'try\s*{.*catch\s*\(', content, re.DOTALL):
                    error_handling.append(f"Try-catch: {php_file.name}")
                
                # ã‚«ã‚¹ã‚¿ãƒ ä¾‹å¤–
                if re.search(r'class\s+\w*Exception\s+extends', content):
                    exception_patterns.append(f"Custom exceptions: {php_file.name}")
                
                # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
                if 'error_log(' in content:
                    error_handling.append(f"Error logging: {php_file.name}")
                
                # ä¾‹å¤–ã®å†ã‚¹ãƒ­ãƒ¼
                if 'throw new' in content:
                    exception_patterns.append(f"Exception throwing: {php_file.name}")
                
            except:
                continue
        
        # JavaScript ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
        for js_file in js_files[:5]:
            try:
                content = js_file.read_text(encoding='utf-8')
                
                # try-catch
                if re.search(r'try\s*{.*catch\s*\(', content, re.DOTALL):
                    error_handling.append(f"JS Try-catch: {js_file.name}")
                
                # Promise error handling
                if '.catch(' in content:
                    error_handling.append(f"Promise error handling: {js_file.name}")
                
                # Console error
                if 'console.error' in content:
                    error_handling.append(f"Console error logging: {js_file.name}")
                
            except:
                continue
        
        error_handling = list(set(error_handling))
        exception_patterns = list(set(exception_patterns))
        
        handling_score = len(error_handling) + len(exception_patterns)
        status = "pass" if handling_score >= 4 else "warning" if handling_score >= 2 else "fail"
        
        return {
            "status": status,
            "error_handling": error_handling,
            "exception_patterns": exception_patterns,
            "score": f"{handling_score}/8",
            "message": f"ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°: {status}"
        }
    
    def _check_performance(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯"""
        
        performance_practices = []
        potential_issues = []
        
        php_files = list(self.project_path.rglob("*.php"))
        js_files = list(self.project_path.rglob("*.js"))
        
        # PHP ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        for php_file in php_files[:10]:
            try:
                content = php_file.read_text(encoding='utf-8')
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªæœ€é©åŒ–
                if 'prepare(' in content:
                    performance_practices.append("Prepared statements")
                
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ä½¿ç”¨
                cache_patterns = ['cache', 'redis', 'memcache', 'apc']
                for pattern in cache_patterns:
                    if pattern.lower() in content.lower():
                        performance_practices.append(f"Caching: {pattern}")
                        break
                
                # æ½œåœ¨çš„ãªå•é¡Œ
                if re.search(r'SELECT\s+\*\s+FROM', content, re.IGNORECASE):
                    potential_issues.append(f"SELECT * usage: {php_file.name}")
                
                # ãƒ«ãƒ¼ãƒ—å†…ã‚¯ã‚¨ãƒªï¼ˆN+1å•é¡Œï¼‰
                if re.search(r'for.*{.*query.*}', content, re.DOTALL | re.IGNORECASE):
                    potential_issues.append(f"Potential N+1 queries: {php_file.name}")
                
            except:
                continue
        
        # JavaScript ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        for js_file in js_files[:5]:
            try:
                content = js_file.read_text(encoding='utf-8')
                
                # éåŒæœŸå‡¦ç†
                if 'async' in content or 'await' in content:
                    performance_practices.append("Async/await usage")
                
                # DOM ã‚¯ã‚¨ãƒªæœ€é©åŒ–
                if 'getElementById' in content or 'querySelector' in content:
                    performance_practices.append("Efficient DOM queries")
                
                # æ½œåœ¨çš„ãªå•é¡Œ
                if 'document.write' in content:
                    potential_issues.append(f"document.write usage: {js_file.name}")
                
            except:
                continue
        
        performance_practices = list(set(performance_practices))
        
        perf_score = len(performance_practices)
        issues_count = len(potential_issues)
        
        status = "pass" if perf_score >= 3 and issues_count <= 1 else "warning" if perf_score >= 1 else "fail"
        
        return {
            "status": status,
            "practices": performance_practices,
            "potential_issues": potential_issues,
            "score": f"{perf_score}/6",
            "message": f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹: {status}"
        }
    
    def _check_maintainability(self) -> Dict[str, Any]:
        """ä¿å®ˆæ€§ãƒã‚§ãƒƒã‚¯"""
        
        maintainability_factors = []
        complexity_issues = []
        
        php_files = list(self.project_path.rglob("*.php"))
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
        large_files = []
        for php_file in php_files:
            try:
                content = php_file.read_text(encoding='utf-8')
                lines = len(content.split('\n'))
                
                if lines > 500:
                    large_files.append(f"{php_file.name} ({lines} lines)")
                elif lines < 200:
                    maintainability_factors.append(f"Manageable file size: {php_file.name}")
                
                # é–¢æ•°ã®è¤‡é›‘åº¦ï¼ˆç°¡æ˜“ãƒã‚§ãƒƒã‚¯ï¼‰
                functions = re.findall(r'function\s+(\w+)', content)
                for func in functions:
                    func_content = content[content.find(f'function {func}'):]
                    if func_content.find('function ') != -1:
                        next_func = func_content.find('function ', 1)
                        if next_func != -1:
                            func_content = func_content[:next_func]
                    
                    # åˆ†å²ã®æ•°ï¼ˆif, for, while, switchï¼‰
                    branches = len(re.findall(r'\b(if|for|while|switch)\b', func_content))
                    if branches > 10:
                        complexity_issues.append(f"Complex function {func}: {branches} branches")
                
            except:
                continue
        
        if large_files:
            complexity_issues.extend(large_files)
        
        # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹é€ 
        has_modules = False
        module_dirs = ['src', 'lib', 'classes', 'modules', 'components']
        for module_dir in module_dirs:
            if (self.project_path / module_dir).exists():
                has_modules = True
                maintainability_factors.append(f"Modular structure: {module_dir}")
        
        # è¨­å®šã®åˆ†é›¢
        config_separation = []
        config_files = list(self.project_path.rglob("*config*"))
        if config_files:
            config_separation.append("Configuration separation")
            maintainability_factors.append("Config files present")
        
        maintainability_score = len(maintainability_factors)
        complexity_score = len(complexity_issues)
        
        status = "pass" if maintainability_score >= 3 and complexity_score <= 2 else "warning" if maintainability_score >= 2 else "fail"
        
        return {
            "status": status,
            "factors": maintainability_factors,
            "complexity_issues": complexity_issues,
            "has_modules": has_modules,
            "score": f"{maintainability_score}/6",
            "message": f"ä¿å®ˆæ€§: {status}"
        }
    
    def _check_code_organization(self) -> Dict[str, Any]:
        """ã‚³ãƒ¼ãƒ‰çµ„ç¹”åŒ–ãƒã‚§ãƒƒã‚¯"""
        
        organization_patterns = []
        structure_score = 0
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã®ç¢ºèª
        common_dirs = [
            ('src', 'ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰'),
            ('lib', 'ãƒ©ã‚¤ãƒ–ãƒ©ãƒª'),
            ('config', 'è¨­å®š'),
            ('public', 'å…¬é–‹ãƒ•ã‚¡ã‚¤ãƒ«'),
            ('assets', 'ã‚¢ã‚»ãƒƒãƒˆ'),
            ('vendor', 'å¤–éƒ¨ä¾å­˜é–¢ä¿‚'),
            ('tests', 'ãƒ†ã‚¹ãƒˆ'),
            ('docs', 'ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ')
        ]
        
        for dir_name, description in common_dirs:
            if (self.project_path / dir_name).exists():
                organization_patterns.append(f"{description}: {dir_name}")
                structure_score += 1
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å‘½åè¦å‰‡
        naming_patterns = []
        
        php_files = list(self.project_path.rglob("*.php"))
        for php_file in php_files[:5]:
            # PascalCase for classes
            if re.search(r'^[A-Z][A-Za-z0-9]*\.php$', php_file.name):
                naming_patterns.append("PascalCase class files")
            
            # camelCase for regular files
            if re.search(r'^[a-z][A-Za-z0-9]*\.php$', php_file.name):
                naming_patterns.append("camelCase naming")
        
        naming_patterns = list(set(naming_patterns))
        
        # åˆ†é›¢ã®ç¢ºèª
        separation_patterns = []
        
        # MVC ãƒ‘ã‚¿ãƒ¼ãƒ³
        mvc_dirs = ['models', 'views', 'controllers']
        mvc_found = sum(1 for dir_name in mvc_dirs if (self.project_path / dir_name).exists())
        if mvc_found >= 2:
            separation_patterns.append("MVC pattern separation")
        
        # CSS/JS åˆ†é›¢
        if (self.project_path / "css").exists() or (self.project_path / "js").exists():
            separation_patterns.append("CSS/JS separation")
        
        organization_score = structure_score + len(naming_patterns) + len(separation_patterns)
        status = "pass" if organization_score >= 5 else "warning" if organization_score >= 3 else "fail"
        
        return {
            "status": status,
            "organization_patterns": organization_patterns,
            "naming_patterns": naming_patterns,
            "separation_patterns": separation_patterns,
            "structure_score": structure_score,
            "score": f"{organization_score}/10",
            "message": f"ã‚³ãƒ¼ãƒ‰çµ„ç¹”åŒ–: {status}"
        }
    
    def _check_best_practices(self) -> Dict[str, Any]:
        """ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ãƒã‚§ãƒƒã‚¯"""
        
        best_practices = []
        anti_patterns = []
        
        php_files = list(self.project_path.rglob("*.php"))
        
        for php_file in php_files[:10]:
            try:
                content = php_file.read_text(encoding='utf-8')
                
                # ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹
                if 'namespace' in content:
                    best_practices.append("Namespace usage")
                
                if 'use ' in content:
                    best_practices.append("Use statements")
                
                if re.search(r'class\s+\w+\s+implements\s+\w+', content):
                    best_practices.append("Interface implementation")
                
                if 'private ' in content or 'protected ' in content:
                    best_practices.append("Encapsulation")
                
                # ã‚¢ãƒ³ãƒãƒ‘ã‚¿ãƒ¼ãƒ³
                if 'global $' in content:
                    anti_patterns.append(f"Global variables: {php_file.name}")
                
                if 'goto ' in content:
                    anti_patterns.append(f"Goto usage: {php_file.name}")
                
                if re.search(r'eval\s*\(', content):
                    anti_patterns.append(f"Eval usage: {php_file.name}")
                
            except:
                continue
        
        best_practices = list(set(best_practices))
        
        practices_score = len(best_practices)
        anti_patterns_count = len(anti_patterns)
        
        status = "pass" if practices_score >= 3 and anti_patterns_count == 0 else "warning" if practices_score >= 2 else "fail"
        
        return {
            "status": status,
            "best_practices": best_practices,
            "anti_patterns": anti_patterns,
            "score": f"{practices_score}/6",
            "message": f"ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹: {status}"
        }
    
    def _calculate_quality_score(self, checks: Dict[str, Any]) -> int:
        """å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—"""
        
        total_score = 0
        max_score = 0
        
        weights = {
            "coding_standards": 20,
            "documentation": 15,
            "testing_framework": 15,
            "error_handling": 15,
            "performance": 10,
            "maintainability": 10,
            "code_organization": 10,
            "best_practices": 5
        }
        
        for check_name, weight in weights.items():
            max_score += weight
            
            if check_name in checks:
                status = checks[check_name].get("status", "fail")
                if status == "pass":
                    total_score += weight
                elif status == "warning":
                    total_score += weight // 2
        
        return int((total_score / max_score) * 100) if max_score > 0 else 0
    
    def _collect_quality_issues(self, checks: Dict[str, Any]) -> List[str]:
        """å“è³ªå•é¡Œåé›†"""
        
        issues = []
        
        for check_name, result in checks.items():
            if result.get("status") == "fail":
                issues.append(f"{check_name}: {result.get('message', 'Failed')}")
            elif result.get("status") == "warning":
                issues.append(f"{check_name}: {result.get('message', 'Needs improvement')}")
        
        return issues
    
    def _generate_quality_recommendations(self, checks: Dict[str, Any]) -> List[str]:
        """å“è³ªæ¨å¥¨äº‹é …ç”Ÿæˆ"""
        
        recommendations = []
        
        # ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„
        if checks.get("coding_standards", {}).get("status") != "pass":
            recommendations.append("ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„ã®æ¡ç”¨ï¼ˆPSR-12 for PHPã€ESLint for JavaScriptï¼‰")
        
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
        if checks.get("documentation", {}).get("status") != "pass":
            recommendations.append("READMEãƒ•ã‚¡ã‚¤ãƒ«ã¨ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆPHPDoc/JSDocï¼‰ã®ä½œæˆ")
        
        # ãƒ†ã‚¹ãƒˆ
        if checks.get("testing_framework", {}).get("status") != "pass":
            recommendations.append("ãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ï¼ˆPHPUnit/Jestç­‰ï¼‰ã®å°å…¥ã¨å˜ä½“ãƒ†ã‚¹ãƒˆã®ä½œæˆ")
        
        # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
        if checks.get("error_handling", {}).get("status") != "pass":
            recommendations.append("é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼ˆtry-catchã€ã‚«ã‚¹ã‚¿ãƒ ä¾‹å¤–ï¼‰ã®å®Ÿè£…")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        if checks.get("performance", {}).get("status") != "pass":
            recommendations.append("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ï¼ˆã‚¯ã‚¨ãƒªæœ€é©åŒ–ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ´»ç”¨ï¼‰")
        
        # ä¿å®ˆæ€§
        if checks.get("maintainability", {}).get("status") != "pass":
            recommendations.append("ã‚³ãƒ¼ãƒ‰ã®åˆ†å‰²ã¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–ã«ã‚ˆã‚‹ä¿å®ˆæ€§å‘ä¸Š")
        
        return recommendations
    
    def apply_auto_answers(self, project_type: str) -> List[str]:
        """å“è³ªé–¢é€£è‡ªå‹•å›ç­”é©ç”¨"""
        
        answers = []
        
        # NAGANO3ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç‰¹æœ‰ã®è‡ªå‹•å›ç­”
        if "nagano3" in project_type.lower() or "kicho" in project_type.lower():
            nagano3_answers = self.auto_answers.get("auto_answers_database", {}).get("project_templates", {}).get("nagano3_kicho", {}).get("universal_answers", {}).get("quality_standards", {})
            
            for key, value in nagano3_answers.items():
                answers.append(f"{key}: {value}")
        else:
            # æ±ç”¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè‡ªå‹•å›ç­”
            answers.extend([
                "ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„: PSR-12ï¼ˆPHPï¼‰ã€ESLintï¼ˆJavaScriptï¼‰æº–æ‹ ",
                "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: README + ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå¿…é ˆ",
                "ãƒ†ã‚¹ãƒˆ: PHPUnit/Jestç­‰ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ä½¿ç”¨",
                "ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°: å…¨ä¾‹å¤–ã®é©åˆ‡ãªå‡¦ç†",
                "å“è³ªç›®æ¨™: ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸80%ä»¥ä¸Š",
                "ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼: ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼"
            ])
        
        return answers
    
    def _generate_human_questions(self, checks: Dict[str, Any], project_type: str) -> List[str]:
        """äººé–“ã¸ã®è³ªå•ç”Ÿæˆ"""
        
        questions = []
        
        # ãƒ†ã‚¹ãƒˆæˆ¦ç•¥
        if checks.get("testing_framework", {}).get("status") == "fail":
            questions.append("ãƒ†ã‚¹ãƒˆæˆ¦ç•¥ã‚’æ•™ãˆã¦ãã ã•ã„ï¼ˆå˜ä½“ãƒ†ã‚¹ãƒˆãƒ»çµåˆãƒ†ã‚¹ãƒˆãƒ»E2Eãƒ†ã‚¹ãƒˆã®æ–¹é‡ï¼‰")
        
        # ã‚³ãƒ¼ãƒ‰å“è³ªç›®æ¨™
        questions.append("ã‚³ãƒ¼ãƒ‰å“è³ªã®ç›®æ¨™ã‚’æ•™ãˆã¦ãã ã•ã„ï¼ˆã‚«ãƒãƒ¬ãƒƒã‚¸ç‡ãƒ»é™çš„è§£æåŸºæº–ç­‰ï¼‰")
        
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¦ä»¶
        if checks.get("documentation", {}).get("status") == "fail":
            questions.append("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¦ä»¶ã‚’æ•™ãˆã¦ãã ã•ã„ï¼ˆAPIä»•æ§˜æ›¸ãƒ»é‹ç”¨ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ç­‰ï¼‰")
        
        # ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹
        if "nagano3" not in project_type.lower():
            questions.append("ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã‚’æ•™ãˆã¦ãã ã•ã„ï¼ˆãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ãƒ»æ‰¿èªãƒ•ãƒ­ãƒ¼ç­‰ï¼‰")
        
        return questions

def main():
    """å“è³ªä¿è¨¼Hookså˜ä½“ãƒ†ã‚¹ãƒˆ"""
    
    project_path = sys.argv[1] if len(sys.argv) > 1 else "."
    
    hooks = QualityAssuranceHooks(project_path)
    result = hooks.execute_hooks()
    
    print("\n" + "="*60)
    print("âœ… Quality Assurance Hooks å®Ÿè¡Œçµæœ")
    print("="*60)
    print(f"ğŸ“Š ç·åˆã‚¹ã‚³ã‚¢: {result['overall_score']}/100")
    print(f"âš ï¸ æ¤œå‡ºå•é¡Œ: {len(result['issues_found'])}ä»¶")
    print(f"ğŸ’¡ æ¨å¥¨äº‹é …: {len(result['recommendations'])}ä»¶")
    print(f"âœ… è‡ªå‹•å›ç­”: {len(result['auto_answers_applied'])}ä»¶")
    
    return result['overall_score'] >= 75

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)