#!/usr/bin/env python3
"""
ğŸ” è‡ªå‹•ãƒ­ãƒ¼ã‚«ãƒ«å‚ç…§ã‚·ã‚¹ãƒ†ãƒ 
æ¯å›ã®ã‚„ã‚Šå–ã‚Šã§æŒ‡å®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•æ¤œç´¢ãƒ»å‚ç…§
æ–‡å­—æ•°å‰Šæ¸›ã¨ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡åŒ–ã‚’å®Ÿç¾
"""

import os
import json
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
import re
from datetime import datetime

class AutoLocalReferenceSystem:
    """è‡ªå‹•ãƒ­ãƒ¼ã‚«ãƒ«å‚ç…§ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, base_path: str):
        self.base_path = Path(base_path)
        self.file_index = {}
        self.content_cache = {}
        self.reference_patterns = self._setup_reference_patterns()
        
        # åˆæœŸåŒ–æ™‚ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰
        self._build_file_index()
    
    def _setup_reference_patterns(self) -> Dict[str, List[str]]:
        """å‚ç…§ãƒ‘ã‚¿ãƒ¼ãƒ³è¨­å®š"""
        return {
            "hooks": [
                "hooks", "hook", "validation", "check", "test",
                "çµ±ä¸€", "çŸ›ç›¾", "ä¿®æ­£", "ã‚·ã‚¹ãƒ†ãƒ "
            ],
            "config": [
                "config", "setting", "database", "auth", "api",
                "è¨­å®š", "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹", "èªè¨¼", "æ§‹æˆ"
            ],
            "development": [
                "dev", "development", "build", "deploy", "run",
                "é–‹ç™º", "å®Ÿè¡Œ", "æ§‹ç¯‰", "ãƒ‡ãƒ—ãƒ­ã‚¤"
            ],
            "documentation": [
                "doc", "readme", "manual", "guide", "instruction",
                "èª¬æ˜", "æ‰‹é †", "æŒ‡ç¤º", "ã‚¬ã‚¤ãƒ‰", "ãƒãƒ‹ãƒ¥ã‚¢ãƒ«"
            ],
            "ai_integration": [
                "ai", "intelligent", "smart", "auto", "machine",
                "AI", "äººå·¥çŸ¥èƒ½", "è‡ªå‹•", "çµ±åˆ"
            ]
        }
    
    def _build_file_index(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰"""
        print("ğŸ” ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ä¸­...")
        
        for file_path in self.base_path.rglob("*"):
            if file_path.is_file() and self._is_text_file(file_path):
                relative_path = str(file_path.relative_to(self.base_path))
                
                # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ç™»éŒ²
                self.file_index[relative_path] = {
                    "full_path": str(file_path),
                    "name": file_path.name,
                    "extension": file_path.suffix,
                    "size": file_path.stat().st_size,
                    "modified": datetime.fromtimestamp(file_path.stat().st_mtime),
                    "category": self._categorize_file(file_path),
                    "keywords": self._extract_keywords_from_filename(file_path.name)
                }
        
        print(f"âœ… {len(self.file_index)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–")
    
    def _is_text_file(self, file_path: Path) -> bool:
        """ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«åˆ¤å®š"""
        text_extensions = {
            '.py', '.js', '.html', '.css', '.md', '.txt', '.json', 
            '.yaml', '.yml', '.ini', '.conf', '.sh', '.sql'
        }
        return file_path.suffix.lower() in text_extensions
    
    def _categorize_file(self, file_path: Path) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚«ãƒ†ã‚´ãƒªåˆ†é¡"""
        name_lower = file_path.name.lower()
        
        if any(keyword in name_lower for keyword in ["hook", "validation", "check"]):
            return "hooks"
        elif any(keyword in name_lower for keyword in ["config", "setting", "database"]):
            return "config"
        elif any(keyword in name_lower for keyword in ["ai", "intelligent", "smart"]):
            return "ai_integration"
        elif any(keyword in name_lower for keyword in ["readme", "manual", "guide"]):
            return "documentation"
        elif file_path.suffix == '.py':
            return "python_code"
        elif file_path.suffix in ['.js', '.html', '.css']:
            return "web_development"
        else:
            return "general"
    
    def _extract_keywords_from_filename(self, filename: str) -> List[str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º"""
        # ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã€ãƒã‚¤ãƒ•ãƒ³ã§åˆ†å‰²
        keywords = re.split(r'[_\-\.]', filename.lower())
        return [kw for kw in keywords if len(kw) > 2]
    
    def auto_find_relevant_files(self, user_query: str) -> List[Dict[str, Any]]:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒªã‹ã‚‰é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«è‡ªå‹•æ¤œç´¢"""
        query_lower = user_query.lower()
        relevant_files = []
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°
        for file_path, file_info in self.file_index.items():
            relevance_score = 0
            matched_keywords = []
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åãƒãƒƒãƒãƒ³ã‚°
            for keyword in file_info["keywords"]:
                if keyword in query_lower:
                    relevance_score += 3
                    matched_keywords.append(keyword)
            
            # ã‚«ãƒ†ã‚´ãƒªãƒãƒƒãƒãƒ³ã‚°
            for category, patterns in self.reference_patterns.items():
                if file_info["category"] == category:
                    for pattern in patterns:
                        if pattern in query_lower:
                            relevance_score += 2
                            matched_keywords.append(pattern)
            
            # é–¢é€£åº¦ãŒé«˜ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ
            if relevance_score > 2:
                relevant_files.append({
                    "file_path": file_path,
                    "full_path": file_info["full_path"],
                    "relevance_score": relevance_score,
                    "matched_keywords": matched_keywords,
                    "category": file_info["category"],
                    "name": file_info["name"]
                })
        
        # é–¢é€£åº¦ã§ã‚½ãƒ¼ãƒˆ
        relevant_files.sort(key=lambda x: x["relevance_score"], reverse=True)
        return relevant_files[:5]  # ä¸Šä½5ä»¶
    
    def get_file_summary(self, file_path: str, max_lines: int = 30) -> Dict[str, Any]:
        """ãƒ•ã‚¡ã‚¤ãƒ«è¦ç´„å–å¾—"""
        full_path = self.base_path / file_path
        
        try:
            with open(full_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«è¦ç´„ç”Ÿæˆ
            summary = {
                "file_path": file_path,
                "total_lines": len(lines),
                "preview": "".join(lines[:max_lines]),
                "file_type": self._analyze_file_type(lines),
                "key_sections": self._extract_key_sections(lines),
                "imports": self._extract_imports(lines) if file_path.endswith('.py') else [],
                "functions": self._extract_functions(lines) if file_path.endswith('.py') else [],
                "classes": self._extract_classes(lines) if file_path.endswith('.py') else []
            }
            
            return summary
            
        except Exception as e:
            return {"error": f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼: {e}"}
    
    def _analyze_file_type(self, lines: List[str]) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—åˆ†æ"""
        content = "".join(lines[:20]).lower()
        
        if "#!/usr/bin/env python" in content or "import " in content:
            return "python_script"
        elif "<!doctype html" in content or "<html" in content:
            return "html_document"
        elif "function " in content or "const " in content:
            return "javascript_code"
        elif "{" in content and ":" in content:
            return "json_config"
        else:
            return "text_document"
    
    def _extract_key_sections(self, lines: List[str]) -> List[str]:
        """é‡è¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³æŠ½å‡º"""
        key_sections = []
        
        for i, line in enumerate(lines[:50]):  # æœ€åˆã®50è¡Œã‹ã‚‰æŠ½å‡º
            line_stripped = line.strip()
            
            # Pythonã‚¯ãƒ©ã‚¹ãƒ»é–¢æ•°
            if line_stripped.startswith(('class ', 'def ', 'async def ')):
                key_sections.append(f"L{i+1}: {line_stripped}")
            
            # ã‚³ãƒ¡ãƒ³ãƒˆï¼ˆé‡è¦ãã†ãªã‚‚ã®ï¼‰
            elif line_stripped.startswith(('#', '"""', "'''")):
                if len(line_stripped) > 20:  # é•·ã„ã‚³ãƒ¡ãƒ³ãƒˆã®ã¿
                    key_sections.append(f"L{i+1}: {line_stripped[:60]}...")
            
            # è¨­å®šãƒ»å®šæ•°
            elif '=' in line_stripped and line_stripped.isupper():
                key_sections.append(f"L{i+1}: {line_stripped}")
        
        return key_sections[:10]  # ä¸Šä½10å€‹
    
    def _extract_imports(self, lines: List[str]) -> List[str]:
        """importæ–‡æŠ½å‡º"""
        imports = []
        for line in lines[:30]:  # æœ€åˆã®30è¡Œ
            line_stripped = line.strip()
            if line_stripped.startswith(('import ', 'from ')):
                imports.append(line_stripped)
        return imports
    
    def _extract_functions(self, lines: List[str]) -> List[str]:
        """é–¢æ•°å®šç¾©æŠ½å‡º"""
        functions = []
        for line in lines:
            line_stripped = line.strip()
            if line_stripped.startswith(('def ', 'async def ')):
                functions.append(line_stripped.split('(')[0].replace('def ', '').replace('async ', ''))
        return functions[:10]  # ä¸Šä½10å€‹
    
    def _extract_classes(self, lines: List[str]) -> List[str]:
        """ã‚¯ãƒ©ã‚¹å®šç¾©æŠ½å‡º"""
        classes = []
        for line in lines:
            line_stripped = line.strip()
            if line_stripped.startswith('class '):
                class_name = line_stripped.split('(')[0].replace('class ', '').replace(':', '')
                classes.append(class_name)
        return classes
    
    def generate_context_summary(self, user_query: str) -> str:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒªã«å¯¾ã™ã‚‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ç”Ÿæˆ"""
        relevant_files = self.auto_find_relevant_files(user_query)
        
        if not relevant_files:
            return "é–¢é€£ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        summary = f"""
# ğŸ” è‡ªå‹•æ¤œç´¢ã•ã‚ŒãŸãƒ­ãƒ¼ã‚«ãƒ«å‚ç…§ãƒ•ã‚¡ã‚¤ãƒ«

## ğŸ“Š ã‚¯ã‚¨ãƒª: "{user_query}"

## ğŸ“ é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ« ({len(relevant_files)}ä»¶)

"""
        
        for i, file_info in enumerate(relevant_files, 1):
            file_summary = self.get_file_summary(file_info["file_path"])
            
            summary += f"""
### {i}. {file_info["name"]}
**ãƒ‘ã‚¹**: `{file_info["file_path"]}`
**é–¢é€£åº¦**: {file_info["relevance_score"]}ç‚¹
**ã‚«ãƒ†ã‚´ãƒª**: {file_info["category"]}
**ãƒãƒƒãƒã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: {', '.join(file_info["matched_keywords"])}

**ãƒ•ã‚¡ã‚¤ãƒ«æ¦‚è¦**:
- ç·è¡Œæ•°: {file_summary.get('total_lines', 'N/A')}è¡Œ
- ã‚¿ã‚¤ãƒ—: {file_summary.get('file_type', 'N/A')}
- ä¸»è¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³: {len(file_summary.get('key_sections', []))}å€‹

**ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼**:
```
{file_summary.get('preview', 'ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼')[:200]}...
```

---
"""
        
        summary += f"""
## ğŸ’¡ å‚ç…§æ´»ç”¨æ–¹æ³•
- è©³ç´°ç¢ºèª: `filesystem:read_file` ã§å®Œå…¨å†…å®¹å–å¾—
- ä¿®æ­£ç‰ˆä½œæˆ: æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã§æ”¹è‰¯ç‰ˆç”Ÿæˆ
- çµ±åˆä½œæ¥­: è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’çµ±åˆ
"""
        
        return summary

# ===================================================
# ğŸš€ å®Ÿè¡Œãƒ»ãƒ†ã‚¹ãƒˆç”¨ã‚·ã‚¹ãƒ†ãƒ 
# ===================================================

def demo_auto_reference_system():
    """è‡ªå‹•å‚ç…§ã‚·ã‚¹ãƒ†ãƒ ãƒ‡ãƒ¢"""
    
    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    base_path = "/Users/aritahiroaki/NAGANO-3/N3-Development/common/claude_universal_hooks"
    auto_ref = AutoLocalReferenceSystem(base_path)
    
    # ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª
    test_queries = [
        "hooksã®çµ±ä¸€ã‚·ã‚¹ãƒ†ãƒ ã«ã¤ã„ã¦",
        "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®šã®ä¿®æ­£",
        "AIçµ±åˆæ©Ÿèƒ½ã®å®Ÿè£…",
        "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª",
        "å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ä½œæˆ"
    ]
    
    print("ğŸ¯ è‡ªå‹•ãƒ­ãƒ¼ã‚«ãƒ«å‚ç…§ã‚·ã‚¹ãƒ†ãƒ  - ãƒ‡ãƒ¢å®Ÿè¡Œ")
    print("=" * 60)
    
    for query in test_queries:
        print(f"\nğŸ“ ã‚¯ã‚¨ãƒª: {query}")
        print("-" * 40)
        
        relevant_files = auto_ref.auto_find_relevant_files(query)
        
        if relevant_files:
            print(f"âœ… {len(relevant_files)}ä»¶ã®é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹:")
            for file_info in relevant_files[:3]:  # ä¸Šä½3ä»¶
                print(f"  - {file_info['name']} (é–¢é€£åº¦: {file_info['relevance_score']})")
        else:
            print("âŒ é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ãªã—")
    
    # è©³ç´°ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆ
    print("\n" + "=" * 60)
    print("ğŸ“‹ è©³ç´°ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆ")
    
    test_query = "çµ±ä¸€hooksã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…"
    context = auto_ref.generate_context_summary(test_query)
    print(context[:1000] + "..." if len(context) > 1000 else context)

if __name__ == "__main__":
    demo_auto_reference_system()
