#!/usr/bin/env python3
"""
ğŸŒŸ æ±ç”¨ãƒ­ãƒ¼ã‚«ãƒ«å‚ç…§ãƒ»è‡ªå‹•ä¿å­˜ã‚·ã‚¹ãƒ†ãƒ 
å…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå¯¾å¿œ - ã©ã“ã§ã‚‚ä½¿ãˆã‚‹ãƒ­ãƒ¼ã‚«ãƒ«é€£æºã‚·ã‚¹ãƒ†ãƒ 

ç‰¹å¾´:
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè‡ªå‹•æ¤œå‡º
- é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«è‡ªå‹•å‚ç…§
- æ—¥ä»˜ãƒ•ã‚©ãƒ«ãƒ€è‡ªå‹•ä½œæˆ
- æˆæœç‰©è‡ªå‹•ä¿å­˜ãƒ»æ•´ç†
"""

import os
import json
import shutil
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
import re
from datetime import datetime
import logging

class UniversalLocalSystem:
    """æ±ç”¨ãƒ­ãƒ¼ã‚«ãƒ«ã‚·ã‚¹ãƒ†ãƒ  - å…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå¯¾å¿œ"""
    
    def __init__(self, project_root: str = None):
        """
        åˆæœŸåŒ–
        project_root: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ï¼ˆè‡ªå‹•æ¤œå‡ºã‚‚å¯èƒ½ï¼‰
        """
        self.project_root = self._detect_project_root(project_root)
        self.auto_save_enabled = True
        self.current_session = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜å…ˆè¨­å®š
        self.save_config = {
            "base_folder": "claude_generated",
            "date_format": "%Y-%m-%d",
            "session_format": "session_%H%M%S",
            "auto_organize": True
        }
        
        # æ¤œç´¢å¯¾è±¡è¨­å®š
        self.search_config = {
            "target_extensions": [
                ".py", ".js", ".html", ".css", ".md", ".json", 
                ".yaml", ".yml", ".sql", ".sh", ".php", ".txt"
            ],
            "search_depths": {
                "shallow": 2,   # config, src ãƒ¬ãƒ™ãƒ«
                "medium": 4,    # src/components/... ãƒ¬ãƒ™ãƒ« 
                "deep": 6       # æ·±ã„éšå±¤ã¾ã§
            },
            "priority_folders": [
                "src", "common", "config", "components", 
                "modules", "hooks", "services", "database",
                "N3-Development", "claude_hooks", "claude_universal_hooks"
            ]
        }
        
        self._initialize_system()
    
    def _detect_project_root(self, provided_root: str = None) -> Path:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆè‡ªå‹•æ¤œå‡º"""
        
        if provided_root:
            return Path(provided_root).resolve()
        
        # ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ä¸Šä½ã¸é¡ã£ã¦ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆæ¤œå‡º
        current_path = Path.cwd()
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒ¼ã‚«ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ•ã‚©ãƒ«ãƒ€
        project_markers = [
            ".git", "package.json", "composer.json", "requirements.txt",
            "Makefile", "docker-compose.yml", "README.md"
        ]
        
        # ä¸Šä½ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¢ç´¢
        for parent in [current_path] + list(current_path.parents):
            for marker in project_markers:
                if (parent / marker).exists():
                    print(f"ğŸ¯ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆæ¤œå‡º: {parent}")
                    return parent
        
        # ãƒãƒ¼ã‚«ãƒ¼ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        print(f"âš ï¸ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆæœªæ¤œå‡º - ç¾åœ¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½¿ç”¨: {current_path}")
        return current_path
    
    def _initialize_system(self):
        """ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        print(f"ğŸš€ æ±ç”¨ãƒ­ãƒ¼ã‚«ãƒ«ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–")
        print(f"ğŸ“‚ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ: {self.project_root}")
        
        # ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆ
        self._setup_save_directories()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰
        self.file_index = self._build_comprehensive_index()
        
        print(f"âœ… ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº† - {len(self.file_index)}ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º")
    
    def _setup_save_directories(self):
        """è‡ªå‹•ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆ"""
        
        today = datetime.now().strftime(self.save_config["date_format"])
        session = datetime.now().strftime(self.save_config["session_format"])
        
        # ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.save_base = self.project_root / self.save_config["base_folder"]
        
        # æ—¥ä»˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.save_date_dir = self.save_base / today
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.save_session_dir = self.save_date_dir / session
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.save_categories = {
            "code": self.save_session_dir / "01_code",
            "config": self.save_session_dir / "02_config", 
            "docs": self.save_session_dir / "03_docs",
            "scripts": self.save_session_dir / "04_scripts",
            "data": self.save_session_dir / "05_data",
            "analysis": self.save_session_dir / "06_analysis"
        }
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        for category_path in self.save_categories.values():
            category_path.mkdir(parents=True, exist_ok=True)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        self._create_session_metadata()
        
        print(f"ğŸ“ ä¿å­˜å…ˆæº–å‚™å®Œäº†: {self.save_session_dir}")
    
    def _create_session_metadata(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä½œæˆ"""
        
        metadata = {
            "session_id": self.current_session,
            "created_at": datetime.now().isoformat(),
            "project_root": str(self.project_root),
            "save_directories": {k: str(v) for k, v in self.save_categories.items()},
            "files_processed": [],
            "generated_files": []
        }
        
        metadata_file = self.save_session_dir / "session_metadata.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        self.session_metadata_file = metadata_file
    
    def _build_comprehensive_index(self) -> Dict[str, Dict[str, Any]]:
        """åŒ…æ‹¬çš„ãƒ•ã‚¡ã‚¤ãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰"""
        
        file_index = {}
        
        # å„ªå…ˆãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰æ¤œç´¢
        for priority_folder in self.search_config["priority_folders"]:
            folder_path = self.project_root / priority_folder
            if folder_path.exists():
                self._index_directory(folder_path, file_index, depth=0, max_depth=4)
        
        # è¿½åŠ ã§ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚‚è»½ãæ¤œç´¢
        self._index_directory(self.project_root, file_index, depth=0, max_depth=2)
        
        return file_index
    
    def _index_directory(self, directory: Path, index: Dict, depth: int, max_depth: int):
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–"""
        
        if depth > max_depth:
            return
        
        try:
            for item in directory.iterdir():
                if item.is_file() and self._is_target_file(item):
                    relative_path = str(item.relative_to(self.project_root))
                    
                    index[relative_path] = {
                        "full_path": str(item),
                        "name": item.name,
                        "extension": item.suffix,
                        "size": item.stat().st_size,
                        "modified": datetime.fromtimestamp(item.stat().st_mtime),
                        "category": self._categorize_file(item),
                        "keywords": self._extract_keywords(item.name),
                        "depth": depth
                    }
                
                elif item.is_dir() and not self._is_ignored_directory(item):
                    self._index_directory(item, index, depth + 1, max_depth)
        
        except PermissionError:
            pass  # ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
    
    def _is_target_file(self, file_path: Path) -> bool:
        """å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«åˆ¤å®š"""
        return file_path.suffix.lower() in self.search_config["target_extensions"]
    
    def _is_ignored_directory(self, dir_path: Path) -> bool:
        """ç„¡è¦–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåˆ¤å®š"""
        ignored = {
            ".git", ".svn", "node_modules", "__pycache__", 
            ".venv", "venv", ".env", "build", "dist"
        }
        return dir_path.name in ignored
    
    def _categorize_file(self, file_path: Path) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚«ãƒ†ã‚´ãƒªåˆ†é¡"""
        
        name_lower = file_path.name.lower()
        parent_lower = file_path.parent.name.lower()
        
        # æ‹¡å¼µå­ãƒ™ãƒ¼ã‚¹åˆ†é¡
        if file_path.suffix == '.py':
            return "python"
        elif file_path.suffix in ['.js', '.ts']:
            return "javascript"
        elif file_path.suffix in ['.html', '.css']:
            return "web"
        elif file_path.suffix in ['.json', '.yaml', '.yml']:
            return "config"
        elif file_path.suffix == '.md':
            return "documentation"
        elif file_path.suffix in ['.sql']:
            return "database"
        elif file_path.suffix in ['.sh']:
            return "script"
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ™ãƒ¼ã‚¹åˆ†é¡
        if "config" in parent_lower:
            return "config"
        elif "hook" in parent_lower:
            return "hooks"
        elif "test" in parent_lower:
            return "test"
        elif "doc" in parent_lower:
            return "documentation"
        
        return "general"
    
    def _extract_keywords(self, filename: str) -> List[str]:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º"""
        keywords = re.split(r'[_\-\.]', filename.lower())
        return [kw for kw in keywords if len(kw) > 2]
    
    def smart_search(self, query: str) -> List[Dict[str, Any]]:
        """ã‚¹ãƒãƒ¼ãƒˆæ¤œç´¢"""
        
        query_lower = query.lower()
        results = []
        
        # æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³
        search_patterns = {
            "hooks": ["hook", "validation", "check", "unified", "çµ±ä¸€"],
            "config": ["config", "setting", "database", "auth", "è¨­å®š"],
            "ai": ["ai", "intelligent", "smart", "auto", "machine"],
            "development": ["dev", "build", "deploy", "run", "é–‹ç™º"],
            "database": ["db", "database", "sql", "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹"],
            "api": ["api", "service", "endpoint", "rest"],
            "frontend": ["frontend", "ui", "component", "ãƒ•ãƒ­ãƒ³ãƒˆ"],
            "backend": ["backend", "server", "ãƒãƒƒã‚¯"]
        }
        
        for file_path, file_info in self.file_index.items():
            relevance_score = 0
            matched_keywords = []
            
            # ç›´æ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒ
            for keyword in file_info["keywords"]:
                if keyword in query_lower:
                    relevance_score += 3
                    matched_keywords.append(keyword)
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒ
            for pattern_name, patterns in search_patterns.items():
                if any(pattern in query_lower for pattern in patterns):
                    if file_info["category"] == pattern_name or any(pattern in file_info["keywords"] for pattern in patterns):
                        relevance_score += 2
                        matched_keywords.extend(patterns)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åãƒãƒƒãƒ
            if any(word in file_info["name"].lower() for word in query_lower.split()):
                relevance_score += 1
            
            if relevance_score > 0:
                results.append({
                    "file_path": file_path,
                    "full_path": file_info["full_path"],
                    "relevance_score": relevance_score,
                    "matched_keywords": list(set(matched_keywords)),
                    "category": file_info["category"],
                    "name": file_info["name"],
                    "size": file_info["size"],
                    "modified": file_info["modified"]
                })
        
        # é–¢é€£åº¦ã§ã‚½ãƒ¼ãƒˆ
        results.sort(key=lambda x: x["relevance_score"], reverse=True)
        return results[:10]  # ä¸Šä½10ä»¶
    
    def auto_save_file(self, content: str, filename: str, category: str = "code", metadata: Dict = None) -> str:
        """è‡ªå‹•ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜"""
        
        if not self.auto_save_enabled:
            return None
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå–å¾—
        if category not in self.save_categories:
            category = "code"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        
        save_dir = self.save_categories[category]
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åå‡¦ç†ï¼ˆé‡è¤‡å›é¿ï¼‰
        base_name, ext = os.path.splitext(filename)
        counter = 1
        final_filename = filename
        
        while (save_dir / final_filename).exists():
            final_filename = f"{base_name}_{counter:02d}{ext}"
            counter += 1
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        file_path = save_dir / final_filename
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°
        self._update_session_metadata("generated_files", {
            "filename": final_filename,
            "category": category,
            "path": str(file_path),
            "size": len(content),
            "created_at": datetime.now().isoformat(),
            "metadata": metadata or {}
        })
        
        print(f"ğŸ’¾ è‡ªå‹•ä¿å­˜: {file_path}")
        return str(file_path)
    
    def _update_session_metadata(self, key: str, value: Any):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°"""
        
        try:
            with open(self.session_metadata_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            if key not in metadata:
                metadata[key] = []
            
            if isinstance(metadata[key], list):
                metadata[key].append(value)
            else:
                metadata[key] = value
            
            metadata["last_updated"] = datetime.now().isoformat()
            
            with open(self.session_metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        except Exception as e:
            print(f"âš ï¸ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
    
    def generate_context_summary(self, query: str) -> str:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ç”Ÿæˆ"""
        
        search_results = self.smart_search(query)
        
        if not search_results:
            return "é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        summary = f"""
# ğŸ” æ±ç”¨ãƒ­ãƒ¼ã‚«ãƒ«å‚ç…§ã‚·ã‚¹ãƒ†ãƒ  - æ¤œç´¢çµæœ

## ğŸ“Š ã‚¯ã‚¨ãƒª: "{query}"
## ğŸ“‚ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {self.project_root.name}
## ğŸ’¾ è‡ªå‹•ä¿å­˜å…ˆ: {self.save_session_dir}

## ğŸ“ é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ« ({len(search_results)}ä»¶)

"""
        
        for i, result in enumerate(search_results, 1):
            summary += f"""
### {i}. {result["name"]}
**ãƒ‘ã‚¹**: `{result["file_path"]}`
**é–¢é€£åº¦**: {result["relevance_score"]}ç‚¹
**ã‚«ãƒ†ã‚´ãƒª**: {result["category"]}
**ã‚µã‚¤ã‚º**: {result["size"]:,}bytes
**æ›´æ–°**: {result["modified"].strftime("%Y-%m-%d %H:%M")}
**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: {', '.join(result["matched_keywords"])}

---
"""
        
        summary += f"""
## ğŸ¯ æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
1. **è©³ç´°ç¢ºèª**: `filesystem:read_file` ã§å†…å®¹ç¢ºèª
2. **è‡ªå‹•ä¿å­˜**: ä¿®æ­£ãƒ»ä½œæˆã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã¯è‡ªå‹•çš„ã«ä¿å­˜
3. **æ•´ç†**: æ—¥ä»˜ãƒ»ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ¥ã§è‡ªå‹•æ•´ç†

## ğŸ“ ä¿å­˜å…ˆæ§‹é€ 
```
{self.save_session_dir}/
â”œâ”€â”€ 01_code/     - Pythonãƒ•ã‚¡ã‚¤ãƒ«ã€JSãƒ•ã‚¡ã‚¤ãƒ«ç­‰
â”œâ”€â”€ 02_config/   - è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã€JSONãƒ•ã‚¡ã‚¤ãƒ«ç­‰  
â”œâ”€â”€ 03_docs/     - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã€MDãƒ•ã‚¡ã‚¤ãƒ«ç­‰
â”œâ”€â”€ 04_scripts/  - å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆã€ã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆç­‰
â”œâ”€â”€ 05_data/     - ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã€CSVãƒ•ã‚¡ã‚¤ãƒ«ç­‰
â””â”€â”€ 06_analysis/ - åˆ†æãƒ¬ãƒãƒ¼ãƒˆã€èª¿æŸ»çµæœç­‰
```
"""
        
        return summary
    
    def get_session_summary(self) -> str:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³è¦ç´„å–å¾—"""
        
        try:
            with open(self.session_metadata_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            generated_count = len(metadata.get("generated_files", []))
            
            summary = f"""
# ğŸ“Š ã‚»ãƒƒã‚·ãƒ§ãƒ³è¦ç´„

## ğŸ• ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±
- **ã‚»ãƒƒã‚·ãƒ§ãƒ³ID**: {metadata["session_id"]}
- **é–‹å§‹æ™‚åˆ»**: {metadata["created_at"]}
- **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**: {Path(metadata["project_root"]).name}

## ğŸ“ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«æ•°
- **ç·æ•°**: {generated_count}ãƒ•ã‚¡ã‚¤ãƒ«

## ğŸ’¾ ä¿å­˜å…ˆ
- **ãƒ™ãƒ¼ã‚¹**: {self.save_session_dir}

## ğŸ“‹ ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°
"""
            
            for file_info in metadata.get("generated_files", []):
                summary += f"- {file_info['filename']} ({file_info['category']}) - {file_info['size']:,}bytes\n"
            
            return summary
            
        except Exception as e:
            return f"ã‚»ãƒƒã‚·ãƒ§ãƒ³è¦ç´„å–å¾—ã‚¨ãƒ©ãƒ¼: {e}"

# ===================================================
# ğŸš€ ä½¿ç”¨ä¾‹ãƒ»ãƒ†ã‚¹ãƒˆ
# ===================================================

def demo_universal_system():
    """æ±ç”¨ã‚·ã‚¹ãƒ†ãƒ ãƒ‡ãƒ¢"""
    
    print("ğŸŒŸ æ±ç”¨ãƒ­ãƒ¼ã‚«ãƒ«å‚ç…§ãƒ»è‡ªå‹•ä¿å­˜ã‚·ã‚¹ãƒ†ãƒ  - ãƒ‡ãƒ¢")
    print("=" * 60)
    
    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    system = UniversalLocalSystem()
    
    # æ¤œç´¢ãƒ†ã‚¹ãƒˆ
    test_queries = [
        "hooksã‚·ã‚¹ãƒ†ãƒ ã®çµ±ä¸€",
        "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š",
        "AIçµ±åˆæ©Ÿèƒ½",
        "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«"
    ]
    
    for query in test_queries:
        print(f"\nğŸ” æ¤œç´¢: {query}")
        context = system.generate_context_summary(query)
        print(context[:500] + "..." if len(context) > 500 else context)
    
    # è‡ªå‹•ä¿å­˜ãƒ†ã‚¹ãƒˆ
    print("\nğŸ’¾ è‡ªå‹•ä¿å­˜ãƒ†ã‚¹ãƒˆ")
    test_content = '''
def unified_hooks_example():
    """çµ±ä¸€Hooksã‚·ã‚¹ãƒ†ãƒ ä¾‹"""
    return "Hello World"
'''
    
    saved_path = system.auto_save_file(
        content=test_content,
        filename="unified_hooks_example.py",
        category="code",
        metadata={"description": "ãƒ†ã‚¹ãƒˆç”¨çµ±ä¸€Hooksãƒ•ã‚¡ã‚¤ãƒ«"}
    )
    
    print(f"âœ… ä¿å­˜å®Œäº†: {saved_path}")
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³è¦ç´„
    print("\nğŸ“Š ã‚»ãƒƒã‚·ãƒ§ãƒ³è¦ç´„")
    print(system.get_session_summary())

if __name__ == "__main__":
    demo_universal_system()
