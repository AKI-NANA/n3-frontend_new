#!/usr/bin/env python3
"""
ğŸ¤– Hooksè‡ªå‹•åˆ¤å®šã‚¨ãƒ³ã‚¸ãƒ³
æŒ‡ç¤ºæ›¸ãƒ»HTMLãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã‹ã‚‰å¿…è¦ãªHooksã‚’è‡ªå‹•åˆ¤å®š

ãƒ•ã‚¡ã‚¤ãƒ«: ~/.claude/engines/auto_classifier.py
"""

import os
import re
import json
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime

class HooksAutoClassifier:
    """Hooksè‡ªå‹•åˆ¤å®šã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, config_path: str = "~/.claude/settings.json"):
        self.config_path = Path(config_path).expanduser()
        self.config = self.load_config()
        self.project_patterns = self.load_project_patterns()
        self.hooks_registry_path = Path("~/.claude/registry/hooks_registry.json").expanduser()
        self.auto_answers_path = Path("~/.claude/database/auto_answers.json").expanduser()
        
    def load_config(self) -> Dict:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿"""
        if self.config_path.exists():
            try:
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return self.get_default_config()
    
    def get_default_config(self) -> Dict:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š"""
        return {
            "classifier_settings": {
                "confidence_threshold": 0.7,
                "max_hooks_per_category": 10,
                "enable_auto_answers": True,
                "enable_learning": True
            },
            "detection_rules": {
                "project_type_weight": 0.4,
                "technology_stack_weight": 0.3,
                "file_structure_weight": 0.2,
                "content_analysis_weight": 0.1
            }
        }
    
    def analyze_project_context(self, project_path: str = ".") -> Dict[str, Any]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã®åˆ†æ"""
        
        project_path = Path(project_path).resolve()
        print(f"ğŸ” ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†æé–‹å§‹: {project_path}")
        
        analysis = {
            "timestamp": datetime.now().isoformat(),
            "project_path": str(project_path),
            "project_type": self.detect_project_type(project_path),
            "technology_stack": self.detect_technology_stack(project_path),
            "file_structure": self.analyze_file_structure(project_path),
            "content_analysis": self.analyze_file_contents(project_path),
            "complexity_metrics": self.calculate_complexity_metrics(project_path),
            "integration_needs": self.detect_integration_needs(project_path),
            "special_requirements": self.extract_special_requirements(project_path)
        }
        
        print(f"âœ… ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†æå®Œäº†")
        return analysis
    
    def detect_project_type(self, project_path: Path) -> Dict[str, Any]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒ—ã®è‡ªå‹•æ¤œå‡º"""
        
        detection_result = {
            "primary_type": "unknown",
            "sub_types": [],
            "confidence": 0.0,
            "evidence": []
        }
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã«ã‚ˆã‚‹åˆ¤å®š
        dir_indicators = {
            "nagano3_kicho": {
                "patterns": [
                    "modules/kicho", "common/js/hooks", "kicho_content.php", 
                    "kicho_ai_visualization.js", "MF_", "NAGANO3"
                ],
                "confidence": 0.95
            },
            "nagano3_generic": {
                "patterns": ["modules/", "common/", "NAGANO3", "N3-Development"],
                "confidence": 0.8
            },
            "e_commerce": {
                "patterns": ["cart/", "payment/", "order/", "product/", "SHOPIFY_", "STRIPE_"],
                "confidence": 0.85
            },
            "api_service": {
                "patterns": ["api/", "endpoints/", "services/", "fastapi", "OPENAI_API"],
                "confidence": 0.8
            },
            "web_application": {
                "patterns": ["public/", "assets/", "views/", "templates/", "css/", "js/"],
                "confidence": 0.7
            }
        }
        
        max_confidence = 0
        detected_type = "unknown"
        evidence_list = []
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¤œç´¢
        for project_type, indicators in dir_indicators.items():
            matches = 0
            total_patterns = len(indicators["patterns"])
            
            for pattern in indicators["patterns"]:
                if self.find_pattern_in_directory(project_path, pattern):
                    matches += 1
                    evidence_list.append(f"Found: {pattern}")
            
            confidence = (matches / total_patterns) * indicators["confidence"]
            
            if confidence > max_confidence:
                max_confidence = confidence
                detected_type = project_type
        
        detection_result.update({
            "primary_type": detected_type,
            "confidence": max_confidence,
            "evidence": evidence_list
        })
        
        print(f"ğŸ¯ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒ—æ¤œå‡º: {detected_type} (ä¿¡é ¼åº¦: {max_confidence:.2f})")
        return detection_result
    
    def detect_technology_stack(self, project_path: Path) -> Dict[str, List[str]]:
        """æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã®è‡ªå‹•æ¤œå‡º"""
        
        tech_stack = {
            "backend": [],
            "frontend": [],
            "database": [],
            "api": [],
            "tools": [],
            "frameworks": []
        }
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã«ã‚ˆã‚‹æ¤œå‡º
        file_extensions = {
            ".php": ("backend", "PHP"),
            ".py": ("backend", "Python"), 
            ".js": ("frontend", "JavaScript"),
            ".ts": ("frontend", "TypeScript"),
            ".html": ("frontend", "HTML"),
            ".css": ("frontend", "CSS"),
            ".sql": ("database", "SQL")
        }
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚ˆã‚‹æ¤œå‡º
        config_files = {
            "composer.json": ("backend", "PHP/Composer"),
            "package.json": ("frontend", "Node.js"),
            "requirements.txt": ("backend", "Python"),
            ".env": ("tools", "Environment"),
            "docker-compose.yml": ("tools", "Docker")
        }
        
        # ãƒ•ã‚¡ã‚¤ãƒ«èµ°æŸ»
        processed_extensions = set()
        processed_configs = set()
        
        for file_path in project_path.rglob("*"):
            if file_path.is_file():
                # æ‹¡å¼µå­ãƒã‚§ãƒƒã‚¯
                suffix = file_path.suffix.lower()
                if suffix in file_extensions and suffix not in processed_extensions:
                    category, tech_name = file_extensions[suffix]
                    tech_stack[category].append(tech_name)
                    processed_extensions.add(suffix)
                
                # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯
                filename = file_path.name
                if filename in config_files and filename not in processed_configs:
                    category, tech_name = config_files[filename]
                    tech_stack[category].append(tech_name)
                    processed_configs.add(filename)
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæ¤œå‡º
        tech_stack["frameworks"] = self.detect_frameworks(project_path)
        
        print(f"ğŸ”§ æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯æ¤œå‡º: {dict((k, v) for k, v in tech_stack.items() if v)}")
        return tech_stack
    
    def detect_frameworks(self, project_path: Path) -> List[str]:
        """ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®æ¤œå‡º"""
        
        frameworks = []
        
        # composer.json ã‹ã‚‰PHPãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯æ¤œå‡º
        composer_file = project_path / "composer.json"
        if composer_file.exists():
            try:
                with open(composer_file, 'r', encoding='utf-8') as f:
                    composer_data = json.load(f)
                    
                require = composer_data.get("require", {})
                for package in require.keys():
                    if "laravel" in package.lower():
                        frameworks.append("Laravel")
                    elif "symfony" in package.lower():
                        frameworks.append("Symfony")
                    elif "codeigniter" in package.lower():
                        frameworks.append("CodeIgniter")
            except:
                pass
        
        # package.json ã‹ã‚‰JavaScriptãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯æ¤œå‡º
        package_file = project_path / "package.json"
        if package_file.exists():
            try:
                with open(package_file, 'r', encoding='utf-8') as f:
                    package_data = json.load(f)
                    
                dependencies = {**package_data.get("dependencies", {}), 
                              **package_data.get("devDependencies", {})}
                
                for package in dependencies.keys():
                    if package == "react":
                        frameworks.append("React")
                    elif package == "vue":
                        frameworks.append("Vue")
                    elif package == "angular" or package.startswith("@angular"):
                        frameworks.append("Angular")
            except:
                pass
        
        # FastAPI/Flaskæ¤œå‡ºï¼ˆãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‹ã‚‰ï¼‰
        if self.find_pattern_in_files(project_path, "from fastapi import"):
            frameworks.append("FastAPI")
        if self.find_pattern_in_files(project_path, "from flask import"):
            frameworks.append("Flask")
        
        # NAGANO3ç‹¬è‡ªã‚·ã‚¹ãƒ†ãƒ æ¤œå‡º
        if self.find_pattern_in_directory(project_path, "NAGANO3"):
            frameworks.append("NAGANO3 Custom System")
        
        return frameworks
    
    def analyze_file_contents(self, project_path: Path) -> Dict[str, Any]:
        """ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã®åˆ†æ"""
        
        content_analysis = {
            "data_actions": [],
            "api_endpoints": [],
            "database_operations": [],
            "security_features": [],
            "integration_points": []
        }
        
        # åˆ†æå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­
        target_extensions = [".php", ".html", ".js", ".py"]
        file_count = 0
        
        for file_path in project_path.rglob("*"):
            if (file_path.suffix.lower() in target_extensions and 
                file_path.is_file() and 
                file_count < 100):  # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ¶é™
                
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                        file_count += 1
                        
                    # data-actionå±æ€§ã®æ¤œå‡º
                    data_actions = re.findall(r'data-action="([^"]+)"', content)
                    content_analysis["data_actions"].extend(data_actions)
                    
                    # API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®æ¤œå‡º
                    api_patterns = [
                        r'@app\.(get|post|put|delete)\("([^"]+)"',  # FastAPI
                        r'Route::(get|post|put|delete)\("([^"]+)"',  # Laravel
                        r'app\.(get|post|put|delete)\("([^"]+)"'     # Express
                    ]
                    
                    for pattern in api_patterns:
                        matches = re.findall(pattern, content)
                        for match in matches:
                            endpoint = match[1] if len(match) > 1 else match[0]
                            content_analysis["api_endpoints"].append(endpoint)
                    
                    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ©Ÿèƒ½ã®æ¤œå‡º
                    security_patterns = [
                        "csrf_token", "session", "authentication", 
                        "authorization", "encrypt", "hash", "CSRF_TOKEN_SECRET"
                    ]
                    
                    for pattern in security_patterns:
                        if pattern.lower() in content.lower():
                            if pattern not in content_analysis["security_features"]:
                                content_analysis["security_features"].append(pattern)
                    
                except:
                    continue
        
        # é‡è¤‡é™¤å»
        for key in content_analysis:
            if isinstance(content_analysis[key], list):
                content_analysis[key] = list(set(content_analysis[key]))
        
        print(f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹åˆ†æå®Œäº†: {file_count}ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†")
        return content_analysis
    
    def auto_select_hooks(self, analysis_result: Dict[str, Any]) -> Dict[str, List[str]]:
        """åˆ†æçµæœã«åŸºã¥ãè‡ªå‹•Hooksé¸æŠ"""
        
        selected_hooks = {
            "universal": [],
            "category": [],
            "technology": [],
            "project": []
        }
        
        # Universal Hooksï¼ˆå¸¸ã«é¸æŠï¼‰
        selected_hooks["universal"] = [
            "security_validation_hooks",
            "infrastructure_check_hooks", 
            "quality_assurance_hooks"
        ]
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒ—åˆ¥é¸æŠ
        project_type = analysis_result["project_type"]["primary_type"]
        
        if project_type == "nagano3_kicho":
            selected_hooks["project"].extend([
                "nagano3_kicho_specific_hooks",
                "nagano3_phase_validation_hooks"
            ])
            selected_hooks["category"].extend([
                "web_application_hooks",
                "ui_intensive_hooks"
            ])
        elif project_type == "nagano3_generic":
            selected_hooks["project"].append("nagano3_generic_hooks")
        elif project_type == "api_service":
            selected_hooks["category"].append("api_development_hooks")
        
        # æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯åˆ¥é¸æŠ
        tech_stack = analysis_result["technology_stack"]
        
        if "PHP" in [item for sublist in tech_stack.values() for item in sublist]:
            selected_hooks["technology"].append("php_development_hooks")
        if "Python" in [item for sublist in tech_stack.values() for item in sublist]:
            selected_hooks["technology"].append("python_development_hooks")
        if "JavaScript" in [item for sublist in tech_stack.values() for item in sublist]:
            selected_hooks["technology"].append("javascript_development_hooks")
        
        # ç‰¹æ®Šè¦ä»¶ã«ã‚ˆã‚‹é¸æŠ
        content_analysis = analysis_result["content_analysis"]
        
        if len(content_analysis["data_actions"]) > 10:
            selected_hooks["category"].append("ui_intensive_hooks")
        if content_analysis["api_endpoints"]:
            selected_hooks["category"].append("api_development_hooks")
        
        print(f"ğŸ¯ é¸æŠã•ã‚ŒãŸHooks: {dict((k, v) for k, v in selected_hooks.items() if v)}")
        return selected_hooks
    
    def find_pattern_in_directory(self, project_path: Path, pattern: str) -> bool:
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã§ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢"""
        try:
            pattern_lower = pattern.lower()
            for item in project_path.rglob("*"):
                if pattern_lower in str(item).lower():
                    return True
            return False
        except:
            return False
    
    def find_pattern_in_files(self, project_path: Path, pattern: str) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã§ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢ï¼ˆé™å®šçš„ï¼‰"""
        try:
            search_count = 0
            for file_path in project_path.rglob("*.py"):
                if file_path.is_file() and search_count < 20:  # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ¶é™
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                        if pattern in content:
                            return True
                    search_count += 1
            return False
        except:
            return False
    
    def calculate_complexity_metrics(self, project_path: Path) -> Dict[str, int]:
        """è¤‡é›‘åº¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨ˆç®—"""
        
        metrics = {
            "total_files": 0,
            "code_files": 0,
            "php_files": 0,
            "js_files": 0,
            "py_files": 0,
            "data_actions_count": 0
        }
        
        code_extensions = [".php", ".js", ".py", ".html", ".css"]
        
        for file_path in project_path.rglob("*"):
            if file_path.is_file():
                metrics["total_files"] += 1
                
                if file_path.suffix.lower() in code_extensions:
                    metrics["code_files"] += 1
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ
                    if file_path.suffix.lower() == ".php":
                        metrics["php_files"] += 1
                    elif file_path.suffix.lower() == ".js":
                        metrics["js_files"] += 1
                    elif file_path.suffix.lower() == ".py":
                        metrics["py_files"] += 1
        
        print(f"ğŸ“Š è¤‡é›‘åº¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹: {metrics}")
        return metrics
    
    def detect_integration_needs(self, project_path: Path) -> List[str]:
        """çµ±åˆè¦ä»¶ã®æ¤œå‡º"""
        
        integrations = []
        
        # .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ¤œå‡º
        env_file = project_path / ".env"
        if env_file.exists():
            try:
                with open(env_file, 'r', encoding='utf-8') as f:
                    env_content = f.read()
                    
                integration_patterns = {
                    "MoneyForward": ["MF_"],
                    "OpenAI": ["OPENAI_", "CHATWORK_API"],
                    "AWS": ["AMAZON_", "AWS_"],
                    "Stripe": ["STRIPE_"],
                    "Shopify": ["SHOPIFY_"],
                    "GitHub": ["GITHUB_"]
                }
                
                for integration_name, patterns in integration_patterns.items():
                    for pattern in patterns:
                        if pattern in env_content:
                            integrations.append(integration_name)
                            break
                    
            except:
                pass
        
        print(f"ğŸ”— çµ±åˆè¦ä»¶æ¤œå‡º: {integrations}")
        return list(set(integrations))
    
    def extract_special_requirements(self, project_path: Path) -> List[str]:
        """ç‰¹æ®Šè¦ä»¶ã®æŠ½å‡º"""
        
        requirements = []
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æã‹ã‚‰ç‰¹æ®Šè¦ä»¶æ¤œå‡º
        if self.find_pattern_in_files(project_path, "websocket"):
            requirements.append("Real-time Communication")
        if self.find_pattern_in_files(project_path, "ai_learning"):
            requirements.append("AI Learning System")
        if self.find_pattern_in_directory(project_path, "kicho"):
            requirements.append("KICHO Specialized System")
            
        print(f"â­ ç‰¹æ®Šè¦ä»¶: {requirements}")
        return list(set(requirements))

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    
    # å¼•æ•°ã‹ã‚‰ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹å–å¾—
    project_path = sys.argv[1] if len(sys.argv) > 1 else "."
    
    print("ğŸ¤– å®Œå…¨è‡ªå‹•åŒ–Hooksã‚·ã‚¹ãƒ†ãƒ  - è‡ªå‹•åˆ¤å®šã‚¨ãƒ³ã‚¸ãƒ³")
    print("=" * 60)
    
    try:
        # åˆ†æå®Ÿè¡Œ
        classifier = HooksAutoClassifier()
        analysis = classifier.analyze_project_context(project_path)
        
        # Hooksé¸æŠ
        selected_hooks = classifier.auto_select_hooks(analysis)
        
        # çµæœä¿å­˜
        results = {
            "analysis": analysis,
            "selected_hooks": selected_hooks,
            "execution_timestamp": datetime.now().isoformat()
        }
        
        # çµæœãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        output_dir = Path("~/.claude/results").expanduser()
        output_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        result_file = output_dir / f"analysis_{timestamp}.json"
        
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print("\n" + "=" * 60)
        print("âœ… åˆ†æå®Œäº†")
        print(f"ğŸ“ çµæœä¿å­˜: {result_file}")
        print(f"ğŸ¯ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒ—: {analysis['project_type']['primary_type']}")
        print(f"ğŸ”§ ä¸»è¦æŠ€è¡“: {', '.join(analysis['technology_stack']['backend'] + analysis['technology_stack']['frontend'])}")
        print(f"ğŸ“Š è¤‡é›‘åº¦: {analysis['complexity_metrics']['code_files']}ãƒ•ã‚¡ã‚¤ãƒ«")
        print(f"ğŸª é¸æŠHooks: {sum(len(hooks) for hooks in selected_hooks.values())}å€‹")
        
        # æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—è¡¨ç¤º
        print("\nğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("1. Hooksåˆ†é¡ã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…")
        print("2. è‡ªå‹•å›ç­”ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å®Ÿè£…")
        print("3. å®Ÿéš›ã®Hookså®Ÿè£…ãƒ»çµ±åˆ")
        
        return True
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)

    # ==========================================
# ğŸ¤– AIæ‹¡å¼µæ©Ÿèƒ½ - 2025å¹´1æœˆè¿½åŠ 
# ==========================================

class AIEnhancedHooksClassifier(HooksAutoClassifier):
    """AIæ‹¡å¼µç‰ˆHooksè‡ªå‹•åˆ¤å®šã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, config_path: str = "~/.claude/settings.json"):
        super().__init__(config_path)
        self.ai_tools_config = {
            "deepseek": {"specialty": "code_generation"},
            "ollama": {"specialty": "text_processing"}, 
            "transformers": {"specialty": "custom_training"}
        }
        self.ai_enabled = self._check_ai_availability()
    
    def execute_ai_enhanced_analysis(self, development_context: Dict = None) -> Dict[str, Any]:
        """AIæ‹¡å¼µåˆ†æå®Ÿè¡Œ"""
        # æ—¢å­˜ã®åŸºæœ¬åˆ†æ
        basic_result = self.analyze_project_context(development_context or ".")
        
        # AIæ‹¡å¼µåˆ†æï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆã®ã¿ï¼‰
        if self.ai_enabled:
            ai_result = self._execute_comprehensive_ai_analysis(development_context)
            return self._merge_analysis_results(basic_result, ai_result)
        else:
            # AIæœªåˆ©ç”¨æ™‚ã¯æ—¢å­˜æ©Ÿèƒ½ã‚’ãã®ã¾ã¾è¿”ã™
            return basic_result
    
    def _execute_comprehensive_ai_analysis(self, context):
        """AIåˆ†æå®Ÿè¡Œï¼ˆpaste.txtã®æ©Ÿèƒ½ã‚’çµ±åˆï¼‰"""
        return {
            "ai_requirements_detected": self._detect_ai_requirements(context),
            "tool_availability": self._check_ai_tools(),
            "recommended_configuration": self._generate_ai_config(context),
            "ai_enhanced": True
        }
    
    def _check_ai_availability(self) -> bool:
        """AIæ©Ÿèƒ½åˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯"""
        try:
            # ç°¡æ˜“ãƒã‚§ãƒƒã‚¯
            import transformers
            return True
        except ImportError:
            return False