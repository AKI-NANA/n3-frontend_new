#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš› elojié€æ–™ãƒ‡ãƒ¼ã‚¿CSVç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ»æ¤œè¨¼ãƒ»åŒæœŸå‡¦ç†
"""

import pandas as pd
import sqlite3
import logging
import json
from typing import Dict, List, Optional, Tuple
from pathlib import Path
from datetime import datetime
import hashlib

class ElojiShippingDataManager:
    """elojié€æ–™ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, db_path: Path, upload_dir: Path):
        self.db_path = db_path
        self.upload_dir = Path(upload_dir)
        self.upload_dir.mkdir(exist_ok=True)
        
        # æœŸå¾…ã™ã‚‹CSVãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå®šç¾©
        self.expected_csv_columns = {
            'destination_country': str,      # ç™ºé€å…ˆå›½
            'destination_region': str,       # ç™ºé€å…ˆåœ°åŸŸ
            'weight_min': float,            # æœ€å°é‡é‡(kg)
            'weight_max': float,            # æœ€å¤§é‡é‡(kg)
            'service_type': str,            # ã‚µãƒ¼ãƒ“ã‚¹ã‚¿ã‚¤ãƒ—
            'cost_usd': float,              # é€æ–™(USD)
            'delivery_days_min': int,       # æœ€çŸ­é…é€æ—¥æ•°
            'delivery_days_max': int,       # æœ€é•·é…é€æ—¥æ•°
            'fuel_surcharge': float,        # ç‡ƒæ²¹ã‚µãƒ¼ãƒãƒ£ãƒ¼ã‚¸
            'last_updated': str             # æ›´æ–°æ—¥æ™‚
        }
        
        self._init_eloji_tables()
    
    def _init_eloji_tables(self):
        """elojié€æ–™ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«åˆæœŸåŒ–"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # elojié€æ–™ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS eloji_shipping_data (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        destination_country TEXT NOT NULL,
                        destination_region TEXT,
                        weight_min REAL NOT NULL,
                        weight_max REAL NOT NULL,
                        service_type TEXT NOT NULL,
                        cost_usd REAL NOT NULL,
                        delivery_days_min INTEGER,
                        delivery_days_max INTEGER,
                        fuel_surcharge REAL DEFAULT 0.0,
                        data_source TEXT DEFAULT 'eloji',
                        csv_file_hash TEXT,
                        imported_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        last_updated TIMESTAMP,
                        UNIQUE(destination_country, destination_region, weight_min, weight_max, service_type)
                    )
                """)
                
                # CSVå‡¦ç†å±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS csv_processing_history (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        filename TEXT NOT NULL,
                        file_hash TEXT NOT NULL,
                        file_size INTEGER,
                        total_rows INTEGER,
                        valid_rows INTEGER,
                        invalid_rows INTEGER,
                        processing_status TEXT,
                        error_details TEXT,
                        processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                conn.commit()
                logging.info("elojié€æ–™ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«åˆæœŸåŒ–å®Œäº†")
                
        except Exception as e:
            logging.error(f"elojié€æ–™ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def validate_csv_format(self, df: pd.DataFrame) -> Dict:
        """CSVå½¢å¼æ¤œè¨¼"""
        validation_results = {
            'is_valid': True,
            'errors': [],
            'warnings': [],
            'valid_rows': 0,
            'invalid_rows': 0
        }
        
        try:
            # å¿…é ˆã‚«ãƒ©ãƒ å­˜åœ¨ãƒã‚§ãƒƒã‚¯
            missing_columns = []
            for col in self.expected_csv_columns.keys():
                if col not in df.columns:
                    missing_columns.append(col)
            
            if missing_columns:
                validation_results['is_valid'] = False
                validation_results['errors'].append(f"å¿…é ˆã‚«ãƒ©ãƒ ä¸è¶³: {missing_columns}")
                return validation_results
            
            # ãƒ‡ãƒ¼ã‚¿å‹ãƒ»å€¤æ¤œè¨¼
            invalid_rows = []
            
            for index, row in df.iterrows():
                row_errors = []
                
                # æ•°å€¤é …ç›®ã®æ¤œè¨¼
                try:
                    if pd.isna(row['weight_min']) or pd.isna(row['weight_max']):
                        row_errors.append("é‡é‡ãŒç©ºã§ã™")
                    elif float(row['weight_min']) < 0 or float(row['weight_max']) < 0:
                        row_errors.append("é‡é‡ãŒè² ã®å€¤ã§ã™")
                    elif float(row['weight_min']) >= float(row['weight_max']):
                        row_errors.append("æœ€å°é‡é‡ >= æœ€å¤§é‡é‡ã§ã™")
                except (ValueError, TypeError):
                    row_errors.append("é‡é‡ã®å½¢å¼ãŒç„¡åŠ¹ã§ã™")
                
                try:
                    if pd.isna(row['cost_usd']) or float(row['cost_usd']) < 0:
                        row_errors.append("é€æ–™ãŒç„¡åŠ¹ã§ã™")
                except (ValueError, TypeError):
                    row_errors.append("é€æ–™ã®å½¢å¼ãŒç„¡åŠ¹ã§ã™")
                
                # æ–‡å­—åˆ—é …ç›®ã®æ¤œè¨¼
                if pd.isna(row['destination_country']) or not str(row['destination_country']).strip():
                    row_errors.append("ç™ºé€å…ˆå›½ãŒç©ºã§ã™")
                
                if pd.isna(row['service_type']) or not str(row['service_type']).strip():
                    row_errors.append("ã‚µãƒ¼ãƒ“ã‚¹ã‚¿ã‚¤ãƒ—ãŒç©ºã§ã™")
                
                if row_errors:
                    invalid_rows.append({
                        'row_number': index + 2,  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œè€ƒæ…®
                        'errors': row_errors
                    })
            
            validation_results['invalid_rows'] = len(invalid_rows)
            validation_results['valid_rows'] = len(df) - len(invalid_rows)
            
            if invalid_rows:
                validation_results['errors'].extend([
                    f"è¡Œ{row['row_number']}: {', '.join(row['errors'])}" 
                    for row in invalid_rows[:10]  # æœ€åˆã®10ä»¶ã®ã¿è¡¨ç¤º
                ])
                
                if len(invalid_rows) > 10:
                    validation_results['errors'].append(f"ä»– {len(invalid_rows) - 10} ä»¶ã®ã‚¨ãƒ©ãƒ¼è¡Œ")
            
            # è­¦å‘Šãƒã‚§ãƒƒã‚¯
            if validation_results['invalid_rows'] > 0:
                validation_results['warnings'].append(
                    f"{validation_results['invalid_rows']}è¡Œã«ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Šã¾ã™"
                )
            
            return validation_results
            
        except Exception as e:
            logging.error(f"CSVæ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            validation_results['is_valid'] = False
            validation_results['errors'].append(f"æ¤œè¨¼ä¸­ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return validation_results
    
    def calculate_file_hash(self, file_path: Path) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥è¨ˆç®—"""
        try:
            hasher = hashlib.md5()
            with open(file_path, 'rb') as f:
                buf = f.read()
                hasher.update(buf)
            return hasher.hexdigest()
        except Exception as e:
            logging.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    def process_csv_upload(self, file_path: Path, overwrite: bool = False) -> Dict:
        """CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†"""
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
            if not file_path.exists():
                return {
                    'success': False,
                    'error': 'ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'
                }
            
            # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±å–å¾—
            file_hash = self.calculate_file_hash(file_path)
            file_size = file_path.stat().st_size
            
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆoverwriteãŒFalseã®å ´åˆï¼‰
            if not overwrite:
                with sqlite3.connect(self.db_path) as conn:
                    cursor = conn.cursor()
                    cursor.execute("""
                        SELECT id, filename, processed_at 
                        FROM csv_processing_history 
                        WHERE file_hash = ? AND processing_status = 'success'
                    """, (file_hash,))
                    
                    existing = cursor.fetchone()
                    if existing:
                        return {
                            'success': False,
                            'error': f'åŒã˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ—¢ã«å‡¦ç†æ¸ˆã¿ã§ã™: {existing[1]} ({existing[2]})',
                            'duplicate': True
                        }
            
            # CSVèª­ã¿è¾¼ã¿
            try:
                df = pd.read_csv(file_path, encoding='utf-8')
            except UnicodeDecodeError:
                try:
                    df = pd.read_csv(file_path, encoding='shift-jis')
                except:
                    df = pd.read_csv(file_path, encoding='cp932')
            
            # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
            validation_result = self.validate_csv_format(df)
            
            # å‡¦ç†å±¥æ­´è¨˜éŒ²é–‹å§‹
            processing_id = self._record_processing_start(
                file_path.name, file_hash, file_size, len(df)
            )
            
            if not validation_result['is_valid']:
                # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•—
                self._record_processing_result(
                    processing_id, 'validation_failed', 
                    0, len(df), validation_result['errors']
                )
                
                return {
                    'success': False,
                    'validation_result': validation_result,
                    'processing_id': processing_id
                }
            
            # ãƒ‡ãƒ¼ã‚¿æ›´æ–°å‡¦ç†
            update_result = self._update_shipping_data(df, file_hash)
            
            # å‡¦ç†çµæœè¨˜éŒ²
            if update_result['success']:
                self._record_processing_result(
                    processing_id, 'success',
                    update_result['updated_count'], 
                    validation_result['invalid_rows']
                )
            else:
                self._record_processing_result(
                    processing_id, 'update_failed',
                    0, len(df), [update_result['error']]
                )
            
            return {
                'success': update_result['success'],
                'validation_result': validation_result,
                'update_result': update_result,
                'processing_id': processing_id
            }
            
        except Exception as e:
            logging.error(f"CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def _record_processing_start(self, filename: str, file_hash: str, 
                                file_size: int, total_rows: int) -> int:
        """å‡¦ç†é–‹å§‹è¨˜éŒ²"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    INSERT INTO csv_processing_history 
                    (filename, file_hash, file_size, total_rows, processing_status)
                    VALUES (?, ?, ?, ?, 'processing')
                """, (filename, file_hash, file_size, total_rows))
                
                processing_id = cursor.lastrowid
                conn.commit()
                return processing_id
                
        except Exception as e:
            logging.error(f"å‡¦ç†é–‹å§‹è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")
            return 0
    
    def _record_processing_result(self, processing_id: int, status: str, 
                                 valid_rows: int, invalid_rows: int, 
                                 errors: List[str] = None):
        """å‡¦ç†çµæœè¨˜éŒ²"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    UPDATE csv_processing_history 
                    SET processing_status = ?, valid_rows = ?, invalid_rows = ?, 
                        error_details = ?
                    WHERE id = ?
                """, (
                    status, valid_rows, invalid_rows,
                    json.dumps(errors) if errors else None,
                    processing_id
                ))
                conn.commit()
                
        except Exception as e:
            logging.error(f"å‡¦ç†çµæœè¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _update_shipping_data(self, df: pd.DataFrame, file_hash: str) -> Dict:
        """é€æ–™ãƒ‡ãƒ¼ã‚¿æ›´æ–°"""
        try:
            updated_count = 0
            
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                for _, row in df.iterrows():
                    try:
                        # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                        destination_country = str(row['destination_country']).strip()
                        destination_region = str(row.get('destination_region', '')).strip()
                        weight_min = float(row['weight_min'])
                        weight_max = float(row['weight_max'])
                        service_type = str(row['service_type']).strip()
                        cost_usd = float(row['cost_usd'])
                        delivery_days_min = int(row.get('delivery_days_min', 0))
                        delivery_days_max = int(row.get('delivery_days_max', 0))
                        fuel_surcharge = float(row.get('fuel_surcharge', 0.0))
                        
                        # UPSERTå®Ÿè¡Œ
                        cursor.execute("""
                            INSERT OR REPLACE INTO eloji_shipping_data 
                            (destination_country, destination_region, weight_min, weight_max,
                             service_type, cost_usd, delivery_days_min, delivery_days_max,
                             fuel_surcharge, csv_file_hash, last_updated)
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
                        """, (
                            destination_country, destination_region, weight_min, weight_max,
                            service_type, cost_usd, delivery_days_min, delivery_days_max,
                            fuel_surcharge, file_hash
                        ))
                        
                        updated_count += 1
                        
                    except Exception as e:
                        logging.warning(f"å€‹åˆ¥è¡Œæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
                        continue
                
                conn.commit()
            
            return {
                'success': True,
                'updated_count': updated_count
            }
            
        except Exception as e:
            logging.error(f"é€æ–™ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def get_processing_history(self, limit: int = 20) -> List[Dict]:
        """å‡¦ç†å±¥æ­´å–å¾—"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT filename, file_hash, file_size, total_rows, valid_rows, 
                           invalid_rows, processing_status, processed_at
                    FROM csv_processing_history 
                    ORDER BY processed_at DESC LIMIT ?
                """, (limit,))
                
                history = []
                for row in cursor.fetchall():
                    history.append({
                        'filename': row[0],
                        'file_hash': row[1],
                        'file_size': row[2],
                        'total_rows': row[3],
                        'valid_rows': row[4],
                        'invalid_rows': row[5],
                        'status': row[6],
                        'processed_at': row[7]
                    })
                
                return history
                
        except Exception as e:
            logging.error(f"å‡¦ç†å±¥æ­´å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def get_shipping_data(self, destination_country: str = None, 
                         service_type: str = None) -> List[Dict]:
        """é€æ–™ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                query = """
                    SELECT destination_country, destination_region, weight_min, weight_max,
                           service_type, cost_usd, delivery_days_min, delivery_days_max,
                           fuel_surcharge, last_updated
                    FROM eloji_shipping_data
                """
                params = []
                
                conditions = []
                if destination_country:
                    conditions.append("destination_country = ?")
                    params.append(destination_country)
                
                if service_type:
                    conditions.append("service_type = ?")
                    params.append(service_type)
                
                if conditions:
                    query += " WHERE " + " AND ".join(conditions)
                
                query += " ORDER BY destination_country, weight_min, service_type"
                
                cursor.execute(query, params)
                
                data = []
                for row in cursor.fetchall():
                    data.append({
                        'destination_country': row[0],
                        'destination_region': row[1],
                        'weight_min': row[2],
                        'weight_max': row[3],
                        'service_type': row[4],
                        'cost_usd': row[5],
                        'delivery_days_min': row[6],
                        'delivery_days_max': row[7],
                        'fuel_surcharge': row[8],
                        'last_updated': row[9]
                    })
                
                return data
                
        except Exception as e:
            logging.error(f"é€æ–™ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []
