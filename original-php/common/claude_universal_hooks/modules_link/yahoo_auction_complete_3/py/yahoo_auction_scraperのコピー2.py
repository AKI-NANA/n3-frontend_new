from playwright.sync_api import sync_playwright
import re
import json
import time
from typing import Dict

class YahooAuctionScraper:
    """N3çµ±åˆç‰ˆãƒ¤ãƒ•ã‚ªã‚¯ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼"""
    
    def __init__(self, debug_mode=True):
        self.debug_mode = debug_mode
        
    def _log_debug(self, message: str):
        if self.debug_mode:
            print(f"[DEBUG] {message}")
    
    def _extract_price(self, price_text: str) -> int:
        """ä¾¡æ ¼ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ•°å€¤ã‚’æŠ½å‡º"""
        if not price_text:
            return 0
        
        # ã€Œ20,000å††ï¼ˆç¨0å††ï¼‰ã€â†’ 20000
        yen_match = re.search(r'([\d,]+)å††', price_text)
        if yen_match:
            return int(yen_match.group(1).replace(',', ''))
        return 0
    
    def scrape(self, url: str) -> Dict:
        """ãƒ¡ã‚¤ãƒ³ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•°"""
        self._log_debug(f"ğŸš€ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹: {url}")
        
        try:
            with sync_playwright() as p:
                browser = p.chromium.launch(headless=False)
                page = browser.new_page()
                
                # ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿
                response = page.goto(url, timeout=30000)
                if response.status != 200:
                    return {'scrape_success': False, 'error': f'HTTP {response.status}'}
                
                page.wait_for_timeout(3000)
                
                # ãƒ‡ãƒ¼ã‚¿å–å¾—
                result = {
                    'scrape_success': True,
                    'url': url,
                    'scrape_timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
                }
                
                # ã‚¿ã‚¤ãƒˆãƒ«
                try:
                    title = page.locator('h1').first.text_content().strip()
                    result['title_jp'] = title
                    self._log_debug(f"âœ… ã‚¿ã‚¤ãƒˆãƒ«: {title[:50]}...")
                except Exception as e:
                    result['title_jp'] = f"å–å¾—å¤±æ•—: {e}"
                
                # ä¾¡æ ¼
                try:
                    price_text = page.locator('dd:has-text("å††")').first.text_content()
                    result['price_jpy'] = self._extract_price(price_text)
                    result['price_text'] = price_text
                    self._log_debug(f"âœ… ä¾¡æ ¼: {result['price_jpy']:,}å††")
                except Exception as e:
                    result['price_jpy'] = 0
                    result['price_text'] = f"å–å¾—å¤±æ•—: {e}"
                
                # èª¬æ˜ï¼ˆç°¡æ˜“ç‰ˆï¼‰
                try:
                    divs = page.locator('div').all()
                    result['description_jp'] = "èª¬æ˜ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
                    for div in divs[:30]:
                        text = div.text_content()
                        if text and len(text.strip()) > 100:
                            result['description_jp'] = text.strip()[:300]
                            break
                except Exception as e:
                    result['description_jp'] = f"å–å¾—å¤±æ•—: {e}"
                
                # ç”»åƒ
                try:
                    images = []
                    imgs = page.locator('img').all()
                    for img in imgs:
                        src = img.get_attribute('src')
                        if src and ('auction' in src or 'yahoo' in src):
                            images.append(src)
                    result['image_urls'] = '|'.join(images[:10])
                    self._log_debug(f"âœ… ç”»åƒ: {len(images)}å€‹")
                except Exception as e:
                    result['image_urls'] = ""
                    self._log_debug(f"âŒ ç”»åƒå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                
                # å•†å“çŠ¶æ…‹
                try:
                    condition_keywords = ['æ–°å“', 'ä¸­å¤', 'å‚·ã‚„æ±šã‚Œã‚ã‚Š', 'æœªä½¿ç”¨']
                    result['condition'] = "çŠ¶æ…‹ä¸æ˜"
                    
                    for keyword in condition_keywords:
                        if page.locator(f'*:has-text("{keyword}")').count() > 0:
                            result['condition'] = keyword
                            break
                except Exception:
                    result['condition'] = "çŠ¶æ…‹ä¸æ˜"
                
                # å•†å“IDæŠ½å‡º
                result['item_id'] = url.split('/')[-1].split('?')[0]
                
                self._log_debug("â¸ï¸ çµæœç¢ºèªã®ãŸã‚3ç§’è¡¨ç¤º...")
                page.wait_for_timeout(3000)
                
                browser.close()
                
                # çµæœãƒ­ã‚°å‡ºåŠ›
                self._log_debug("ğŸ“Š å–å¾—çµæœ:")
                self._log_debug(f"  ã‚¿ã‚¤ãƒˆãƒ«: {result.get('title_jp', 'N/A')[:50]}...")
                self._log_debug(f"  ä¾¡æ ¼: {result.get('price_jpy', 0):,}å††")
                self._log_debug(f"  èª¬æ˜: {result.get('description_jp', 'N/A')[:50]}...")
                self._log_debug(f"  ç”»åƒ: {len(result.get('image_urls', '').split('|'))}å€‹")
                
                return result
                
        except Exception as e:
            self._log_debug(f"âŒ è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'scrape_success': False,
                'error': str(e),
                'url': url,
                'scrape_timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
            }

def scrape_yahoo_auction(url, debug=True):
    """
    N3ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰å‘¼ã³å‡ºã•ã‚Œã‚‹é–¢æ•°
    """
    scraper = YahooAuctionScraper(debug_mode=debug)
    return scraper.scrape(url)

def test_scraper():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œç”¨"""
    print("=" * 60)
    print("ğŸ§ª N3çµ±åˆç‰ˆãƒ¤ãƒ•ã‚ªã‚¯ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    test_url = "https://auctions.yahoo.co.jp/jp/auction/p1198293948"
    result = scrape_yahoo_auction(test_url)
    
    print("\n" + "=" * 60)
    print("ğŸ“Š æœ€çµ‚çµæœ")
    print("=" * 60)
    
    if result and result.get('scrape_success'):
        print("âœ… ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æˆåŠŸ!")
        print(f"ğŸ“‹ ã‚¿ã‚¤ãƒˆãƒ«: {result['title_jp']}")
        print(f"ğŸ’° ä¾¡æ ¼: {result['price_jpy']:,}å††")
        print(f"ğŸ“ èª¬æ˜: {result['description_jp'][:100]}...")
        print(f"ğŸ–¼ï¸ ç”»åƒ: {len(result['image_urls'].split('|')) if result['image_urls'] else 0}å€‹")
        print(f"ğŸ·ï¸ çŠ¶æ…‹: {result['condition']}")
        print(f"ğŸ†” å•†å“ID: {result['item_id']}")
        
        # JSONå‡ºåŠ›
        print(f"\nğŸ“„ JSONå‡ºåŠ›:")
        print(json.dumps(result, ensure_ascii=False, indent=2))
        
    else:
        print("âŒ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¤±æ•—")
        if result:
            print(f"ã‚¨ãƒ©ãƒ¼: {result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")

if __name__ == "__main__":
    test_scraper()
