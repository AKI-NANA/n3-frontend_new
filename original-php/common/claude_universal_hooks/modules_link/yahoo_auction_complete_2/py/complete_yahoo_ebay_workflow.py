#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¯ ãƒ¤ãƒ•ã‚ªã‚¯â†’eBayå®Œå…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ï¼ˆãƒ‡ãƒ¼ã‚¿ç·¨é›†æ©Ÿèƒ½è¿½åŠ ç‰ˆï¼‰
å•é¡Œè§£æ±ºï¼šæ­£ç¢ºãªãƒ‡ãƒ¼ã‚¿å–å¾—ã€ç”»åƒURLä¿®æ­£ã€å•†å“æƒ…å ±ç²¾åº¦å‘ä¸Š
"""

from playwright.sync_api import sync_playwright
import pandas as pd
import re
import json
import time
import uuid
import os
from datetime import datetime
from pathlib import Path
import requests

class CompleteYahooEbayWorkflow:
    def __init__(self, data_dir="yahoo_ebay_data"):
        """å®Œå…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)
        
        self.csv_path = self.data_dir / "scraped_products.csv"
        self.log_path = self.data_dir / "workflow_log.txt"
        
        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
        if not self.log_path.exists():
            with open(self.log_path, 'w', encoding='utf-8') as f:
                f.write("--- ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ­ã‚°é–‹å§‹ ---\n")
        
        print(f"âœ… ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼åˆæœŸåŒ–å®Œäº†: {self.data_dir}")
    
    def log(self, message):
        """ãƒ­ã‚°è¨˜éŒ²"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        log_entry = f"[{timestamp}] {message}\n"
        
        with open(self.log_path, 'a', encoding='utf-8') as f:
            f.write(log_entry)
        
        print(f"ğŸ“ {log_entry.strip()}")

    def scrape_yahoo_auction(self, url):
        """ãƒ¤ãƒ•ã‚ªã‚¯ã®å•†å“æƒ…å ±ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°"""
        try:
            with sync_playwright() as p:
                browser = p.chromium.launch()
                page = browser.new_page()
                page.goto(url, wait_until='domcontentloaded')

                title_jp = page.locator('.ProductTitle__text').text_content().strip()
                
                price_element = page.locator('.ProductPrice dd')
                if not price_element.is_visible():
                    price_element = page.locator('.Price__value')
                
                price_text = price_element.text_content().replace('å††', '').replace(',', '').strip()
                price_jpy = int(re.sub(r'[^0-9]', '', price_text))
                
                description_jp = page.locator('.ProductDescription__body').text_content().strip()
                
                image_elements = page.locator('.ProductImage__image')
                image_urls = '|'.join([img.get_attribute('src') for img in image_elements.all() if img.get_attribute('src')])
                
                condition_jp = page.locator('.ProductDetail__body').text_content().strip()
                
                item_id = url.split('/')[-1].split('?')[0]

                browser.close()

                return {
                    'url': url,
                    'title_jp': title_jp,
                    'price_jpy': price_jpy,
                    'description_jp': description_jp,
                    'image_urls': image_urls,
                    'condition': condition_jp,
                    'item_id': item_id
                }
        except Exception as e:
            self.log(f"ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def get_all_products(self):
        """CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å…¨ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€ãƒªã‚¹ãƒˆå½¢å¼ã§è¿”ã—ã¾ã™ã€‚"""
        if not self.csv_path.exists():
            self.log("ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ–°è¦ä½œæˆã—ã¾ã™ã€‚")
            df = pd.DataFrame(columns=[
                'product_id', 'scrape_timestamp', 'yahoo_url', 'title_jp', 'price_jpy', 'description_jp', 'image_urls', 
                'seller_info', 'category_jp', 'title_en', 'description_en', 'ebay_category_id', 'ebay_price_usd', 
                'shipping_cost_usd', 'stock_quantity', 'status', 'ebay_item_id', 'last_stock_check', 
                'scrape_success', 'ebay_list_success', 'errors'
            ])
            df.to_csv(self.csv_path, index=False, encoding='utf-8')
            return []
        
        try:
            df = pd.read_csv(self.csv_path, encoding='utf-8')
            # å…¨ã¦ã®NaNå€¤ã‚’ç©ºæ–‡å­—åˆ—ã«å¤‰æ›
            df = df.fillna('')
            # product_idã‚’æ–‡å­—åˆ—ã¨ã—ã¦æ‰±ã†
            df['product_id'] = df['product_id'].astype(str)
            return df.to_dict('records')
        except Exception as e:
            self.log(f"CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def save_products(self, products_data):
        """JSONå½¢å¼ã®è£½å“ãƒ‡ãƒ¼ã‚¿ã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ãƒ»æ›´æ–°ã—ã¾ã™ã€‚"""
        if not self.csv_path.exists():
            self.log("ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return False

        try:
            # æ—¢å­˜ã®CSVã‚’èª­ã¿è¾¼ã‚€
            df = pd.read_csv(self.csv_path, encoding='utf-8', dtype={'product_id': str})
            
            # å—ã‘å–ã£ãŸãƒ‡ãƒ¼ã‚¿ã‚’DataFrameã«å¤‰æ›
            new_df = pd.DataFrame(products_data)
            new_df['product_id'] = new_df['product_id'].astype(str)
            
            # product_idã‚’ã‚­ãƒ¼ã¨ã—ã¦æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¨ãƒãƒ¼ã‚¸ãƒ»æ›´æ–°
            df.set_index('product_id', inplace=True)
            new_df.set_index('product_id', inplace=True)
            
            # ç·¨é›†ã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã¿æ›´æ–°
            for col in new_df.columns:
                df.update(new_df[col])
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦ä¿å­˜
            df.reset_index(inplace=True)
            df.to_csv(self.csv_path, index=False, encoding='utf-8')
            self.log(f"âœ… {len(products_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ãŒä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")
            return True
        except Exception as e:
            self.log(f"ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def get_workflow_status(self):
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çŠ¶æ…‹å–å¾—"""
        status = {
            'scraped': 0,
            'edited': 0,
            'listed': 0,
            'sold_out': 0,
            'error': 0,
            'total': 0
        }
        
        if self.csv_path.exists():
            try:
                df = pd.read_csv(self.csv_path, encoding='utf-8')
                status['total'] = len(df)
                
                for status_type in ['scraped', 'edited', 'listed', 'sold_out', 'error']:
                    status[status_type] = len(df[df.get('status', '') == status_type])
            except Exception as e:
                self.log(f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        
        return status