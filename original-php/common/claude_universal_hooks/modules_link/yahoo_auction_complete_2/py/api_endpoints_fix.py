# ğŸ”§ Python APIã‚µãƒ¼ãƒãƒ¼ä¿®æ­£ç‰ˆ
# workflow_api_server_complete.py ã«ä»¥ä¸‹ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’è¿½åŠ 

@app.route('/system_status', methods=['GET'])
def system_status_endpoint():
    """PHPå´ã‹ã‚‰å‘¼ã³å‡ºã•ã‚Œã‚‹çµ±è¨ˆæƒ…å ±å–å¾—ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        if not workflow:
            return jsonify({
                'success': False,
                'error': 'ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚·ã‚¹ãƒ†ãƒ æœªåˆæœŸåŒ–',
                'stats': {
                    'total': 0,
                    'scraped': 0,
                    'edited': 0,
                    'listed': 0,
                    'today_scraped': 0,
                    'error': 0
                },
                'profit_stats': {
                    'total_profit': 0,
                    'avg_margin': 0,
                    'max_margin': 0
                }
            })
        
        # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çŠ¶æ…‹å–å¾—
        workflow_status = workflow.get_workflow_status()
        
        # CSVå­˜åœ¨ç¢ºèªã¨ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ
        stats = {
            'total': workflow_status.get('total', 0),
            'scraped': workflow_status.get('scraped', 0),
            'edited': workflow_status.get('edited', 0),
            'listed': workflow_status.get('listed', 0),
            'today_scraped': 0,
            'error': workflow_status.get('error', 0)
        }
        
        # ä»Šæ—¥ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        if workflow.csv_path.exists():
            try:
                df = pd.read_csv(workflow.csv_path, encoding='utf-8')
                today = datetime.now().strftime('%Y-%m-%d')
                today_data = df[df['scrape_timestamp'].str.contains(today, na=False)]
                stats['today_scraped'] = len(today_data)
            except Exception as e:
                print(f"ä»Šæ—¥ã®çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        
        # åˆ©ç›Šçµ±è¨ˆï¼ˆåŸºæœ¬å€¤ï¼‰
        profit_stats = {
            'total_profit': stats['total'] * 10,  # ä»®ã®è¨ˆç®—
            'avg_margin': 15.5,
            'max_margin': 45.0
        }
        
        log_request('system_status', True)
        
        return jsonify({
            'success': True,
            'stats': stats,
            'profit_stats': profit_stats,
            'system_info': {
                'server_start_time': system_status['server_start_time'],
                'total_requests': system_status['total_requests'],
                'successful_requests': system_status['successful_requests'],
                'failed_requests': system_status['failed_requests'],
                'workflow_initialized': workflow is not None
            }
        })
        
    except Exception as e:
        log_request('system_status', False, e)
        return jsonify({
            'success': False,
            'error': str(e),
            'stats': {'total': 0, 'scraped': 0, 'edited': 0, 'listed': 0, 'today_scraped': 0, 'error': 0},
            'profit_stats': {'total_profit': 0, 'avg_margin': 0, 'max_margin': 0}
        }), 500

@app.route('/search_data', methods=['POST'])
def search_data():
    """PHPå´ã‹ã‚‰å‘¼ã³å‡ºã•ã‚Œã‚‹æ¤œç´¢æ©Ÿèƒ½"""
    try:
        if not workflow or not workflow.csv_path.exists():
            return jsonify({
                'success': False,
                'error': 'ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“',
                'data': [],
                'count': 0
            })
        
        data = request.get_json() or {}
        query = data.get('query', '').strip()
        status_filter = data.get('status_filter', '')
        date_filter = data.get('date_filter', '')
        
        # CSVãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        df = pd.read_csv(workflow.csv_path, encoding='utf-8')
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç†
        filtered_df = df.copy()
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
        if query:
            mask = (
                df['title_jp'].str.contains(query, case=False, na=False) |
                df['description_jp'].str.contains(query, case=False, na=False) |
                df['product_id'].str.contains(query, case=False, na=False)
            )
            filtered_df = filtered_df[mask]
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ•ã‚£ãƒ«ã‚¿
        if status_filter:
            filtered_df = filtered_df[filtered_df['status'] == status_filter]
        
        # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿
        if date_filter:
            today = datetime.now().strftime('%Y-%m-%d')
            if date_filter == 'today':
                filtered_df = filtered_df[filtered_df['scrape_timestamp'].str.contains(today, na=False)]
            elif date_filter == 'week':
                week_ago = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')
                filtered_df = filtered_df[filtered_df['scrape_timestamp'] >= week_ago]
            elif date_filter == 'month':
                month_ago = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
                filtered_df = filtered_df[filtered_df['scrape_timestamp'] >= month_ago]
        
        # çµæœã‚’è¾æ›¸å½¢å¼ã«å¤‰æ›
        results = filtered_df.head(100).to_dict('records')  # æœ€å¤§100ä»¶
        
        log_request('search_data', True)
        
        return jsonify({
            'success': True,
            'data': results,
            'count': len(results),
            'total_count': len(filtered_df)
        })
        
    except Exception as e:
        log_request('search_data', False, e)
        return jsonify({
            'success': False,
            'error': str(e),
            'data': [],
            'count': 0
        }), 500
