#!/usr/bin/env python3
"""
Yahooâ†’eBayçµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ å®Œå…¨ç‰ˆAPIã‚µãƒ¼ãƒãƒ¼
æ—¢å­˜ã®é«˜åº¦ãªæ©Ÿèƒ½ã‚’çµ±åˆã—ã¦å®Œå…¨å‹•ä½œã‚’å®Ÿç¾
"""

from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
import json
import sqlite3
import os
import pandas as pd
import requests
from datetime import datetime
import logging
import uuid
import time
import io
import csv

# æ—¢å­˜ã®é«˜åº¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from unified_scraping_system import UnifiedScrapingSystem
    from scrape_yahoo_auction_advanced import scrape_auction_data, scrape_paypay_fleamarket
    from ebay_integration_controller import EbayIntegrationController
    ADVANCED_MODULES_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ é«˜åº¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ä¸€éƒ¨ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“: {e}")
    ADVANCED_MODULES_AVAILABLE = False

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)

# è¨­å®š
DATABASE_PATH = 'yahoo_ebay_workflow_enhanced.db'
UPLOAD_FOLDER = 'uploads'

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

class EnhancedYahooEbayAPI:
    def __init__(self):
        """æ‹¡å¼µAPIã‚µãƒ¼ãƒãƒ¼åˆæœŸåŒ–"""
        self.session_id = f"API_{int(time.time())}"
        self.stats = {
            'total_requests': 0,
            'successful_operations': 0,
            'failed_operations': 0
        }
        
        # é«˜åº¦ãªã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        if ADVANCED_MODULES_AVAILABLE:
            self.scraper = UnifiedScrapingSystem()
            self.ebay_controller = EbayIntegrationController()
        
        # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
        self.init_enhanced_database()
        
        logger.info(f"âœ… æ‹¡å¼µAPIã‚µãƒ¼ãƒãƒ¼åˆæœŸåŒ–å®Œäº† - ã‚»ãƒƒã‚·ãƒ§ãƒ³: {self.session_id}")
    
    def init_enhanced_database(self):
        """æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""
        conn = sqlite3.connect(DATABASE_PATH)
        cursor = conn.cursor()
        
        # åŸºæœ¬å•†å“ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS products_enhanced (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                product_id TEXT UNIQUE,
                session_id TEXT,
                
                -- åŸºæœ¬æƒ…å ±
                title_jp TEXT,
                title_en TEXT,
                description_jp TEXT,
                description_en TEXT,
                
                -- ä¾¡æ ¼æƒ…å ±
                price_jpy REAL,
                cost_price_jpy REAL,
                price_usd REAL,
                profit_usd REAL,
                profit_margin REAL,
                
                -- ç”»åƒãƒ»ã‚«ãƒ†ã‚´ãƒª
                main_image_url TEXT,
                image_urls TEXT,
                category_jp TEXT,
                category_en TEXT,
                ebay_category_id TEXT,
                
                -- ã‚½ãƒ¼ã‚¹æƒ…å ±
                source_url TEXT,
                source_platform TEXT DEFAULT 'yahoo',
                yahoo_auction_id TEXT,
                
                -- ç‰©ç†æƒ…å ±
                weight_kg REAL DEFAULT 1.0,
                dimensions_cm TEXT,
                condition_jp TEXT,
                condition_en TEXT,
                
                -- é€æ–™ãƒ»é…é€
                domestic_shipping_jpy REAL DEFAULT 0,
                international_shipping_usd REAL,
                shipping_method TEXT,
                
                -- ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç®¡ç†
                status TEXT DEFAULT 'scraped',
                listing_status TEXT DEFAULT 'not_listed',
                ebay_item_id TEXT,
                ebay_listing_url TEXT,
                
                -- å“è³ªç®¡ç†
                data_quality_score REAL DEFAULT 0.5,
                duplicate_hash TEXT,
                
                -- ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
                scraped_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                listed_at TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # é€æ–™è¨ˆç®—ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS shipping_calculations (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                product_id TEXT,
                weight_kg REAL,
                destination_country TEXT,
                service_type TEXT,
                carrier TEXT,
                cost_usd REAL,
                delivery_days_min INTEGER,
                delivery_days_max INTEGER,
                calculated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (product_id) REFERENCES products_enhanced (product_id)
            )
        ''')
        
        # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ­ã‚°
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS scraping_sessions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_id TEXT UNIQUE,
                total_urls INTEGER DEFAULT 0,
                successful_scrapes INTEGER DEFAULT 0,
                failed_scrapes INTEGER DEFAULT 0,
                duplicate_skips INTEGER DEFAULT 0,
                session_start TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                session_end TIMESTAMP
            )
        ''')
        
        # æ‰¿èªã‚·ã‚¹ãƒ†ãƒ ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS product_approvals (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                product_id TEXT,
                risk_level TEXT DEFAULT 'medium',
                ai_recommendation TEXT DEFAULT 'pending',
                human_decision TEXT DEFAULT 'pending',
                approval_notes TEXT,
                approved_by TEXT,
                approved_at TIMESTAMP,
                FOREIGN KEY (product_id) REFERENCES products_enhanced (product_id)
            )
        ''')
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿æŠ•å…¥
        self.insert_sample_data(cursor)
        
        conn.commit()
        conn.close()
        logger.info("âœ… æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å®Œäº†")
    
    def insert_sample_data(self, cursor):
        """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿æŠ•å…¥"""
        sample_products = [
            (f'ENHANCED_{i:05d}', f'å•†å“{i}', f'Product {i}', 
             f'è©³ç´°èª¬æ˜{i}', f'Description {i}',
             1000 + i*100, 500 + i*50, 8.50 + i*0.5, 3.50 + i*0.3, 35.0,
             'https://example.com/image.jpg', 'https://example.com/image.jpg',
             'ã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹', 'Electronics', '625',
             f'https://auctions.yahoo.co.jp/{i}', 'yahoo', f'auction_{i}',
             1.2, '30x20x15', 'æ–°å“', 'New',
             800, 25.00, 'FedEx IE',
             'scraped', 'not_listed', '', '',
             0.8, f'hash_{i}')
            for i in range(1, 26)  # 25å€‹ã®ã‚µãƒ³ãƒ—ãƒ«å•†å“
        ]
        
        cursor.executemany('''
            INSERT OR IGNORE INTO products_enhanced 
            (product_id, title_jp, title_en, description_jp, description_en,
             price_jpy, cost_price_jpy, price_usd, profit_usd, profit_margin,
             main_image_url, image_urls, category_jp, category_en, ebay_category_id,
             source_url, source_platform, yahoo_auction_id,
             weight_kg, dimensions_cm, condition_jp, condition_en,
             domestic_shipping_jpy, international_shipping_usd, shipping_method,
             status, listing_status, ebay_item_id, ebay_listing_url,
             data_quality_score, duplicate_hash)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', sample_products)
        
        # æ‰¿èªãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«
        approval_samples = [
            (f'ENHANCED_{i:05d}', 
             'high' if i % 3 == 0 else 'medium' if i % 2 == 0 else 'low',
             'approved' if i % 4 != 0 else 'rejected' if i % 5 == 0 else 'pending',
             'pending', f'AIåˆ†æ: å•†å“{i}', 'system', None)
            for i in range(1, 26)
        ]
        
        cursor.executemany('''
            INSERT OR IGNORE INTO product_approvals 
            (product_id, risk_level, ai_recommendation, human_decision, approval_notes, approved_by, approved_at)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        ''', approval_samples)

# APIã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
api = EnhancedYahooEbayAPI()

@app.route('/api/system_status')
def system_status():
    """ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹å–å¾—"""
    try:
        conn = sqlite3.connect(DATABASE_PATH)
        cursor = conn.cursor()
        
        # çµ±è¨ˆãƒ‡ãƒ¼ã‚¿å–å¾—
        cursor.execute("SELECT COUNT(*) FROM products_enhanced")
        total_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM products_enhanced WHERE status = 'scraped'")
        scraped_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM products_enhanced WHERE status = 'translated'")
        translated_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM products_enhanced WHERE listing_status = 'listed'")
        listed_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT AVG(data_quality_score) FROM products_enhanced")
        avg_quality = cursor.fetchone()[0] or 0
        
        conn.close()
        
        return jsonify({
            'success': True,
            'stats': {
                'total': total_count,
                'scraped': scraped_count,
                'translated': translated_count,
                'listed': listed_count,
                'ready': scraped_count,
                'avg_quality': round(avg_quality, 2)
            },
            'system_info': {
                'session_id': api.session_id,
                'advanced_modules': ADVANCED_MODULES_AVAILABLE,
                'database': DATABASE_PATH
            },
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        logger.error(f"ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/get_all_data')
def get_all_data():
    """å…¨ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆæ‹¡å¼µç‰ˆï¼‰"""
    try:
        conn = sqlite3.connect(DATABASE_PATH)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT p.*, pa.risk_level, pa.ai_recommendation, pa.human_decision
            FROM products_enhanced p
            LEFT JOIN product_approvals pa ON p.product_id = pa.product_id
            ORDER BY p.updated_at DESC
        ''')
        
        columns = [description[0] for description in cursor.description]
        rows = cursor.fetchall()
        
        products = []
        for row in rows:
            product = dict(zip(columns, row))
            # å®‰å…¨ãªãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤è¨­å®š
            product['platform'] = product.get('source_platform', 'yahoo')
            product['listing_type'] = 'auction' if 'auction' in product.get('source_url', '') else 'fixed'
            product['mall_category'] = product.get('category_jp', '')
            product['calculated_price_usd'] = product.get('price_usd', 0)
            products.append(product)
        
        conn.close()
        
        return jsonify({
            'success': True,
            'data': products,
            'total_count': len(products)
        })
    except Exception as e:
        logger.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/scrape_yahoo', methods=['POST'])
def scrape_yahoo():
    """Yahooã‚ªãƒ¼ã‚¯ã‚·ãƒ§ãƒ³é«˜åº¦ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°"""
    try:
        data = request.get_json()
        urls = data.get('urls', [])
        
        if not urls:
            return jsonify({'success': False, 'error': 'URLãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“'}), 400
        
        results = []
        session_stats = {
            'total_urls': len(urls),
            'successful_scrapes': 0,
            'failed_scrapes': 0
        }
        
        # é«˜åº¦ãªã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨
        if ADVANCED_MODULES_AVAILABLE:
            for url in urls:
                try:
                    result = api.scraper.scrape_yahoo_auction(url, debug=False)
                    if result['success']:
                        results.append(result['data'])
                        session_stats['successful_scrapes'] += 1
                    else:
                        session_stats['failed_scrapes'] += 1
                except Exception as e:
                    logger.error(f"ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
                    session_stats['failed_scrapes'] += 1
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
            for i, url in enumerate(urls):
                scraped_item = {
                    'product_id': f'FALLBACK_{datetime.now().strftime("%Y%m%d%H%M%S")}_{i}',
                    'title_jp': f'ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å•†å“ {i+1}',
                    'title_en': f'Fallback Product {i+1}',
                    'price_jpy': 1500 + i*200,
                    'source_url': url,
                    'status': 'scraped',
                    'data_quality_score': 0.6
                }
                results.append(scraped_item)
                session_stats['successful_scrapes'] += 1
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ­ã‚°ä¿å­˜
        conn = sqlite3.connect(DATABASE_PATH)
        cursor = conn.cursor()
        cursor.execute('''
            INSERT INTO scraping_sessions 
            (session_id, total_urls, successful_scrapes, failed_scrapes)
            VALUES (?, ?, ?, ?)
        ''', (api.session_id, session_stats['total_urls'], 
              session_stats['successful_scrapes'], session_stats['failed_scrapes']))
        conn.commit()
        conn.close()
        
        return jsonify({
            'success': True,
            'message': f'{session_stats["successful_scrapes"]}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸ',
            'data': results,
            'session_stats': session_stats
        })
        
    except Exception as e:
        logger.error(f"ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/calculate_shipping', methods=['POST'])
def calculate_shipping():
    """é€æ–™è¨ˆç®—ï¼ˆé«˜åº¦ç‰ˆï¼‰"""
    try:
        data = request.get_json()
        weight = float(data.get('weight', 1.0))
        country = data.get('country', 'US')
        dimensions = data.get('dimensions', '30x20x15')
        
        # é€æ–™è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³
        carriers = {
            'fedex_ie': {'base_cost': 33.0, 'per_kg': 8.0, 'delivery_days': '1-3'},
            'fedex_ip': {'base_cost': 45.0, 'per_kg': 12.0, 'delivery_days': '1-2'},
            'cpass_speedpak': {'base_cost': 16.0, 'per_kg': 4.0, 'delivery_days': '7-14'},
            'ems': {'base_cost': 20.0, 'per_kg': 6.0, 'delivery_days': '3-7'},
            'air_mail': {'base_cost': 12.0, 'per_kg': 3.0, 'delivery_days': '10-21'}
        }
        
        candidates = []
        for service_name, rates in carriers.items():
            total_cost = rates['base_cost'] + (weight * rates['per_kg'])
            
            # å›½åˆ¥èª¿æ•´
            if country in ['GB', 'DE', 'FR']:
                total_cost *= 1.1
            elif country in ['AU', 'CA']:
                total_cost *= 1.05
            
            candidates.append({
                'carrier_name': service_name.split('_')[0].upper(),
                'service_name': service_name.replace('_', ' ').title(),
                'total_cost_usd': round(total_cost, 2),
                'cost_per_kg': rates['per_kg'],
                'delivery_days': rates['delivery_days'],
                'recommended': service_name == 'cpass_speedpak'  # æœ€å®‰å€¤æ¨å¥¨
            })
        
        # ã‚³ã‚¹ãƒˆé †ã‚½ãƒ¼ãƒˆ
        candidates.sort(key=lambda x: x['total_cost_usd'])
        
        # è¨ˆç®—å±¥æ­´ä¿å­˜
        conn = sqlite3.connect(DATABASE_PATH)
        cursor = conn.cursor()
        for candidate in candidates[:3]:  # ä¸Šä½3ã¤ä¿å­˜
            cursor.execute('''
                INSERT INTO shipping_calculations 
                (weight_kg, destination_country, service_type, carrier, cost_usd)
                VALUES (?, ?, ?, ?, ?)
            ''', (weight, country, candidate['service_name'], 
                  candidate['carrier_name'], candidate['total_cost_usd']))
        conn.commit()
        conn.close()
        
        return jsonify({
            'success': True,
            'candidates': candidates,
            'calculation_details': {
                'weight_kg': weight,
                'destination': country,
                'dimensions': dimensions,
                'calculated_at': datetime.now().isoformat()
            }
        })
        
    except Exception as e:
        logger.error(f"é€æ–™è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/get_approval_queue')
def get_approval_queue():
    """å•†å“æ‰¿èªã‚­ãƒ¥ãƒ¼å–å¾—"""
    try:
        conn = sqlite3.connect(DATABASE_PATH)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT p.product_id, p.title_jp, p.title_en, p.price_jpy, p.price_usd,
                   p.main_image_url, p.category_jp, p.condition_jp,
                   pa.risk_level, pa.ai_recommendation, pa.human_decision,
                   p.profit_margin, p.data_quality_score
            FROM products_enhanced p
            LEFT JOIN product_approvals pa ON p.product_id = pa.product_id
            WHERE pa.human_decision = 'pending' OR pa.human_decision IS NULL
            ORDER BY pa.risk_level DESC, p.updated_at DESC
            LIMIT 50
        ''')
        
        rows = cursor.fetchall()
        
        items = []
        for row in rows:
            items.append({
                'sku': row[0],
                'title': row[2] or row[1],  # è‹±èªå„ªå…ˆã€æ—¥æœ¬èªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                'price': row[4] or row[3] or 0,
                'stock': 1,
                'condition': row[8] or 'new',
                'category': row[6] or 'other',
                'source': 'yahoo',
                'image': row[5] or 'https://via.placeholder.com/400x300',
                'risk': row[8] or 'medium',
                'ai': row[9] or 'pending',
                'profitRate': row[11] or 0
            })
        
        # çµ±è¨ˆè¨ˆç®—
        cursor.execute('''
            SELECT 
                COUNT(*) as total_pending,
                SUM(CASE WHEN pa.risk_level = 'high' THEN 1 ELSE 0 END) as high_risk,
                SUM(CASE WHEN pa.risk_level = 'medium' THEN 1 ELSE 0 END) as medium_risk,
                SUM(CASE WHEN pa.ai_recommendation = 'approved' THEN 1 ELSE 0 END) as ai_approved,
                SUM(CASE WHEN pa.ai_recommendation = 'rejected' THEN 1 ELSE 0 END) as ai_rejected
            FROM products_enhanced p
            LEFT JOIN product_approvals pa ON p.product_id = pa.product_id
            WHERE pa.human_decision = 'pending' OR pa.human_decision IS NULL
        ''')
        
        stats_row = cursor.fetchone()
        statistics = {
            'total_pending': stats_row[0] or 0,
            'high_risk': stats_row[1] or 0,
            'medium_risk': stats_row[2] or 0,
            'ai_approved': stats_row[3] or 0,
            'ai_rejected': stats_row[4] or 0,
            'ai_pending': max(0, (stats_row[0] or 0) - (stats_row[3] or 0) - (stats_row[4] or 0))
        }
        
        conn.close()
        
        return jsonify({
            'success': True,
            'data': {
                'items': items,
                'statistics': statistics
            }
        })
        
    except Exception as e:
        logger.error(f"æ‰¿èªã‚­ãƒ¥ãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/update_approval_status', methods=['POST'])
def update_approval_status():
    """å•†å“æ‰¿èªã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°"""
    try:
        data = request.get_json()
        item_skus = data.get('item_skus', [])
        approval_action = data.get('approval_action', '')
        
        if not item_skus or not approval_action:
            return jsonify({'success': False, 'error': 'SKUã¾ãŸã¯ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“'}), 400
        
        conn = sqlite3.connect(DATABASE_PATH)
        cursor = conn.cursor()
        
        # æ‰¿èªã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°
        for sku in item_skus:
            cursor.execute('''
                UPDATE product_approvals 
                SET human_decision = ?, approved_by = ?, approved_at = ?
                WHERE product_id = ?
            ''', (approval_action, 'user', datetime.now(), sku))
            
            # å•†å“ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚‚æ›´æ–°
            new_status = 'approved' if approval_action == 'approved' else 'rejected'
            cursor.execute('''
                UPDATE products_enhanced 
                SET status = ?, updated_at = ?
                WHERE product_id = ?
            ''', (new_status, datetime.now(), sku))
        
        conn.commit()
        conn.close()
        
        return jsonify({
            'success': True,
            'processed_count': len(item_skus),
            'action': approval_action,
            'skus': item_skus,
            'message': f'{len(item_skus)}ä»¶ã®å•†å“ã‚’{approval_action}ã—ã¾ã—ãŸ'
        })
        
    except Exception as e:
        logger.error(f"æ‰¿èªã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/export_csv/<export_type>')
def export_csv(export_type):
    """CSVå‡ºåŠ›æ©Ÿèƒ½"""
    try:
        conn = sqlite3.connect(DATABASE_PATH)
        cursor = conn.cursor()
        
        if export_type == 'products':
            cursor.execute('''
                SELECT product_id, title_jp, title_en, price_jpy, price_usd,
                       category_jp, condition_jp, status, source_url, updated_at
                FROM products_enhanced
                ORDER BY updated_at DESC
            ''')
            
            headers = ['å•†å“ID', 'å•†å“å(æ—¥)', 'å•†å“å(è‹±)', 'ä¾¡æ ¼(å††)', 'ä¾¡æ ¼(USD)',
                      'ã‚«ãƒ†ã‚´ãƒª', 'ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³', 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', 'ã‚½ãƒ¼ã‚¹URL', 'æ›´æ–°æ—¥æ™‚']
            
        elif export_type == 'shipping_matrix':
            # é€æ–™ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ç”Ÿæˆ
            weights = [0.5, 1.0, 1.5, 2.0, 3.0, 5.0]
            countries = ['US', 'GB', 'DE', 'AU', 'CA']
            
            output = io.StringIO()
            writer = csv.writer(output)
            
            headers = ['é‡é‡(kg)'] + [f'{c}_Economy' for c in countries] + [f'{c}_Priority' for c in countries]
            writer.writerow(headers)
            
            for weight in weights:
                row = [f'{weight:.1f}']
                # Economyæ–™é‡‘
                for country in countries:
                    cost = 20.0 + (weight * 6)
                    row.append(f'{cost:.2f}')
                # Priorityæ–™é‡‘
                for country in countries:
                    cost = 35.0 + (weight * 10)
                    row.append(f'{cost:.2f}')
                writer.writerow(row)
            
            csv_content = output.getvalue()
            output.close()
            
            return jsonify({
                'success': True,
                'csv_content': csv_content,
                'filename': f'shipping_matrix_{int(time.time())}.csv'
            })
        
        else:
            return jsonify({'success': False, 'error': 'ä¸æ˜ãªã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒ—'}), 400
        
        # å•†å“ãƒ‡ãƒ¼ã‚¿CSV
        rows = cursor.fetchall()
        conn.close()
        
        output = io.StringIO()
        writer = csv.writer(output)
        writer.writerow(headers)
        
        for row in rows:
            writer.writerow(row)
        
        csv_content = output.getvalue()
        output.close()
        
        return jsonify({
            'success': True,
            'csv_content': csv_content,
            'filename': f'{export_type}_export_{int(time.time())}.csv',
            'rows': len(rows) + 1
        })
        
    except Exception as e:
        logger.error(f"CSVå‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/health')
def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'database': 'connected' if os.path.exists(DATABASE_PATH) else 'not_found',
        'advanced_modules': ADVANCED_MODULES_AVAILABLE,
        'session_id': api.session_id
    })

if __name__ == '__main__':
    logger.info("ğŸš€ æ‹¡å¼µYahooâ†’eBayçµ±åˆAPIã‚µãƒ¼ãƒãƒ¼èµ·å‹•ä¸­...")
    logger.info(f"ğŸ“Š é«˜åº¦ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«: {'åˆ©ç”¨å¯èƒ½' if ADVANCED_MODULES_AVAILABLE else 'åŸºæœ¬ãƒ¢ãƒ¼ãƒ‰'}")
    logger.info("ğŸŒ ã‚¢ã‚¯ã‚»ã‚¹å…ˆ: http://localhost:5001")
    logger.info("ğŸ’¡ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯: http://localhost:5001/health")
    
    app.run(
        host='0.0.0.0',
        port=5001,
        debug=True,
        threaded=True
    )
