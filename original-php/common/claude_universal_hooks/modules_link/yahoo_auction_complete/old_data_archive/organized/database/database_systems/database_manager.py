#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üóÇÔ∏è „Éá„Éº„Çø„Éô„Éº„ÇπÁÆ°ÁêÜ„É¢„Ç∏„É•„Éº„É´
N3Ê∫ñÊã† - „É§„Éï„Ç™„ÇØ/PayPay„Éï„É™„ÉûÁµ±ÂêàÂûãÂú®Â∫´ÁÆ°ÁêÜ„Ç∑„Çπ„ÉÜ„É†Áî®
"""

import mysql.connector
from mysql.connector import pooling, Error
import json
import logging
import time
from typing import Dict, List, Optional, Union, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
import os
import sys


@dataclass
class ProductListing:
    """ÂïÜÂìÅ„É™„Çπ„ÉÜ„Ç£„É≥„Ç∞„Éá„Éº„Çø„ÇØ„É©„Çπ"""
    platform: str
    item_id: str
    title_original: str
    price_jpy: float = 0.0
    title_translated: str = ""
    description_original: str = ""
    description_translated: str = ""
    price_usd: float = None
    price_text: str = ""
    condition_jp: str = ""
    category_jp: str = ""
    image_urls: str = ""
    image_count: int = 0
    main_image_url: str = ""
    seller_info: Dict = None
    auction_info: Dict = None
    master_sku: str = ""
    
    def __post_init__(self):
        if self.seller_info is None:
            self.seller_info = {}
        if self.auction_info is None:
            self.auction_info = {}


class DatabaseManager:
    """„Éá„Éº„Çø„Éô„Éº„ÇπÁÆ°ÁêÜ„ÇØ„É©„Çπ"""
    
    def __init__(self, config_path: str = None):
        self.config = self._load_config(config_path)
        self.logger = self._setup_logger()
        self.connection_pool = None
        self._create_connection_pool()
    
    def _load_config(self, config_path: str) -> Dict:
        """„Éá„Éº„Çø„Éô„Éº„ÇπË®≠ÂÆö„ÇíË™≠„ÅøËæº„Åø"""
        default_config = {
            'host': 'localhost',
            'database': 'nagano3',
            'user': 'root',
            'password': '',
            'charset': 'utf8mb4',
            'pool_name': 'yahoo_auction_pool',
            'pool_size': 10,
            'pool_reset_session': True,
            'autocommit': True
        }
        
        if config_path and os.path.exists(config_path):
            try:
                with open(config_path, 'r') as f:
                    file_config = json.load(f)
                    default_config.update(file_config)
            except Exception as e:
                print(f"Ë®≠ÂÆö„Éï„Ç°„Ç§„É´Ë™≠„ÅøËæº„ÅøË≠¶Âëä: {e}")
        
        # Áí∞Â¢ÉÂ§âÊï∞„Åã„Çâ„ÅÆ‰∏äÊõ∏„Åç
        env_mapping = {
            'DB_HOST': 'host',
            'DB_NAME': 'database',
            'DB_USER': 'user',
            'DB_PASS': 'password'
        }
        
        for env_key, config_key in env_mapping.items():
            if os.getenv(env_key):
                default_config[config_key] = os.getenv(env_key)
        
        return default_config
    
    def _setup_logger(self) -> logging.Logger:
        """„É≠„Ç∞„Çª„ÉÉ„Éà„Ç¢„ÉÉ„Éó"""
        logger = logging.getLogger('DatabaseManager')
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
        return logger
    
    def _create_connection_pool(self):
        """„Éá„Éº„Çø„Éô„Éº„ÇπÊé•Á∂ö„Éó„Éº„É´‰ΩúÊàê"""
        try:
            pool_config = {
                'pool_name': self.config['pool_name'],
                'pool_size': self.config['pool_size'],
                'pool_reset_session': self.config['pool_reset_session'],
                'host': self.config['host'],
                'database': self.config['database'],
                'user': self.config['user'],
                'password': self.config['password'],
                'charset': self.config['charset'],
                'autocommit': self.config['autocommit']
            }
            
            self.connection_pool = mysql.connector.pooling.MySQLConnectionPool(**pool_config)
            self.logger.info("‚úÖ „Éá„Éº„Çø„Éô„Éº„ÇπÊé•Á∂ö„Éó„Éº„É´‰ΩúÊàêÊàêÂäü")
            
        except Error as e:
            self.logger.error(f"‚ùå „Éá„Éº„Çø„Éô„Éº„ÇπÊé•Á∂ö„Éó„Éº„É´‰ΩúÊàêÂ§±Êïó: {e}")
            raise
    
    def get_connection(self):
        """„Éá„Éº„Çø„Éô„Éº„ÇπÊé•Á∂öÂèñÂæó"""
        try:
            return self.connection_pool.get_connection()
        except Error as e:
            self.logger.error(f"„Éá„Éº„Çø„Éô„Éº„ÇπÊé•Á∂öÂèñÂæóÂ§±Êïó: {e}")
            raise
    
    def execute_query(self, query: str, params: Tuple = None, fetch: bool = False) -> Union[List[Dict], bool]:
        """„ÇØ„Ç®„É™ÂÆüË°å"""
        connection = None
        cursor = None
        
        try:
            connection = self.get_connection()
            cursor = connection.cursor(dictionary=True)
            
            cursor.execute(query, params or ())
            
            if fetch:
                results = cursor.fetchall()
                return results
            else:
                connection.commit()
                return True
                
        except Error as e:
            self.logger.error(f"„ÇØ„Ç®„É™ÂÆüË°å„Ç®„É©„Éº: {e}")
            if connection:
                connection.rollback()
            return False
            
        finally:
            if cursor:
                cursor.close()
            if connection:
                connection.close()
    
    def save_product_listing(self, product_data: Dict) -> Optional[int]:
        """ÂïÜÂìÅ„É™„Çπ„ÉÜ„Ç£„É≥„Ç∞‰øùÂ≠ò"""
        try:
            # „Éá„Éº„ÇøÊï¥ÂΩ¢
            save_data = self._prepare_product_data(product_data)
            
            # INSERT ON DUPLICATE KEY UPDATE
            query = """
            INSERT INTO product_listings (
                platform, item_id, title_original, price_jpy, price_text,
                description_original, image_urls, image_count, main_image_url,
                seller_info, auction_info, scrape_status, last_scrape_at,
                scrape_attempts, created_by, updated_by
            ) VALUES (
                %(platform)s, %(item_id)s, %(title_original)s, %(price_jpy)s, %(price_text)s,
                %(description_original)s, %(image_urls)s, %(image_count)s, %(main_image_url)s,
                %(seller_info)s, %(auction_info)s, 'success', NOW(),
                1, 'scraper', 'scraper'
            )
            ON DUPLICATE KEY UPDATE
                title_original = VALUES(title_original),
                price_jpy = VALUES(price_jpy),
                price_text = VALUES(price_text),
                description_original = VALUES(description_original),
                image_urls = VALUES(image_urls),
                image_count = VALUES(image_count),
                main_image_url = VALUES(main_image_url),
                seller_info = VALUES(seller_info),
                auction_info = VALUES(auction_info),
                scrape_status = 'success',
                last_scrape_at = NOW(),
                scrape_attempts = scrape_attempts + 1,
                updated_by = 'scraper',
                updated_at = CURRENT_TIMESTAMP
            """
            
            connection = self.get_connection()
            cursor = connection.cursor()
            
            cursor.execute(query, save_data)
            connection.commit()
            
            # ÂïÜÂìÅID„ÇíÂèñÂæó
            product_id = cursor.lastrowid or self._get_product_id(save_data['platform'], save_data['item_id'])
            
            cursor.close()
            connection.close()
            
            self.logger.info(f"‚úÖ ÂïÜÂìÅ‰øùÂ≠òÊàêÂäü: ID={product_id}, {save_data['title_original'][:50]}...")
            return product_id
            
        except Exception as e:
            self.logger.error(f"‚ùå ÂïÜÂìÅ‰øùÂ≠òÂ§±Êïó: {e}")
            return None
    
    def _prepare_product_data(self, raw_data: Dict) -> Dict:
        """ÂïÜÂìÅ„Éá„Éº„Çø„ÅÆÊï¥ÂΩ¢"""
        # ÁîªÂÉèURLÂá¶ÁêÜ
        image_urls = raw_data.get('image_urls', [])
        if isinstance(image_urls, list):
            image_urls_str = '|'.join(image_urls)
            main_image = image_urls[0] if image_urls else ""
            image_count = len(image_urls)
        else:
            image_urls_str = str(image_urls) if image_urls else ""
            main_image = ""
            image_count = 0
        
        # JSONÂΩ¢Âºè„Éá„Éº„Çø
        seller_info = raw_data.get('seller_info', {})
        auction_info = raw_data.get('auction_info', {})
        
        prepared_data = {
            'platform': raw_data.get('platform', 'yahoo_auction'),
            'item_id': raw_data.get('item_id', ''),
            'title_original': raw_data.get('title', '')[:1000],  # Èï∑„ÅïÂà∂Èôê
            'price_jpy': float(raw_data.get('price_jpy', 0)),
            'price_text': raw_data.get('price_text', '')[:255],
            'description_original': raw_data.get('description', '')[:10000],  # Èï∑„ÅïÂà∂Èôê
            'image_urls': image_urls_str,
            'image_count': image_count,
            'main_image_url': main_image[:500] if main_image else "",
            'seller_info': json.dumps(seller_info, ensure_ascii=False) if seller_info else None,
            'auction_info': json.dumps(auction_info, ensure_ascii=False) if auction_info else None
        }
        
        return prepared_data
    
    def _get_product_id(self, platform: str, item_id: str) -> Optional[int]:
        """„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†„Å®„Ç¢„Ç§„ÉÜ„É†ID„Åã„ÇâÂïÜÂìÅID„ÇíÂèñÂæó"""
        query = "SELECT id FROM product_listings WHERE platform = %s AND item_id = %s"
        results = self.execute_query(query, (platform, item_id), fetch=True)
        
        if results:
            return results[0]['id']
        return None
    
    def save_scraping_history(self, listing_id: int, scrape_data: Dict) -> bool:
        """„Çπ„ÇØ„É¨„Ç§„Éî„É≥„Ç∞Â±•Ê≠¥‰øùÂ≠ò"""
        try:
            query = """
            INSERT INTO scraping_history (
                listing_id, url, platform, item_id, status, processing_time,
                data_extracted, error_message, user_agent, retry_count, scraped_at
            ) VALUES (
                %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW()
            )
            """
            
            params = (
                listing_id,
                scrape_data.get('url', ''),
                scrape_data.get('platform', ''),
                scrape_data.get('item_id', ''),
                'success' if scrape_data.get('success', False) else 'failed',
                scrape_data.get('processing_time', 0),
                json.dumps(scrape_data.get('debug_info', {}), ensure_ascii=False),
                scrape_data.get('error_message', ''),
                'RobustScraper/1.0',
                scrape_data.get('retry_count', 0)
            )
            
            return self.execute_query(query, params)
            
        except Exception as e:
            self.logger.error(f"„Çπ„ÇØ„É¨„Ç§„Éî„É≥„Ç∞Â±•Ê≠¥‰øùÂ≠òÂ§±Êïó: {e}")
            return False
    
    def get_products(self, platform: str = None, limit: int = 100, offset: int = 0) -> List[Dict]:
        """ÂïÜÂìÅ„É™„Çπ„ÉàÂèñÂæó"""
        base_query = """
        SELECT 
            id, platform, item_id, title_original, price_jpy, price_usd,
            scrape_status, ebay_listing_status, inventory_status,
            created_at, updated_at
        FROM product_listings 
        WHERE deleted_at IS NULL
        """
        
        params = []
        if platform:
            base_query += " AND platform = %s"
            params.append(platform)
        
        base_query += " ORDER BY updated_at DESC LIMIT %s OFFSET %s"
        params.extend([limit, offset])
        
        results = self.execute_query(base_query, tuple(params), fetch=True)
        return results or []
    
    def get_product_by_id(self, product_id: int) -> Optional[Dict]:
        """ÂïÜÂìÅË©≥Á¥∞ÂèñÂæó"""
        query = """
        SELECT * FROM product_listings 
        WHERE id = %s AND deleted_at IS NULL
        """
        
        results = self.execute_query(query, (product_id,), fetch=True)
        return results[0] if results else None
    
    def update_ebay_listing(self, product_id: int, ebay_data: Dict) -> bool:
        """eBayÂá∫ÂìÅÊÉÖÂ†±Êõ¥Êñ∞"""
        try:
            query = """
            UPDATE product_listings SET
                ebay_item_id = %s,
                ebay_listing_status = %s,
                ebay_listing_url = %s,
                ebay_price_usd = %s,
                ebay_listed_at = %s,
                updated_by = 'ebay_sync',
                updated_at = CURRENT_TIMESTAMP
            WHERE id = %s
            """
            
            params = (
                ebay_data.get('item_id', ''),
                ebay_data.get('status', 'draft'),
                ebay_data.get('listing_url', ''),
                ebay_data.get('price_usd', None),
                ebay_data.get('listed_at', None),
                product_id
            )
            
            return self.execute_query(query, params)
            
        except Exception as e:
            self.logger.error(f"eBayÊÉÖÂ†±Êõ¥Êñ∞Â§±Êïó: {e}")
            return False
    
    def get_products_for_ebay_listing(self, limit: int = 50) -> List[Dict]:
        """eBayÂá∫ÂìÅÂØæË±°ÂïÜÂìÅÂèñÂæó"""
        query = """
        SELECT 
            id, platform, item_id, title_original, title_translated,
            description_original, description_translated,
            price_jpy, price_usd, image_urls, main_image_url,
            condition_jp, category_jp
        FROM product_listings 
        WHERE deleted_at IS NULL
        AND scrape_status = 'success'
        AND ebay_listing_status = 'not_listed'
        AND price_jpy > 0
        AND title_original != ''
        ORDER BY profitability_score DESC, created_at DESC
        LIMIT %s
        """
        
        results = self.execute_query(query, (limit,), fetch=True)
        return results or []
    
    def cleanup_old_data(self, days: int = 30) -> bool:
        """Âè§„ÅÑ„Éá„Éº„Çø„ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó"""
        try:
            # Âè§„ÅÑ„Çπ„ÇØ„É¨„Ç§„Éî„É≥„Ç∞Â±•Ê≠¥ÂâäÈô§
            query1 = "DELETE FROM scraping_history WHERE scraped_at < DATE_SUB(NOW(), INTERVAL %s DAY)"
            self.execute_query(query1, (days,))
            
            self.logger.info(f"‚úÖ {days}Êó•Ââç„ÅÆ„Éá„Éº„Çø„ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„ÉóÂÆå‰∫Ü")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå „Éá„Éº„Çø„ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„ÉóÂ§±Êïó: {e}")
            return False
    
    def close(self):
        """Êé•Á∂ö„Éó„Éº„É´„ÇØ„É≠„Éº„Ç∫"""
        if self.connection_pool:
            # Êé•Á∂ö„Éó„Éº„É´„ÅÆÊòéÁ§∫ÁöÑ„Å™„ÇØ„É≠„Éº„Ç∫„ÅØÈÄöÂ∏∏‰∏çË¶Å
            # „Ç¨„Éô„Éº„Ç∏„Ç≥„É¨„ÇØ„Ç∑„Éß„É≥„ÅßËá™ÂãïÁöÑ„Å´Âá¶ÁêÜ„Åï„Çå„Çã
            pass
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()


# ‰æøÂà©„Å™Èñ¢Êï∞
def get_database_manager(config_path: str = None) -> DatabaseManager:
    """„Éá„Éº„Çø„Éô„Éº„Çπ„Éû„Éç„Éº„Ç∏„É£„ÉºÂèñÂæó"""
    return DatabaseManager(config_path)


# ‰ΩøÁî®‰æã„Éª„ÉÜ„Çπ„ÉàÁî®„É°„Ç§„É≥Èñ¢Êï∞
def main():
    """„É°„Ç§„É≥ÂÆüË°åÈñ¢Êï∞"""
    import argparse
    
    parser = argparse.ArgumentParser(description='„Éá„Éº„Çø„Éô„Éº„ÇπÁÆ°ÁêÜ„Ç∑„Çπ„ÉÜ„É†')
    parser.add_argument('--test', action='store_true', help='„ÉÜ„Çπ„ÉàÂÆüË°å')
    parser.add_argument('--cleanup', type=int, help='„ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„ÉóÔºàÊó•Êï∞ÊåáÂÆöÔºâ')
    parser.add_argument('--config', help='Ë®≠ÂÆö„Éï„Ç°„Ç§„É´„Éë„Çπ')
    
    args = parser.parse_args()
    
    try:
        with get_database_manager(args.config) as db:
            if args.test:
                # „ÉÜ„Çπ„Éà„Éá„Éº„Çø‰øùÂ≠ò
                test_data = {
                    'platform': 'yahoo_auction',
                    'item_id': 'test_' + str(int(time.time())),
                    'title': '„ÉÜ„Çπ„ÉàÂïÜÂìÅ',
                    'price_jpy': 1000,
                    'description': '„ÉÜ„Çπ„ÉàÁî®ÂïÜÂìÅË™¨Êòé',
                    'image_urls': ['https://example.com/image1.jpg'],
                    'seller_info': {'name': '„ÉÜ„Çπ„ÉàÂá∫ÂìÅËÄÖ'}
                }
                
                product_id = db.save_product_listing(test_data)
                print(f"‚úÖ „ÉÜ„Çπ„Éà„Éá„Éº„Çø‰øùÂ≠ò: ID={product_id}")
            
            elif args.cleanup:
                # „Éá„Éº„Çø„ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó
                success = db.cleanup_old_data(args.cleanup)
                print(f"{'‚úÖ' if success else '‚ùå'} „ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó: {args.cleanup}Êó•Ââç")
            
            else:
                # „Éá„Éï„Ç©„É´„Éà: ÊúÄÊñ∞ÂïÜÂìÅË°®Á§∫
                products = db.get_products(limit=5)
                print(f"üì¶ ÊúÄÊñ∞ÂïÜÂìÅ ({len(products)}‰ª∂):")
                for product in products:
                    print(f"  - {product['title_original'][:50]}... (¬•{product['price_jpy']:,.0f})")
    
    except Exception as e:
        print(f"‚ùå „Ç®„É©„Éº: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
