# services/risk-assessment/src/services/risk_assessor.py
import asyncio
import aiohttp
import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass
import asyncpg
from sklearn.ensemble import RandomForestRegressor, IsolationForest
from sklearn.preprocessing import StandardScaler
import json
import re

@dataclass
class RiskAssessment:
    """ãƒªã‚¹ã‚¯è©•ä¾¡çµæœ"""
    overall_risk_score: float
    market_volatility_score: float
    competition_risk: float
    supply_chain_risk: float
    seasonal_risk: float
    counterfeit_risk: float
    policy_risk: float
    liquidity_risk: float
    risk_factors: List[Dict]
    confidence_level: float
    recommendations: List[str]

@dataclass
class MarketAnalysis:
    """å¸‚å ´åˆ†æçµæœ"""
    trend_direction: str  # 'up', 'down', 'stable'
    trend_strength: float
    market_size_estimate: float
    growth_rate: float
    seasonality_index: float
    competition_intensity: float
    price_volatility: float
    demand_forecast: List[Dict]
    data_quality_score: float

class RiskAssessorService:
    def __init__(self):
        self.db_pool = None
        self.session = None
        self.ml_models = {}
        self.risk_weights = {
            'market_volatility': 0.25,
            'competition': 0.20,
            'supply_chain': 0.15,
            'seasonal': 0.15,
            'counterfeit': 0.10,
            'policy': 0.10,
            'liquidity': 0.05
        }

    async def initialize(self):
        """ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–"""
        self.db_pool = await asyncpg.create_pool(settings.DATABASE_URL)
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=30)
        )
        
        # æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        await self.initialize_ml_models()

    async def initialize_ml_models(self):
        """æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã¨è¨“ç·´"""
        try:
            # éå»ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            historical_data = await self.fetch_historical_data()
            
            if len(historical_data) > 100:  # ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆ
                # ä¾¡æ ¼å¤‰å‹•äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
                self.ml_models['price_volatility'] = await self.train_volatility_model(historical_data)
                
                # ç•°å¸¸å€¤æ¤œå‡ºãƒ¢ãƒ‡ãƒ«
                self.ml_models['anomaly_detector'] = await self.train_anomaly_model(historical_data)
                
                # éœ€è¦äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«  
                self.ml_models['demand_forecast'] = await self.train_demand_model(historical_data)
                
                print("Machine learning models initialized successfully")
            else:
                print("Insufficient data for ML models, using rule-based approach")
                
        except Exception as e:
            print(f"ML model initialization error: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡ã‚’ä½¿ç”¨

    async def assess_investment_risk(
        self, 
        product_data: Dict, 
        supplier_data: Dict, 
        market_data: Optional[Dict] = None
    ) -> RiskAssessment:
        """ç·åˆæŠ•è³‡ãƒªã‚¹ã‚¯è©•ä¾¡"""
        
        try:
            # å„ãƒªã‚¹ã‚¯è¦ç´ ã‚’å€‹åˆ¥ã«è©•ä¾¡
            market_volatility = await self.assess_market_volatility_risk(product_data, market_data)
            competition_risk = await self.assess_competition_risk(product_data)
            supply_chain_risk = await self.assess_supply_chain_risk(supplier_data)
            seasonal_risk = await self.assess_seasonal_risk(product_data)
            counterfeit_risk = await self.assess_counterfeit_risk(product_data)
            policy_risk = await self.assess_policy_risk(product_data)
            liquidity_risk = await self.assess_liquidity_risk(product_data)

            # ç·åˆãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢è¨ˆç®—
            overall_risk = (
                market_volatility * self.risk_weights['market_volatility'] +
                competition_risk * self.risk_weights['competition'] +
                supply_chain_risk * self.risk_weights['supply_chain'] +
                seasonal_risk * self.risk_weights['seasonal'] +
                counterfeit_risk * self.risk_weights['counterfeit'] +
                policy_risk * self.risk_weights['policy'] +
                liquidity_risk * self.risk_weights['liquidity']
            )

            # ãƒªã‚¹ã‚¯è¦å› ã®è©³ç´°åŒ–
            risk_factors = [
                {
                    'factor': 'Market Volatility',
                    'score': market_volatility,
                    'impact': 'high' if market_volatility > 0.7 else 'medium' if market_volatility > 0.4 else 'low',
                    'description': self.get_risk_description('market_volatility', market_volatility)
                },
                {
                    'factor': 'Competition Level',
                    'score': competition_risk,
                    'impact': 'high' if competition_risk > 0.7 else 'medium' if competition_risk > 0.4 else 'low',
                    'description': self.get_risk_description('competition', competition_risk)
                },
                {
                    'factor': 'Supply Chain',
                    'score': supply_chain_risk,
                    'impact': 'high' if supply_chain_risk > 0.7 else 'medium' if supply_chain_risk > 0.4 else 'low',
                    'description': self.get_risk_description('supply_chain', supply_chain_risk)
                }
            ]

            # æ¨å¥¨äº‹é …ç”Ÿæˆ
            recommendations = self.generate_risk_recommendations(
                overall_risk, market_volatility, competition_risk, supply_chain_risk
            )

            # ä¿¡é ¼åº¦è¨ˆç®—
            confidence_level = self.calculate_risk_confidence(product_data, market_data)

            return RiskAssessment(
                overall_risk_score=overall_risk,
                market_volatility_score=market_volatility,
                competition_risk=competition_risk,
                supply_chain_risk=supply_chain_risk,
                seasonal_risk=seasonal_risk,
                counterfeit_risk=counterfeit_risk,
                policy_risk=policy_risk,
                liquidity_risk=liquidity_risk,
                risk_factors=risk_factors,
                confidence_level=confidence_level,
                recommendations=recommendations
            )

        except Exception as e:
            print(f"Risk assessment error: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒªã‚¹ã‚¯è©•ä¾¡ã‚’è¿”ã™
            return self.get_default_risk_assessment()

    async def assess_market_volatility_risk(self, product_data: Dict, market_data: Optional[Dict]) -> float:
        """å¸‚å ´ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯è©•ä¾¡"""
        
        try:
            category_id = product_data.get('category_id')
            price = product_data.get('ebay_selling_price', 0)
            
            # éå»ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            price_history = await self.fetch_price_history(category_id, days=90)
            
            if len(price_history) < 10:
                # ãƒ‡ãƒ¼ã‚¿ä¸è¶³æ™‚ã¯ã‚«ãƒ†ã‚´ãƒªå¹³å‡ã‚’ä½¿ç”¨
                return await self.get_category_volatility(category_id)
            
            # ä¾¡æ ¼å¤‰å‹•ç‡ã‚’è¨ˆç®—
            prices = [p['price'] for p in price_history]
            price_changes = np.diff(prices) / prices[:-1]
            volatility = np.std(price_changes)
            
            # æ­£è¦åŒ– (0-1ã‚¹ã‚±ãƒ¼ãƒ«)
            normalized_volatility = min(1.0, volatility * 10)  # 10%å¤‰å‹•ã§1.0
            
            # æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹å ´åˆã¯äºˆæ¸¬ã‚‚è€ƒæ…®
            if 'price_volatility' in self.ml_models:
                predicted_volatility = await self.predict_price_volatility(product_data)
                normalized_volatility = (normalized_volatility + predicted_volatility) / 2
            
            return normalized_volatility

        except Exception as e:
            print(f"Market volatility assessment error: {e}")
            return 0.5  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤

    async def assess_competition_risk(self, product_data: Dict) -> float:
        """ç«¶åˆãƒªã‚¹ã‚¯è©•ä¾¡"""
        
        try:
            title = product_data.get('title', '')
            category_id = product_data.get('category_id')
            price = product_data.get('ebay_selling_price', 0)
            
            # é¡ä¼¼å•†å“ã®å‡ºå“æ•°ã‚’èª¿æŸ»
            similar_products = await self.fetch_similar_products(title, category_id)
            
            # ç«¶åˆåˆ†ææŒ‡æ¨™
            competition_count = len(similar_products)
            price_competition = self.analyze_price_competition(price, similar_products)
            seller_competition = self.analyze_seller_competition(similar_products)
            
            # ç«¶åˆå¯†åº¦è¨ˆç®—
            base_risk = min(1.0, competition_count / 100)  # 100ä»¶ã§æœ€å¤§ãƒªã‚¹ã‚¯
            
            # ä¾¡æ ¼ç«¶åˆè€ƒæ…®
            if price_competition > 0.8:  # 80%ä»¥ä¸ŠãŒåŒä¾¡æ ¼å¸¯
                base_risk += 0.3
            elif price_competition > 0.6:
                base_risk += 0.2
            
            # å¤§æ‰‹ã‚»ãƒ©ãƒ¼å‚å…¥ãƒªã‚¹ã‚¯
            if seller_competition > 0.7:  # å¤§æ‰‹ã‚»ãƒ©ãƒ¼70%ä»¥ä¸Š
                base_risk += 0.25
            
            return min(1.0, base_risk)

        except Exception as e:
            print(f"Competition risk assessment error: {e}")
            return 0.5

    async def assess_supply_chain_risk(self, supplier_data: Dict) -> float:
        """ã‚µãƒ—ãƒ©ã‚¤ãƒã‚§ãƒ¼ãƒ³ãƒªã‚¹ã‚¯è©•ä¾¡"""
        
        try:
            supplier_type = supplier_data.get('supplier_type', '')
            reliability_score = supplier_data.get('reliability_score', 0.5)
            availability = supplier_data.get('availability_status', 'unknown')
            
            # ãƒ™ãƒ¼ã‚¹ãƒªã‚¹ã‚¯ï¼ˆã‚µãƒ—ãƒ©ã‚¤ãƒ¤ãƒ¼ã‚¿ã‚¤ãƒ—åˆ¥ï¼‰
            base_risks = {
                'amazon': 0.1,     # æœ€ã‚‚å®‰å®š
                'rakuten': 0.2,
                'yahoo_auctions': 0.4,
                'mercari': 0.6,    # å€‹äººè²©å£²ã®ãŸã‚ãƒªã‚¹ã‚¯é«˜
                'other': 0.5
            }
            
            base_risk = base_risks.get(supplier_type, 0.5)
            
            # ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢ã§ãƒªã‚¹ã‚¯èª¿æ•´
            reliability_risk = 1.0 - reliability_score
            
            # åœ¨åº«çŠ¶æ³ã§ãƒªã‚¹ã‚¯èª¿æ•´
            availability_risk = {
                'in_stock': 0.0,
                'limited': 0.3,
                'out_of_stock': 0.8,
                'unknown': 0.5
            }.get(availability, 0.5)
            
            # ç·åˆã‚µãƒ—ãƒ©ã‚¤ãƒã‚§ãƒ¼ãƒ³ãƒªã‚¹ã‚¯
            total_risk = (base_risk + reliability_risk + availability_risk) / 3
            
            return min(1.0, total_risk)

        except Exception as e:
            print(f"Supply chain risk assessment error: {e}")
            return 0.5

    async def assess_seasonal_risk(self, product_data: Dict) -> float:
        """å­£ç¯€æ€§ãƒªã‚¹ã‚¯è©•ä¾¡"""
        
        try:
            title = product_data.get('title', '').lower()
            category_id = product_data.get('category_id')
            current_month = datetime.now().month
            
            # å­£ç¯€æ€§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º
            seasonal_keywords = {
                'winter': [12, 1, 2],
                'spring': [3, 4, 5], 
                'summer': [6, 7, 8],
                'autumn': [9, 10, 11],
                'christmas': [11, 12],
                'valentine': [1, 2],
                'halloween': [10],
                'graduation': [3, 4]
            }
            
            seasonal_risk = 0.0
            
            for season, months in seasonal_keywords.items():
                if season in title:
                    if current_month not in months:
                        # å­£ç¯€å¤–ã‚Œå•†å“ã¯é«˜ãƒªã‚¹ã‚¯
                        months_until_season = min(
                            [(m - current_month) % 12 for m in months]
                        )
                        seasonal_risk = max(seasonal_risk, 
                                          min(1.0, months_until_season / 6))
            
            # ã‚«ãƒ†ã‚´ãƒªåˆ¥å­£ç¯€æ€§ã‚‚è€ƒæ…®
            category_seasonality = await self.get_category_seasonality(category_id, current_month)
            seasonal_risk = max(seasonal_risk, category_seasonality)
            
            return seasonal_risk

        except Exception as e:
            print(f"Seasonal risk assessment error: {e}")
            return 0.1  # ä½ãƒªã‚¹ã‚¯ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

    async def assess_counterfeit_risk(self, product_data: Dict) -> float:
        """å½ç‰©ãƒ»æ¨¡å€£å“ãƒªã‚¹ã‚¯è©•ä¾¡"""
        
        try:
            title = product_data.get('title', '').lower()
            brand = product_data.get('brand', '').lower()
            category_id = product_data.get('category_id')
            price = product_data.get('ebay_selling_price', 0)
            
            # é«˜ãƒªã‚¹ã‚¯ãƒ–ãƒ©ãƒ³ãƒ‰
            high_risk_brands = ['nike', 'adidas', 'gucci', 'louis vuitton', 'rolex', 
                               'apple', 'samsung', 'sony', 'nintendo']
            
            # é«˜ãƒªã‚¹ã‚¯ã‚«ãƒ†ã‚´ãƒª
            high_risk_categories = ['fashion', 'luxury', 'electronics', 'watches']
            
            counterfeit_risk = 0.0
            
            # ãƒ–ãƒ©ãƒ³ãƒ‰ãƒªã‚¹ã‚¯
            if any(brand_name in title for brand_name in high_risk_brands):
                counterfeit_risk += 0.4
                
                # å¸‚å ´ä¾¡æ ¼ã¨ã®æ¯”è¼ƒ
                market_price = await self.get_market_price_range(brand, category_id)
                if market_price and price < market_price * 0.6:  # 40%ä»¥ä¸Šå®‰ã„
                    counterfeit_risk += 0.4
            
            # ã‚«ãƒ†ã‚´ãƒªãƒªã‚¹ã‚¯
            category_name = await self.get_category_name(category_id)
            if any(cat in category_name.lower() for cat in high_risk_categories):
                counterfeit_risk += 0.2
            
            # ç–‘ã‚ã—ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º
            suspicious_keywords = ['replica', 'aaa', 'mirror', 'inspired', 'style']
            if any(keyword in title for keyword in suspicious_keywords):
                counterfeit_risk += 0.5
            
            return min(1.0, counterfeit_risk)

        except Exception as e:
            print(f"Counterfeit risk assessment error: {e}")
            return 0.2  # ä¸­ä½ãƒªã‚¹ã‚¯ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

    async def assess_policy_risk(self, product_data: Dict) -> float:
        """æ”¿ç­–ãƒ»è¦åˆ¶ãƒªã‚¹ã‚¯è©•ä¾¡"""
        
        try:
            category_id = product_data.get('category_id')
            title = product_data.get('title', '').lower()
            
            # é«˜è¦åˆ¶ã‚«ãƒ†ã‚´ãƒª
            high_regulation_categories = {
                'medical': 0.8,
                'pharmaceutical': 0.9,
                'weapons': 0.95,
                'alcohol': 0.7,
                'tobacco': 0.8,
                'automotive_parts': 0.4,
                'food_supplements': 0.6
            }
            
            category_name = await self.get_category_name(category_id)
            
            policy_risk = 0.1  # ãƒ™ãƒ¼ã‚¹ãƒªã‚¹ã‚¯
            
            # ã‚«ãƒ†ã‚´ãƒªè¦åˆ¶ãƒªã‚¹ã‚¯
            for reg_category, risk_score in high_regulation_categories.items():
                if reg_category in category_name.lower():
                    policy_risk = max(policy_risk, risk_score)
            
            # è¦åˆ¶é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º
            regulatory_keywords = ['medical', 'prescription', 'fda', 'restricted', 
                                 'professional', 'license', 'certified']
            
            if any(keyword in title for keyword in regulatory_keywords):
                policy_risk += 0.3
            
            # å›½éš›è¦åˆ¶ãƒªã‚¹ã‚¯ï¼ˆæ—¥æœ¬â‡”ã‚¢ãƒ¡ãƒªã‚«ï¼‰
            international_risk = await self.assess_international_regulation_risk(
                product_data
            )
            policy_risk += international_risk
            
            return min(1.0, policy_risk)

        except Exception as e:
            print(f"Policy risk assessment error: {e}")
            return 0.1

    async def assess_liquidity_risk(self, product_data: Dict) -> float:
        """æµå‹•æ€§ãƒªã‚¹ã‚¯è©•ä¾¡ï¼ˆå£²ã‚Šã‚„ã™ã•ï¼‰"""
        
        try:
            sold_quantity = product_data.get('ebay_sold_quantity', 0)
            watch_count = product_data.get('watch_count', 0)
            category_id = product_data.get('category_id')
            
            # è²©å£²å±¥æ­´ã«ã‚ˆã‚‹æµå‹•æ€§è©•ä¾¡
            if sold_quantity > 100:
                liquidity_risk = 0.1  # é«˜æµå‹•æ€§
            elif sold_quantity > 50:
                liquidity_risk = 0.2
            elif sold_quantity > 10:
                liquidity_risk = 0.4
            else:
                liquidity_risk = 0.7  # ä½æµå‹•æ€§
            
            # ã‚¦ã‚©ãƒƒãƒæ•°ã«ã‚ˆã‚‹èª¿æ•´
            if watch_count > 50:
                liquidity_risk -= 0.2
            elif watch_count > 20:
                liquidity_risk -= 0.1
            
            # ã‚«ãƒ†ã‚´ãƒªæµå‹•æ€§
            category_liquidity = await self.get_category_liquidity(category_id)
            liquidity_risk = (liquidity_risk + category_liquidity) / 2
            
            return max(0.0, min(1.0, liquidity_risk))

        except Exception as e:
            print(f"Liquidity risk assessment error: {e}")
            return 0.3

    def get_risk_description(self, risk_type: str, score: float) -> str:
        """ãƒªã‚¹ã‚¯è¦å› ã®èª¬æ˜æ–‡ç”Ÿæˆ"""
        
        descriptions = {
            'market_volatility': {
                'low': 'å¸‚å ´ä¾¡æ ¼ãŒå®‰å®šã—ã¦ãŠã‚Šã€ä¾¡æ ¼å¤‰å‹•ãƒªã‚¹ã‚¯ã¯é™å®šçš„ã§ã™ã€‚',
                'medium': 'å¸‚å ´ã«ã‚ã‚‹ç¨‹åº¦ã®ä¾¡æ ¼å¤‰å‹•ãŒè¦‹ã‚‰ã‚Œã€æ³¨æ„ãŒå¿…è¦ã§ã™ã€‚',
                'high': 'å¸‚å ´ä¾¡æ ¼ã®å¤‰å‹•ãŒæ¿€ã—ãã€æŠ•è³‡ãƒªã‚¹ã‚¯ãŒé«˜ã„çŠ¶æ³ã§ã™ã€‚'
            },
            'competition': {
                'low': 'ç«¶åˆå‡ºå“è€…ãŒå°‘ãªãã€å¸‚å ´ã‚·ã‚§ã‚¢ç²å¾—ãŒæœŸå¾…ã§ãã¾ã™ã€‚',
                'medium': 'é©åº¦ãªç«¶åˆãŒã‚ã‚Šã¾ã™ãŒã€å·®åˆ¥åŒ–ã«ã‚ˆã‚Šåˆ©ç›Šç¢ºä¿ã¯å¯èƒ½ã§ã™ã€‚', 
                'high': 'æ¿€ã—ã„ä¾¡æ ¼ç«¶äº‰ã«ã‚ˆã‚Šã€åˆ©ç›Šç¢ºä¿ãŒå›°é›£ãªå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚'
            },
            'supply_chain': {
                'low': 'ä¿¡é ¼æ€§ã®é«˜ã„ã‚µãƒ—ãƒ©ã‚¤ãƒ¤ãƒ¼ã‹ã‚‰å®‰å®šèª¿é”ãŒå¯èƒ½ã§ã™ã€‚',
                'medium': 'ã‚µãƒ—ãƒ©ã‚¤ãƒã‚§ãƒ¼ãƒ³ã«è‹¥å¹²ã®ä¸å®‰å®šè¦ç´ ãŒã‚ã‚Šã¾ã™ã€‚',
                'high': 'èª¿é”ã®å®‰å®šæ€§ã«é‡å¤§ãªæ‡¸å¿µãŒã‚ã‚Šã€åœ¨åº«åˆ‡ã‚Œãƒªã‚¹ã‚¯ãŒé«˜ã„ã§ã™ã€‚'
            }
        }
        
        risk_level = 'high' if score > 0.7 else 'medium' if score > 0.4 else 'low'
        return descriptions.get(risk_type, {}).get(risk_level, 'ãƒªã‚¹ã‚¯è©•ä¾¡ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚')

    def generate_risk_recommendations(
        self, 
        overall_risk: float, 
        market_volatility: float, 
        competition_risk: float, 
        supply_chain_risk: float
    ) -> List[str]:
        """ãƒªã‚¹ã‚¯ã«åŸºã¥ãæ¨å¥¨äº‹é …ç”Ÿæˆ"""
        
        recommendations = []
        
        if overall_risk > 0.7:
            recommendations.append("âš ï¸ ç·åˆãƒªã‚¹ã‚¯ãŒé«˜ã„ãŸã‚ã€æŠ•è³‡ã¯æ…é‡ã«æ¤œè¨ã—ã¦ãã ã•ã„")
        
        if market_volatility > 0.6:
            recommendations.append("ğŸ“Š ä¾¡æ ¼å¤‰å‹•ãŒå¤§ãã„ãŸã‚ã€é »ç¹ãªä¾¡æ ¼èª¿æ•´ãŒå¿…è¦ã§ã™")
            
        if competition_risk > 0.7:
            recommendations.append("ğŸ¯ ç«¶åˆãŒå¤šã„ãŸã‚ã€å·®åˆ¥åŒ–æˆ¦ç•¥ã‚„ç‹¬è‡ªæ€§ã®ç¢ºä¿ãŒé‡è¦ã§ã™")
            
        if supply_chain_risk > 0.6:
            recommendations.append("ğŸª ä»£æ›¿ã‚µãƒ—ãƒ©ã‚¤ãƒ¤ãƒ¼ã®ç¢ºä¿ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
            
        if overall_risk < 0.3:
            recommendations.append("âœ… ä½ãƒªã‚¹ã‚¯ã®æŠ•è³‡æ©Ÿä¼šã§ã™ã€‚ç©æ¥µçš„ãªæ¤œè¨ã‚’ãŠå‹§ã‚ã—ã¾ã™")
        elif overall_risk < 0.5:
            recommendations.append("âš–ï¸ é©åº¦ãªãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã€‚åˆ©ç›Šã¨ãƒªã‚¹ã‚¯ã®ãƒãƒ©ãƒ³ã‚¹ã‚’è€ƒæ…®ã—ã¦ãã ã•ã„")
        
        # å…·ä½“çš„ãªå¯¾ç­–ææ¡ˆ
        if market_volatility > 0.5:
            recommendations.append("ğŸ’¡ ä¾¡æ ¼è¿½è·¡ãƒ„ãƒ¼ãƒ«ã®è¨­å®šã¨è‡ªå‹•ä¾¡æ ¼èª¿æ•´ã®å°å…¥ã‚’æ¤œè¨")
            
        if supply_chain_risk > 0.5:
            recommendations.append("ğŸ’¡ è¤‡æ•°ã®ä»•å…¥å…ˆã‚’ç¢ºä¿ã—ã€åœ¨åº«ç®¡ç†ã®æœ€é©åŒ–ã‚’å®Ÿæ–½")
        
        return recommendations

    async def calculate_risk_confidence(self, product_data: Dict, market_data: Optional[Dict]) -> float:
        """ãƒªã‚¹ã‚¯è©•ä¾¡ã®ä¿¡é ¼åº¦è¨ˆç®—"""
        
        try:
            confidence_factors = []
            
            # ãƒ‡ãƒ¼ã‚¿å“è³ªã«ã‚ˆã‚‹ä¿¡é ¼åº¦
            if product_data.get('ebay_sold_quantity', 0) > 50:
                confidence_factors.append(0.9)  # ååˆ†ãªè²©å£²å±¥æ­´
            elif product_data.get('ebay_sold_quantity', 0) > 10:
                confidence_factors.append(0.7)
            else:
                confidence_factors.append(0.4)  # è²©å£²å±¥æ­´ä¸è¶³
            
            # å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã®è³ª
            if market_data and len(market_data.get('price_history', [])) > 30:
                confidence_factors.append(0.9)  # ååˆ†ãªä¾¡æ ¼å±¥æ­´
            elif market_data and len(market_data.get('price_history', [])) > 10:
                confidence_factors.append(0.7)
            else:
                confidence_factors.append(0.5)
            
            # æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®åˆ©ç”¨å¯èƒ½æ€§
            if self.ml_models:
                confidence_factors.append(0.8)
            else:
                confidence_factors.append(0.6)  # ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ã¿
            
            return sum(confidence_factors) / len(confidence_factors)

        except Exception as e:
            print(f"Risk confidence calculation error: {e}")
            return 0.5

    def get_default_risk_assessment(self) -> RiskAssessment:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒªã‚¹ã‚¯è©•ä¾¡"""
        return RiskAssessment(
            overall_risk_score=0.5,
            market_volatility_score=0.5,
            competition_risk=0.5,
            supply_chain_risk=0.5,
            seasonal_risk=0.3,
            counterfeit_risk=0.3,
            policy_risk=0.2,
            liquidity_risk=0.4,
            risk_factors=[],
            confidence_level=0.3,
            recommendations=["ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã«ã‚ˆã‚Šè©³ç´°ãªè©•ä¾¡ãŒã§ãã¾ã›ã‚“ã€‚è¿½åŠ æƒ…å ±ã®åé›†ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚"]
        )

    # ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤

    async def fetch_historical_data(self) -> List[Dict]:
        """éå»ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        async with self.db_pool.acquire() as conn:
            rows = await conn.fetch("""
                SELECT p.id, p.title, p.category_id, p.ebay_selling_price,
                       pc.profit_margin, pc.net_profit, pc.calculated_at,
                       ds.price as domestic_price, ds.supplier_type
                FROM products p
                JOIN profit_calculations pc ON p.id = pc.product_id
                JOIN domestic_suppliers ds ON p.id = ds.product_id
                WHERE pc.calculated_at > NOW() - INTERVAL '6 months'
                ORDER BY pc.calculated_at DESC
            """)
            
            return [dict(row) for row in rows]

    async def train_volatility_model(self, data: List[Dict]) -> RandomForestRegressor:
        """ä¾¡æ ¼å¤‰å‹•äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´"""
        try:
            df = pd.DataFrame(data)
            
            # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
            features = []
            targets = []
            
            for _, row in df.iterrows():
                # ä¾¡æ ¼å¤‰å‹•ç‡ã‚’è¨ˆç®—
                price_changes = self.calculate_price_volatility_from_history(row)
                if price_changes is not None:
                    feature_vector = [
                        row['ebay_selling_price'],
                        row.get('domestic_price', 0),
                        row.get('profit_margin', 0),
                        hash(str(row.get('category_id', 0))) % 1000,  # ã‚«ãƒ†ã‚´ãƒªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
                        len(str(row.get('title', ''))),  # ã‚¿ã‚¤ãƒˆãƒ«é•·
                    ]
                    features.append(feature_vector)
                    targets.append(price_changes)
            
            if len(features) > 10:
                # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
                model = RandomForestRegressor(n_estimators=100, random_state=42)
                model.fit(features, targets)
                return model
            
        except Exception as e:
            print(f"Volatility model training error: {e}")
        
        return None

    async def train_anomaly_model(self, data: List[Dict]) -> IsolationForest:
        """ç•°å¸¸å€¤æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´"""
        try:
            df = pd.DataFrame(data)
            
            # æ­£å¸¸ãªåˆ©ç›Šç‡ã®ç¯„å›²ã‚’å­¦ç¿’
            profit_margins = df['profit_margin'].fillna(0).values.reshape(-1, 1)
            
            if len(profit_margins) > 20:
                model = IsolationForest(contamination=0.1, random_state=42)
                model.fit(profit_margins)
                return model
            
        except Exception as e:
            print(f"Anomaly model training error: {e}")
        
        return None

    async def train_demand_model(self, data: List[Dict]) -> RandomForestRegressor:
        """éœ€è¦äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´"""
        try:
            # éœ€è¦äºˆæ¸¬ã®ãŸã‚ã®ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä½œæˆ
            df = pd.DataFrame(data)
            
            # æœˆåˆ¥å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
            df['month'] = pd.to_datetime(df['calculated_at']).dt.month
            df['dayofweek'] = pd.to_datetime(df['calculated_at']).dt.dayofweek
            
            features = []
            targets = []
            
            for _, row in df.iterrows():
                feature_vector = [
                    row['ebay_selling_price'],
                    row['month'],
                    row['dayofweek'],
                    row.get('profit_margin', 0),
                    hash(str(row.get('category_id', 0))) % 1000,
                ]
                features.append(feature_vector)
                # å£²ä¸Šé‡ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã™ã‚‹ï¼ˆåˆ©ç›Šã‹ã‚‰é€†ç®—ï¼‰
                estimated_volume = max(1, row.get('net_profit', 0) / max(1, row.get('profit_margin', 1)))
                targets.append(estimated_volume)
            
            if len(features) > 20:
                model = RandomForestRegressor(n_estimators=50, random_state=42)
                model.fit(features, targets)
                return model
            
        except Exception as e:
            print(f"Demand model training error: {e}")
        
        return None

    async def predict_price_volatility(self, product_data: Dict) -> float:
        """æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹ä¾¡æ ¼å¤‰å‹•äºˆæ¸¬"""
        try:
            model = self.ml_models.get('price_volatility')
            if not model:
                return 0.5
            
            feature_vector = [[
                product_data.get('ebay_selling_price', 0),
                0,  # domestic_price (å¾Œã§å–å¾—)
                0,  # profit_margin (å¾Œã§è¨ˆç®—)
                hash(str(product_data.get('category_id', 0))) % 1000,
                len(str(product_data.get('title', ''))),
            ]]
            
            prediction = model.predict(feature_vector)[0]
            return max(0.0, min(1.0, prediction))
            
        except Exception as e:
            print(f"Price volatility prediction error: {e}")
            return 0.5

    def calculate_price_volatility_from_history(self, row: Dict) -> Optional[float]:
        """å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ä¾¡æ ¼å¤‰å‹•ç‡ã‚’è¨ˆç®—"""
        # å®Ÿè£…ã§ã¯éå»ã®ä¾¡æ ¼å±¥æ­´ã‚’ä½¿ã£ã¦æ¨™æº–åå·®ã‚’è¨ˆç®—
        # ã“ã“ã§ã¯ç°¡ç•¥åŒ–
        profit_margin = row.get('profit_margin', 0)
        if profit_margin > 50:
            return 0.2  # é«˜åˆ©ç›Šç‡ã¯ä½å¤‰å‹•
        elif profit_margin > 20:
            return 0.5
        else:
            return 0.8  # ä½åˆ©ç›Šç‡ã¯é«˜å¤‰å‹•

    async def fetch_price_history(self, category_id: str, days: int = 90) -> List[Dict]:
        """ä¾¡æ ¼å±¥æ­´ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        async with self.db_pool.acquire() as conn:
            rows = await conn.fetch("""
                SELECT ebay_selling_price as price, created_at
                FROM products
                WHERE category_id = $1 
                AND created_at > NOW() - INTERVAL '%s days'
                ORDER BY created_at DESC
            """, category_id, days)
            
            return [{'price': row['price'], 'date': row['created_at']} for row in rows]

    async def get_category_volatility(self, category_id: str) -> float:
        """ã‚«ãƒ†ã‚´ãƒªå¹³å‡å¤‰å‹•ç‡å–å¾—"""
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå¤‰å‹•ç‡
        volatility_map = {
            '293': 0.4,    # Consumer Electronics
            '58058': 0.6,  # Cell Phones & Accessories  
            '11450': 0.3,  # Clothing, Shoes & Accessories
            '550': 0.5,    # Art
        }
        return volatility_map.get(str(category_id), 0.5)

    async def fetch_similar_products(self, title: str, category_id: str) -> List[Dict]:
        """é¡ä¼¼å•†å“æ¤œç´¢"""
        # ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ä¸»è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
        keywords = self.extract_search_keywords(title)
        
        async with self.db_pool.acquire() as conn:
            query = """
                SELECT title, ebay_selling_price, ebay_sold_quantity
                FROM products
                WHERE category_id = $1
                AND (title ILIKE ANY($2))
                AND created_at > NOW() - INTERVAL '30 days'
                LIMIT 100
            """
            
            like_patterns = [f'%{keyword}%' for keyword in keywords[:3]]
            rows = await conn.fetch(query, category_id, like_patterns)
            
            return [dict(row) for row in rows]

    def extract_search_keywords(self, title: str) -> List[str]:
        """ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º"""
        # åŸºæœ¬çš„ãªå‰å‡¦ç†
        title = re.sub(r'[^\w\s]', ' ', title.lower())
        words = title.split()
        
        # ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰é™¤å»
        stop_words = {'new', 'used', 'for', 'with', 'the', 'and', 'or', 'in', 'on', 'at'}
        keywords = [word for word in words if word not in stop_words and len(word) > 2]
        
        return keywords[:5]

    def analyze_price_competition(self, price: float, similar_products: List[Dict]) -> float:
        """ä¾¡æ ¼ç«¶åˆåˆ†æ"""
        if not similar_products:
            return 0.0
            
        competitor_prices = [p.get('ebay_selling_price', 0) for p in similar_products]
        competitor_prices = [p for p in competitor_prices if p > 0]
        
        if not competitor_prices:
            return 0.0
        
        # ä¾¡æ ¼å¸¯ã®è¿‘ã•ã‚’è©•ä¾¡
        price_range = (price * 0.8, price * 1.2)
        competitors_in_range = sum(1 for p in competitor_prices if price_range[0] <= p <= price_range[1])
        
        return competitors_in_range / len(competitor_prices)

    def analyze_seller_competition(self, similar_products: List[Dict]) -> float:
        """ã‚»ãƒ©ãƒ¼ç«¶åˆåˆ†æ"""
        if not similar_products:
            return 0.0
        
        # è²©å£²å®Ÿç¸¾ã«ã‚ˆã‚‹å¤§æ‰‹ã‚»ãƒ©ãƒ¼åˆ¤å®š
        high_volume_sellers = sum(1 for p in similar_products if p.get('ebay_sold_quantity', 0) > 100)
        
        return high_volume_sellers / len(similar_products)

    async def get_category_seasonality(self, category_id: str, current_month: int) -> float:
        """ã‚«ãƒ†ã‚´ãƒªåˆ¥å­£ç¯€æ€§ãƒªã‚¹ã‚¯"""
        seasonal_categories = {
            '888': {  # Sporting Goods
                'peak_months': [4, 5, 6, 7, 8],  # Spring/Summer
                'low_months': [11, 12, 1, 2]
            },
            '11700': {  # Home & Garden
                'peak_months': [3, 4, 5, 6],  # Spring
                'low_months': [11, 12, 1]
            }
        }
        
        category_data = seasonal_categories.get(str(category_id))
        if not category_data:
            return 0.1  # ä½å­£ç¯€æ€§
        
        if current_month in category_data['low_months']:
            return 0.7
        elif current_month in category_data['peak_months']:
            return 0.1
        else:
            return 0.4

    async def get_market_price_range(self, brand: str, category_id: str) -> Optional[float]:
        """å¸‚å ´ä¾¡æ ¼å¸¯å–å¾—"""
        async with self.db_pool.acquire() as conn:
            row = await conn.fetchrow("""
                SELECT AVG(ebay_selling_price) as avg_price
                FROM products
                WHERE LOWER(title) LIKE $1
                AND category_id = $2
                AND created_at > NOW() - INTERVAL '30 days'
            """, f'%{brand.lower()}%', category_id)
            
            return row['avg_price'] if row else None

    async def get_category_name(self, category_id: str) -> str:
        """ã‚«ãƒ†ã‚´ãƒªåå–å¾—"""
        category_names = {
            '293': 'Consumer Electronics',
            '58058': 'Cell Phones & Accessories',
            '11450': 'Clothing, Shoes & Accessories',
            '550': 'Art',
            '888': 'Sporting Goods',
            '11700': 'Home & Garden'
        }
        return category_names.get(str(category_id), 'Other')

    async def assess_international_regulation_risk(self, product_data: Dict) -> float:
        """å›½éš›è¦åˆ¶ãƒªã‚¹ã‚¯è©•ä¾¡"""
        title = product_data.get('title', '').lower()
        
        # è¼¸å‡ºå…¥è¦åˆ¶å“ç›®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        restricted_keywords = ['battery', 'lithium', 'medical', 'pharmaceutical', 
                              'electronic', 'radio', 'wireless', 'bluetooth']
        
        risk_score = 0.0
        for keyword in restricted_keywords:
            if keyword in title:
                risk_score += 0.1
        
        return min(0.5, risk_score)  # æœ€å¤§50%

    async def get_category_liquidity(self, category_id: str) -> float:
        """ã‚«ãƒ†ã‚´ãƒªæµå‹•æ€§è©•ä¾¡"""
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥æµå‹•æ€§ãƒãƒƒãƒ—
        liquidity_map = {
            '293': 0.2,    # Consumer Electronics - é«˜æµå‹•æ€§
            '58058': 0.1,  # Cell Phones - æœ€é«˜æµå‹•æ€§
            '11450': 0.3,  # Clothing - ä¸­æµå‹•æ€§
            '550': 0.6,    # Art - ä½æµå‹•æ€§
        }
        return liquidity_map.get(str(category_id), 0.4)

    async def close(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if self.session:
            await self.session.close()
        if self.db_pool:
            await self.db_pool.close()


# å¸‚å ´åˆ†æã‚µãƒ¼ãƒ“ã‚¹
class MarketAnalyzerService:
    def __init__(self):
        self.db_pool = None
        self.session = None

    async def initialize(self):
        """ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–"""
        self.db_pool = await asyncpg.create_pool(settings.DATABASE_URL)
        self.session = aiohttp.ClientSession()

    async def analyze_market_conditions(self, product_data: Dict) -> MarketAnalysis:
        """å¸‚å ´çŠ¶æ³åˆ†æ"""
        try:
            category_id = product_data.get('category_id')
            title = product_data.get('title', '')
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘åˆ†æ
            trend_direction, trend_strength = await self.analyze_price_trend(category_id)
            
            # å¸‚å ´è¦æ¨¡æ¨å®š
            market_size = await self.estimate_market_size(category_id)
            
            # æˆé•·ç‡åˆ†æ
            growth_rate = await self.calculate_growth_rate(category_id)
            
            # å­£ç¯€æ€§æŒ‡æ•°
            seasonality_index = await self.calculate_seasonality_index(category_id)
            
            # ç«¶åˆæ¿€åº¦
            competition_intensity = await self.analyze_competition_intensity(category_id)
            
            # ä¾¡æ ¼å¤‰å‹•æ€§
            price_volatility = await self.calculate_price_volatility(category_id)
            
            # éœ€è¦äºˆæ¸¬
            demand_forecast = await self.generate_demand_forecast(product_data)
            
            # ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡
            data_quality = await self.evaluate_data_quality(category_id)

            return MarketAnalysis(
                trend_direction=trend_direction,
                trend_strength=trend_strength,
                market_size_estimate=market_size,
                growth_rate=growth_rate,
                seasonality_index=seasonality_index,
                competition_intensity=competition_intensity,
                price_volatility=price_volatility,
                demand_forecast=demand_forecast,
                data_quality_score=data_quality
            )

        except Exception as e:
            print(f"Market analysis error: {e}")
            return self.get_default_market_analysis()

    async def analyze_price_trend(self, category_id: str) -> Tuple[str, float]:
        """ä¾¡æ ¼ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"""
        async with self.db_pool.acquire() as conn:
            rows = await conn.fetch("""
                SELECT ebay_selling_price, created_at
                FROM products
                WHERE category_id = $1
                AND created_at > NOW() - INTERVAL '90 days'
                ORDER BY created_at ASC
            """, category_id)
            
            if len(rows) < 10:
                return 'stable', 0.5
            
            prices = [row['ebay_selling_price'] for row in rows]
            
            # ç·šå½¢å›å¸°ã§ãƒˆãƒ¬ãƒ³ãƒ‰è¨ˆç®—
            x = np.arange(len(prices))
            slope = np.polyfit(x, prices, 1)[0]
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰æ–¹å‘ã¨å¼·ã•ã‚’æ±ºå®š
            if abs(slope) < 0.1:
                return 'stable', abs(slope) * 10
            elif slope > 0:
                return 'up', min(1.0, slope / 2)
            else:
                return 'down', min(1.0, abs(slope) / 2)

    async def estimate_market_size(self, category_id: str) -> float:
        """å¸‚å ´è¦æ¨¡æ¨å®š"""
        async with self.db_pool.acquire() as conn:
            row = await conn.fetchrow("""
                SELECT COUNT(*) as product_count,
                       AVG(ebay_selling_price) as avg_price,
                       SUM(ebay_sold_quantity) as total_sold
                FROM products
                WHERE category_id = $1
                AND created_at > NOW() - INTERVAL '30 days'
            """, category_id)
            
            if row:
                # ç°¡æ˜“å¸‚å ´è¦æ¨¡ = å¹³å‡ä¾¡æ ¼ Ã— ç·è²©å£²æ•°
                market_size = (row['avg_price'] or 0) * (row['total_sold'] or 0)
                return float(market_size)
            
            return 0.0

    async def calculate_growth_rate(self, category_id: str) -> float:
        """æˆé•·ç‡è¨ˆç®—"""
        async with self.db_pool.acquire() as conn:
            # å‰æœˆã¨ä»Šæœˆã®å£²ä¸Šæ¯”è¼ƒ
            current_month = await conn.fetchrow("""
                SELECT COUNT(*) as count, AVG(ebay_selling_price) as avg_price
                FROM products
                WHERE category_id = $1
                AND created_at > DATE_TRUNC('month', CURRENT_DATE)
            """, category_id)
            
            previous_month = await conn.fetchrow("""
                SELECT COUNT(*) as count, AVG(ebay_selling_price) as avg_price
                FROM products
                WHERE category_id = $1
                AND created_at >= DATE_TRUNC('month', CURRENT_DATE - INTERVAL '1 month')
                AND created_at < DATE_TRUNC('month', CURRENT_DATE)
            """, category_id)
            
            current_value = (current_month['count'] or 0) * (current_month['avg_price'] or 0)
            previous_value = (previous_month['count'] or 0) * (previous_month['avg_price'] or 0)
            
            if previous_value > 0:
                growth_rate = (current_value - previous_value) / previous_value
                return growth_rate
            
            return 0.0

    async def calculate_seasonality_index(self, category_id: str) -> float:
        """å­£ç¯€æ€§æŒ‡æ•°è¨ˆç®—"""
        current_month = datetime.now().month
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥å­£ç¯€æ€§ãƒ‘ã‚¿ãƒ¼ãƒ³
        seasonal_patterns = {
            '11450': {  # Clothing
                'peak_months': [9, 10, 11, 3, 4],
                'index': 0.8
            },
            '888': {  # Sporting Goods
                'peak_months': [4, 5, 6, 7, 8],
                'index': 0.7
            }
        }
        
        pattern = seasonal_patterns.get(str(category_id))
        if pattern and current_month in pattern['peak_months']:
            return pattern['index']
        elif pattern:
            return 0.3
        
        return 0.5  # ä¸­ç«‹

    async def analyze_competition_intensity(self, category_id: str) -> float:
        """ç«¶åˆæ¿€åº¦åˆ†æ"""
        async with self.db_pool.acquire() as conn:
            row = await conn.fetchrow("""
                SELECT COUNT(DISTINCT title) as unique_products,
                       COUNT(*) as total_listings,
                       AVG(ebay_sold_quantity) as avg_sold
                FROM products
                WHERE category_id = $1
                AND created_at > NOW() - INTERVAL '30 days'
            """, category_id)
            
            if row and row['total_listings'] > 0:
                # ç«¶åˆæ¿€åº¦ = ç·å‡ºå“æ•° / ãƒ¦ãƒ‹ãƒ¼ã‚¯å•†å“æ•°
                intensity = row['total_listings'] / max(1, row['unique_products'])
                return min(1.0, intensity / 5)  # æ­£è¦åŒ–
            
            return 0.5

    async def calculate_price_volatility(self, category_id: str) -> float:
        """ä¾¡æ ¼å¤‰å‹•æ€§è¨ˆç®—"""
        async with self.db_pool.acquire() as conn:
            rows = await conn.fetch("""
                SELECT ebay_selling_price
                FROM products
                WHERE category_id = $1
                AND created_at > NOW() - INTERVAL '30 days'
                AND ebay_selling_price > 0
            """, category_id)
            
            if len(rows) < 5:
                return 0.5
            
            prices = [row['ebay_selling_price'] for row in rows]
            volatility = np.std(prices) / np.mean(prices)  # å¤‰å‹•ä¿‚æ•°
            
            return min(1.0, volatility * 2)  # æ­£è¦åŒ–

    async def generate_demand_forecast(self, product_data: Dict) -> List[Dict]:
        """éœ€è¦äºˆæ¸¬ç”Ÿæˆ"""
        # ç°¡ç•¥åŒ–ã•ã‚ŒãŸéœ€è¦äºˆæ¸¬
        forecast = []
        current_date = datetime.now()
        
        for i in range(12):  # 12ãƒ¶æœˆå…ˆã¾ã§äºˆæ¸¬
            future_date = current_date + timedelta(days=30 * i)
            
            # å­£ç¯€æ€§ã‚’è€ƒæ…®ã—ãŸéœ€è¦äºˆæ¸¬
            base_demand = 100
            seasonal_factor = 1 + 0.2 * np.sin(2 * np.pi * future_date.month / 12)
            predicted_demand = base_demand * seasonal_factor
            
            forecast.append({
                'month': future_date.strftime('%Y-%m'),
                'predicted_demand': round(predicted_demand),
                'confidence': 0.7
            })
        
        return forecast

    async def evaluate_data_quality(self, category_id: str) -> float:
        """ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡"""
        async with self.db_pool.acquire() as conn:
            row = await conn.fetchrow("""
                SELECT COUNT(*) as total_count,
                       COUNT(CASE WHEN ebay_selling_price > 0 THEN 1 END) as price_count,
                       COUNT(CASE WHEN ebay_sold_quantity > 0 THEN 1 END) as sold_count
                FROM products
                WHERE category_id = $1
                AND created_at > NOW() - INTERVAL '30 days'
            """, category_id)
            
            if row and row['total_count'] > 0:
                price_quality = row['price_count'] / row['total_count']
                sold_quality = row['sold_count'] / row['total_count']
                return (price_quality + sold_quality) / 2
            
            return 0.3

    def get_default_market_analysis(self) -> MarketAnalysis:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå¸‚å ´åˆ†æ"""
        return MarketAnalysis(
            trend_direction='stable',
            trend_strength=0.5,
            market_size_estimate=0.0,
            growth_rate=0.0,
            seasonality_index=0.5,
            competition_intensity=0.5,
            price_volatility=0.5,
            demand_forecast=[],
            data_quality_score=0.3
        )

    async def close(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if self.session:
            await self.session.close()
        if self.db_pool:
            await self.db_pool.close()