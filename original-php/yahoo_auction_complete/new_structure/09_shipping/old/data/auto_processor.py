#!/usr/bin/env python3
"""
é€æ–™ãƒ‡ãƒ¼ã‚¿è‡ªå‹•å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ 
ã‚ã‚‰ã‚†ã‚‹å½¢å¼ã®é€æ–™ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç”¨SQLã«å¤‰æ›
"""

import os
import pandas as pd
import re
import json
from pathlib import Path

class ShippingDataProcessor:
    def __init__(self, data_dir="/Users/aritahiroaki/NAGANO-3/N3-Development/modules/yahoo_auction_complete/new_structure/09_shipping/data"):
        self.data_dir = Path(data_dir)
        self.processed_data = []
        
    def process_all_files(self):
        """data ãƒ•ã‚©ãƒ«ãƒ€å†…ã®å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•å‡¦ç†"""
        print("ğŸ¤– é€æ–™ãƒ‡ãƒ¼ã‚¿è‡ªå‹•å‡¦ç†é–‹å§‹...")
        
        for file_path in self.data_dir.glob("*"):
            if file_path.is_file():
                print(f"ğŸ“ å‡¦ç†ä¸­: {file_path.name}")
                self.process_single_file(file_path)
        
        self.generate_sql()
        print("âœ… å…¨ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å®Œäº†!")
    
    def process_single_file(self, file_path):
        """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†"""
        extension = file_path.suffix.lower()
        
        if extension == '.csv':
            self.process_csv(file_path)
        elif extension in ['.xlsx', '.xls']:
            self.process_excel(file_path)
        elif extension == '.pdf':
            self.process_pdf(file_path)
        elif extension in ['.txt', '.md']:
            self.process_text(file_path)
        else:
            print(f"âš ï¸ æœªå¯¾å¿œå½¢å¼: {extension}")
    
    def process_csv(self, file_path):
        """CSVè‡ªå‹•å‡¦ç†"""
        try:
            # è¤‡æ•°ã®åŒºåˆ‡ã‚Šæ–‡å­—ã§è©¦è¡Œ
            for sep in [',', '\t', ';', '|']:
                try:
                    df = pd.read_csv(file_path, sep=sep, encoding='utf-8')
                    if len(df.columns) > 1:
                        break
                except:
                    continue
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼æ­£è¦åŒ–
            df.columns = self.normalize_headers(df.columns)
            
            # æ¥­è€…åæ¨å®š
            carrier = self.detect_carrier(file_path.name)
            
            # ãƒ‡ãƒ¼ã‚¿å¤‰æ›
            for _, row in df.iterrows():
                self.extract_shipping_data(row, carrier)
                
        except Exception as e:
            print(f"âŒ CSVå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    def process_excel(self, file_path):
        """Excelè‡ªå‹•å‡¦ç†"""
        try:
            # å…¨ã‚·ãƒ¼ãƒˆèª­ã¿è¾¼ã¿
            excel_file = pd.ExcelFile(file_path)
            
            for sheet_name in excel_file.sheet_names:
                df = pd.read_excel(file_path, sheet_name=sheet_name)
                
                # æ¥­è€…åæ¨å®šï¼ˆã‚·ãƒ¼ãƒˆå or ãƒ•ã‚¡ã‚¤ãƒ«åï¼‰
                carrier = self.detect_carrier(sheet_name) or self.detect_carrier(file_path.name)
                
                # ãƒ˜ãƒƒãƒ€ãƒ¼æ­£è¦åŒ–
                df.columns = self.normalize_headers(df.columns)
                
                # ãƒ‡ãƒ¼ã‚¿å¤‰æ›
                for _, row in df.iterrows():
                    self.extract_shipping_data(row, carrier)
                    
        except Exception as e:
            print(f"âŒ Excelå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
    
    def process_pdf(self, file_path):
        """PDFè‡ªå‹•å‡¦ç†ï¼ˆAIè§£æï¼‰"""
        print(f"ğŸ” PDFè§£æä¸­: {file_path.name}")
        
        # PDFãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºï¼ˆç–‘ä¼¼å®Ÿè£…ï¼‰
        text_content = self.extract_pdf_text(file_path)
        
        # æ–™é‡‘è¡¨ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
        rate_patterns = self.detect_rate_patterns(text_content)
        
        # æ¥­è€…åæ¨å®š
        carrier = self.detect_carrier(file_path.name)
        
        # æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿å¤‰æ›
        for pattern in rate_patterns:
            self.convert_pattern_to_data(pattern, carrier)
    
    def normalize_headers(self, headers):
        """ãƒ˜ãƒƒãƒ€ãƒ¼åæ­£è¦åŒ–"""
        normalized = []
        for header in headers:
            header = str(header).lower().strip()
            
            # é‡é‡é–¢é€£
            if any(keyword in header for keyword in ['é‡é‡', 'weight', 'kg', 'gram']):
                if 'ã‹ã‚‰' in header or 'from' in header:
                    normalized.append('weight_from')
                elif 'ã¾ã§' in header or 'to' in header:
                    normalized.append('weight_to')
                else:
                    normalized.append('weight')
            
            # æ–™é‡‘é–¢é€£
            elif any(keyword in header for keyword in ['æ–™é‡‘', 'price', 'ä¾¡æ ¼', 'å††', 'yen', 'jpy']):
                normalized.append('price')
            
            # é…é€å…ˆé–¢é€£
            elif any(keyword in header for keyword in ['é…é€å…ˆ', 'destination', 'å›½', 'country', 'zone']):
                normalized.append('destination')
            
            # ã‚µãƒ¼ãƒ“ã‚¹é–¢é€£
            elif any(keyword in header for keyword in ['ã‚µãƒ¼ãƒ“ã‚¹', 'service', 'method']):
                normalized.append('service')
            
            else:
                normalized.append(header)
        
        return normalized
    
    def detect_carrier(self, text):
        """æ¥­è€…åè‡ªå‹•æ¤œå‡º"""
        text = text.lower()
        
        if any(keyword in text for keyword in ['emoji', 'ã‚¨ãƒ¢ã‚¸']):
            return 'EMOJI'
        elif any(keyword in text for keyword in ['cpass', 'ã‚·ãƒ¼ãƒ‘ã‚¹']):
            return 'CPASS'
        elif any(keyword in text for keyword in ['jppost', 'æ—¥æœ¬éƒµä¾¿', 'japan post']):
            return 'JPPOST'
        elif any(keyword in text for keyword in ['fedex']):
            return 'FEDEX'
        elif any(keyword in text for keyword in ['ups']):
            return 'UPS'
        elif any(keyword in text for keyword in ['dhl']):
            return 'DHL'
        
        return 'UNKNOWN'
    
    def extract_shipping_data(self, row, carrier):
        """è¡Œãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é€æ–™æƒ…å ±æŠ½å‡º"""
        try:
            # é‡é‡ç¯„å›²æŠ½å‡º
            weight_from, weight_to = self.parse_weight_range(row)
            
            # æ–™é‡‘æŠ½å‡º
            price = self.parse_price(row)
            
            # é…é€å…ˆã‚¾ãƒ¼ãƒ³æ±ºå®š
            zone = self.determine_zone(row)
            
            # ã‚µãƒ¼ãƒ“ã‚¹åç‰¹å®š
            service = self.detect_service(row, carrier)
            
            if all([weight_from, weight_to, price, zone, service]):
                self.processed_data.append({
                    'carrier_code': carrier,
                    'service_code': service,
                    'destination_zone': zone,
                    'weight_from_g': int(weight_from * 1000),  # kg â†’ g
                    'weight_to_g': int(weight_to * 1000),
                    'price_jpy': float(price),
                    'data_source': 'auto_processed_2025'
                })
                
        except Exception as e:
            print(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
    
    def parse_weight_range(self, row):
        """é‡é‡ç¯„å›²è§£æ"""
        # å®Ÿè£…: æ§˜ã€…ãªé‡é‡è¡¨è¨˜ã‹ã‚‰æ•°å€¤æŠ½å‡º
        # ä¾‹: "0.5kg-1.0kg", "500gä»¥ä¸‹", "1-2kg" ãªã©
        return 0.5, 1.0  # ã‚µãƒ³ãƒ—ãƒ«
    
    def parse_price(self, row):
        """æ–™é‡‘è§£æ"""
        # å®Ÿè£…: æ§˜ã€…ãªä¾¡æ ¼è¡¨è¨˜ã‹ã‚‰æ•°å€¤æŠ½å‡º
        # ä¾‹: "Â¥2,800", "2800å††", "$28.00" ãªã©
        return 2800  # ã‚µãƒ³ãƒ—ãƒ«
    
    def determine_zone(self, row):
        """é…é€å…ˆã‚¾ãƒ¼ãƒ³æ±ºå®š"""
        # å®Ÿè£…: å›½åãƒ»åœ°åŸŸåã‹ã‚‰ã‚¾ãƒ¼ãƒ³åˆ¤å®š
        return 'zone1'  # ã‚µãƒ³ãƒ—ãƒ«
    
    def detect_service(self, row, carrier):
        """ã‚µãƒ¼ãƒ“ã‚¹åç‰¹å®š"""
        # å®Ÿè£…: æ¥­è€…ãƒ»ã‚µãƒ¼ãƒ“ã‚¹åã‹ã‚‰æ¨™æº–ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
        if carrier == 'EMOJI':
            return 'FEDEX_INTL_PRIORITY'
        return 'STANDARD'  # ã‚µãƒ³ãƒ—ãƒ«
    
    def generate_sql(self):
        """SQLç”Ÿæˆ"""
        if not self.processed_data:
            print("âŒ å‡¦ç†å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        sql_file = self.data_dir / "auto_generated_shipping_data.sql"
        
        with open(sql_file, 'w', encoding='utf-8') as f:
            f.write("-- è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸé€æ–™ãƒ‡ãƒ¼ã‚¿æŠ•å…¥SQL\n")
            f.write("-- ç”Ÿæˆæ—¥æ™‚: " + pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S') + "\n\n")
            
            f.write("-- æ—¢å­˜ã®è‡ªå‹•ç”Ÿæˆãƒ‡ãƒ¼ã‚¿å‰Šé™¤\n")
            f.write("DELETE FROM real_shipping_rates WHERE data_source LIKE 'auto_processed_%';\n\n")
            
            f.write("-- æ–°ã—ã„é€æ–™ãƒ‡ãƒ¼ã‚¿æŠ•å…¥\n")
            f.write("INSERT INTO real_shipping_rates (carrier_code, service_code, destination_zone, weight_from_g, weight_to_g, price_jpy, data_source) VALUES\n")
            
            values = []
            for data in self.processed_data:
                values.append(f"('{data['carrier_code']}', '{data['service_code']}', '{data['destination_zone']}', {data['weight_from_g']}, {data['weight_to_g']}, {data['price_jpy']}, '{data['data_source']}')")
            
            f.write(',\n'.join(values) + ';\n\n')
            
            f.write(f"-- æŠ•å…¥ä»¶æ•°: {len(self.processed_data)} ä»¶\n")
            
        print(f"âœ… SQLç”Ÿæˆå®Œäº†: {sql_file}")
        print(f"ğŸ“Š å‡¦ç†ä»¶æ•°: {len(self.processed_data)} ä»¶")
        
        return sql_file

# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    processor = ShippingDataProcessor()
    processor.process_all_files()
