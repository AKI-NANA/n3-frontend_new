import openai
import json
import logging
from datetime import datetime, timedelta
from decimal import Decimal
from typing import Dict, List, Optional

from django.conf import settings
from django.utils import timezone
from apps.cards.models import PokemonCard, PriceData, MarketTrend

logger = logging.getLogger(__name__)

class AIContentGenerator:
    """AI ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.client = openai.OpenAI(api_key=settings.OPENAI_API_KEY)
        self.model = "gpt-4"
        
    def generate_blog_article(self, card_data: Dict, language: str = 'ja') -> Dict:
        """ãƒ–ãƒ­ã‚°è¨˜äº‹ã®ç”Ÿæˆ"""
        try:
            # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
            formatted_data = self._format_card_data(card_data)
            prompt = self._get_blog_prompt(formatted_data, language)
            
            # OpenAI API å‘¼ã³å‡ºã—
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self._get_system_prompt('blog', language)},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=3000,
                temperature=0.7
            )
            
            content = response.choices[0].message.content
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
            title = self._extract_title_from_content(content)
            meta_description = self._generate_meta_description(content)
            tags = self._generate_tags(card_data, language)
            
            return {
                'title': title,
                'content': content,
                'meta_description': meta_description,
                'tags': tags,
                'language': language,
                'word_count': len(content.split()),
                'generated_at': timezone.now()
            }
            
        except Exception as e:
            logger.error(f"ãƒ–ãƒ­ã‚°è¨˜äº‹ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def generate_youtube_script(self, card_data: Dict, duration_minutes: int = 10) -> Dict:
        """YouTubeå‹•ç”»ã‚¹ã‚¯ãƒªãƒ—ãƒˆç”Ÿæˆ"""
        try:
            formatted_data = self._format_card_data(card_data)
            prompt = self._get_youtube_script_prompt(formatted_data, duration_minutes)
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self._get_system_prompt('youtube_script', 'ja')},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=4000,
                temperature=0.8
            )
            
            script_content = response.choices[0].message.content
            
            # ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®æ§‹é€ åŒ–
            structured_script = self._structure_youtube_script(script_content)
            
            return {
                'script': script_content,
                'structured_script': structured_script,
                'duration_minutes': duration_minutes,
                'video_title': self._generate_video_title(card_data),
                'description': self._generate_video_description(card_data),
                'tags': self._generate_video_tags(card_data),
                'generated_at': timezone.now()
            }
            
        except Exception as e:
            logger.error(f"YouTubeã‚¹ã‚¯ãƒªãƒ—ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def generate_social_posts(self, card_data: Dict) -> Dict:
        """SNSæŠ•ç¨¿ç”Ÿæˆ"""
        try:
            formatted_data = self._format_card_data(card_data)
            
            # TwitteræŠ•ç¨¿ç”Ÿæˆ
            twitter_post = self._generate_twitter_post(formatted_data)
            
            # InstagramæŠ•ç¨¿ç”Ÿæˆ
            instagram_post = self._generate_instagram_post(formatted_data)
            
            return {
                'twitter': twitter_post,
                'instagram': instagram_post,
                'generated_at': timezone.now()
            }
            
        except Exception as e:
            logger.error(f"SNSæŠ•ç¨¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _format_card_data(self, card_data: Dict) -> str:
        """ã‚«ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã®æ•´å½¢"""
        card_name = card_data.get('card_name', '')
        current_price = card_data.get('current_price', 0)
        price_change_24h = card_data.get('price_change_24h', 0)
        price_change_7d = card_data.get('price_change_7d', 0)
        investment_grade = card_data.get('investment_grade', 'C')
        market_factors = card_data.get('market_factors', [])
        
        formatted = f"""
== ã‚«ãƒ¼ãƒ‰åŸºæœ¬æƒ…å ± ==
ã‚«ãƒ¼ãƒ‰å: {card_name}
ç¾åœ¨ä¾¡æ ¼: Â¥{current_price:,}
æŠ•è³‡ã‚°ãƒ¬ãƒ¼ãƒ‰: {investment_grade}ç´š

== ä¾¡æ ¼å‹•å‘ ==
24æ™‚é–“å¤‰å‹•: {price_change_24h:+.1f}%
7æ—¥é–“å¤‰å‹•: {price_change_7d:+.1f}%

== å¸‚å ´è¦å›  ==
{chr(10).join([f"- {factor}" for factor in market_factors])}

== åˆ†ææ—¥æ™‚ ==
{datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}
"""
        return formatted
    
    def _get_system_prompt(self, content_type: str, language: str) -> str:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ç”Ÿæˆ"""
        prompts = {
            'blog': {
                'ja': """ã‚ãªãŸã¯æ—¥æœ¬ã®ãƒã‚±ãƒ¢ãƒ³ã‚«ãƒ¼ãƒ‰æŠ•è³‡ãƒ»ç›¸å ´åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚
ä»¥ä¸‹ã®ç‰¹å¾´ã§è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š
- ãƒã‚±ã‚«æŠ•è³‡åˆå¿ƒè€…ã‹ã‚‰ä¸­ç´šè€…å‘ã‘
- ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸå®¢è¦³çš„åˆ†æ
- è¦ªã—ã¿ã‚„ã™ã„èªèª¿ã ãŒå°‚é–€æ€§ã‚‚æ„Ÿã˜ã‚‰ã‚Œã‚‹
- SEOæœ€é©åŒ–ã‚’æ„è­˜ã—ãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä½¿ç”¨
- èª­è€…ã®æŠ•è³‡åˆ¤æ–­ã«å½¹ç«‹ã¤å®Ÿç”¨çš„å†…å®¹
- 3000æ–‡å­—ç¨‹åº¦ã®è©³ç´°ãªè¨˜äº‹""",
                'en': """You are a Pokemon card investment and market analysis expert in Japan.
Create articles with these characteristics:
- For beginner to intermediate Pokemon card investors
- Objective analysis based on data
- Professional yet accessible tone
- SEO-optimized keyword usage
- Practical investment guidance
- Around 3000 words detailed article"""
            },
            'youtube_script': {
                'ja': """ã‚ãªãŸã¯YouTubeå‘ã‘ãƒã‚±ãƒ¢ãƒ³ã‚«ãƒ¼ãƒ‰è§£èª¬å‹•ç”»ã®å°æœ¬ä½œæˆå°‚é–€å®¶ã§ã™ã€‚
ä»¥ä¸‹ã®è¦ä»¶ã§å°æœ¬ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š
- è¦–è´è€…ã®é–¢å¿ƒã‚’å¼•ãå°å…¥
- æ™‚é–“è»¸ä»˜ãã®è©³ç´°æ§‹æˆ
- ç”»é¢è¡¨ç¤ºæŒ‡ç¤ºã‚‚å«ã‚ã‚‹
- ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚’é«˜ã‚ã‚‹å·¥å¤«
- è¦ªã—ã¿ã‚„ã™ã„èªèª¿
- 10åˆ†ç¨‹åº¦ã®å‹•ç”»ç”¨"""
            },
            'social': {
                'ja': """SNSæŠ•ç¨¿ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã¨ã—ã¦ã€ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã®é«˜ã„æŠ•ç¨¿ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
- Twitter: 280æ–‡å­—ä»¥å†…ã€é©åˆ‡ãªãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°
- Instagram: é­…åŠ›çš„ãªã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã€10-15å€‹ã®ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°"""
            }
        }
        
        return prompts.get(content_type, {}).get(language, prompts[content_type]['ja'])
    
    def _get_blog_prompt(self, formatted_data: str, language: str) -> str:
        """ãƒ–ãƒ­ã‚°ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
        if language == 'ja':
            return f"""
ä»¥ä¸‹ã®ãƒã‚±ãƒ¢ãƒ³ã‚«ãƒ¼ãƒ‰ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«ã€SEOæœ€é©åŒ–ã•ã‚ŒãŸãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

{formatted_data}

ã€è¨˜äº‹è¦ä»¶ã€‘
- ã‚¿ã‚¤ãƒˆãƒ«: ã‚¯ãƒªãƒƒã‚¯ã•ã‚Œã‚„ã™ã„ã‚¿ã‚¤ãƒˆãƒ«
- æ§‹æˆ: 1.å°å…¥ 2.ç¾çŠ¶åˆ†æ 3.ä¾¡æ ¼è¦å›  4.ä»Šå¾Œã®äºˆæ¸¬ 5.æŠ•è³‡ã‚¢ãƒ‰ãƒã‚¤ã‚¹ 6.ã¾ã¨ã‚
- æ–‡å­—æ•°: 3000æ–‡å­—ç¨‹åº¦
- SEOã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: ã€Œãƒã‚±ã‚« ç›¸å ´ã€ã€ŒæŠ•è³‡ã€ã€Œä¾¡æ ¼äºˆæ¸¬ã€ã‚’è‡ªç„¶ã«å«ã‚ã‚‹
- CTA: é–¢é€£è¨˜äº‹ã¸ã®èª˜å°ã‚’å«ã‚ã‚‹
- èªèª¿: å°‚é–€çš„ã ãŒè¦ªã—ã¿ã‚„ã™ã„

å®Œå…¨ãªè¨˜äº‹ã‚’ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚
"""
        else:
            return f"""
Create an SEO-optimized blog article based on the following Pokemon card price data:

{formatted_data}

Requirements:
- Title: Click-worthy title
- Structure: 1.Introduction 2.Current Analysis 3.Price Factors 4.Future Prediction 5.Investment Advice 6.Conclusion
- Length: Around 3000 words
- SEO Keywords: Include "Pokemon card investment", "market analysis", "price prediction" naturally
- CTA: Include calls-to-action for related articles

Create a complete article in markdown format.
"""
    
    def _get_youtube_script_prompt(self, formatted_data: str, duration: int) -> str:
        """YouTubeã‚¹ã‚¯ãƒªãƒ—ãƒˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        return f"""
ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«ã€{duration}åˆ†ã®YouTubeå‹•ç”»å°æœ¬ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

{formatted_data}

ã€å°æœ¬è¦ä»¶ã€‘
- ç·æ™‚é–“: {duration}åˆ†ï¼ˆç´„{duration * 60}ç§’ï¼‰
- æ§‹æˆ: å°å…¥30ç§’ã€ãƒ¡ã‚¤ãƒ³è§£èª¬{duration-2}åˆ†ã€ã¾ã¨ã‚ãƒ»CTA90ç§’
- æ™‚é–“è»¸æŒ‡ç¤º: [00:30] ã®ã‚ˆã†ãªå½¢å¼ã§æ™‚é–“ã‚’æ˜è¨˜
- ç”»é¢æŒ‡ç¤º: ã€Œç”»é¢ï¼šä¾¡æ ¼ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤ºã€ãªã©ã®æŒ‡ç¤ºã‚’å«ã‚ã‚‹
- ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ: è¦–è´è€…ã¸ã®è³ªå•ã€ã‚³ãƒ¡ãƒ³ãƒˆä¿ƒé€²
- èªèª¿: YouTubeè¦–è´è€…å‘ã‘ã®è¦ªã—ã¿ã‚„ã™ã„è©±ã—æ–¹

è©³ç´°ãªå°æœ¬ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
"""
    
    def _generate_twitter_post(self, formatted_data: str) -> Dict:
        """TwitteræŠ•ç¨¿ç”Ÿæˆ"""
        try:
            prompt = f"""
ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰TwitteræŠ•ç¨¿ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

{formatted_data}

è¦ä»¶ï¼š
- 280æ–‡å­—ä»¥å†…
- ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚’ä¿ƒã™å†…å®¹
- é©åˆ‡ãªãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°3-5å€‹
- æ•°å­—ãƒ‡ãƒ¼ã‚¿ã‚’åŠ¹æœçš„ã«ä½¿ç”¨
"""
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self._get_system_prompt('social', 'ja')},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=300,
                temperature=0.8
            )
            
            content = response.choices[0].message.content
            
            return {
                'content': content,
                'character_count': len(content),
                'platform': 'twitter'
            }
            
        except Exception as e:
            logger.error(f"TwitteræŠ•ç¨¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return {'content': '', 'character_count': 0, 'platform': 'twitter'}
    
    def _generate_instagram_post(self, formatted_data: str) -> Dict:
        """InstagramæŠ•ç¨¿ç”Ÿæˆ"""
        try:
            prompt = f"""
ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰InstagramæŠ•ç¨¿ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

{formatted_data}

è¦ä»¶ï¼š
- é­…åŠ›çš„ãªã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³
- ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°10-15å€‹
- ã‚¹ãƒˆãƒ¼ãƒªãƒ¼é¢¨ã®èªã‚Šã‹ã‘
- è¦–è¦šçš„ãªè¦ç´ ã¸ã®è¨€åŠ
"""
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self._get_system_prompt('social', 'ja')},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=500,
                temperature=0.8
            )
            
            content = response.choices[0].message.content
            
            return {
                'content': content,
                'character_count': len(content),
                'platform': 'instagram'
            }
            
        except Exception as e:
            logger.error(f"InstagramæŠ•ç¨¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return {'content': '', 'character_count': 0, 'platform': 'instagram'}
    
    def _extract_title_from_content(self, content: str) -> str:
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡º"""
        lines = content.split('\n')
        for line in lines[:5]:
            if line.strip().startswith('#'):
                return line.strip('#').strip()
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return "ãƒã‚±ãƒ¢ãƒ³ã‚«ãƒ¼ãƒ‰ç›¸å ´åˆ†æãƒ¬ãƒãƒ¼ãƒˆ"
    
    def _generate_meta_description(self, content: str) -> str:
        """ãƒ¡ã‚¿ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ç”Ÿæˆ"""
        # æœ€åˆã®æ®µè½ã‹ã‚‰160æ–‡å­—ç¨‹åº¦ã‚’æŠ½å‡º
        paragraphs = content.split('\n\n')
        for paragraph in paragraphs:
            clean_text = paragraph.replace('#', '').strip()
            if len(clean_text) > 50:
                return clean_text[:157] + "..." if len(clean_text) > 160 else clean_text
        
        return "ãƒã‚±ãƒ¢ãƒ³ã‚«ãƒ¼ãƒ‰ã®æœ€æ–°ç›¸å ´æƒ…å ±ã¨æŠ•è³‡åˆ†æã‚’ãŠå±Šã‘ã—ã¾ã™ã€‚"
    
    def _generate_tags(self, card_data: Dict, language: str) -> List[str]:
        """ã‚¿ã‚°ç”Ÿæˆ"""
        if language == 'ja':
            base_tags = ['ãƒã‚±ã‚«', 'ãƒã‚±ãƒ¢ãƒ³ã‚«ãƒ¼ãƒ‰', 'ç›¸å ´', 'æŠ•è³‡', 'ä¾¡æ ¼']
            if card_data.get('card_name'):
                base_tags.append(card_data['card_name'])
            return base_tags
        else:
            base_tags = ['pokemon', 'trading-cards', 'investment', 'market-analysis']
            return base_tags
    
    def _generate_video_title(self, card_data: Dict) -> str:
        """å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ"""
        card_name = card_data.get('card_name', 'ãƒã‚±ãƒ¢ãƒ³ã‚«ãƒ¼ãƒ‰')
        change = card_data.get('price_change_24h', 0)
        
        if change > 10:
            return f"ã€æ€¥é¨°ä¸­ã€‘{card_name} ä¾¡æ ¼åˆ†æï¼ä»Šè²·ã†ã¹ãï¼ŸæŠ•è³‡åˆ¤æ–­ã‚’è§£èª¬"
        elif change < -10:
            return f"ã€ä¾¡æ ¼æ€¥è½ã€‘{card_name} æš´è½ã®çœŸç›¸ã¨ä»Šå¾Œã®è¦‹é€šã—"
        else:
            return f"ã€ç›¸å ´åˆ†æã€‘{card_name} æœ€æ–°ä¾¡æ ¼å‹•å‘ã¨æŠ•è³‡æˆ¦ç•¥"
    
    def _generate_video_description(self, card_data: Dict) -> str:
        """å‹•ç”»èª¬æ˜æ–‡ç”Ÿæˆ"""
        card_name = card_data.get('card_name', 'ãƒã‚±ãƒ¢ãƒ³ã‚«ãƒ¼ãƒ‰')
        return f"""
{card_name}ã®æœ€æ–°ç›¸å ´åˆ†æå‹•ç”»ã§ã™ï¼

ğŸ“Š ã“ã®å‹•ç”»ã§åˆ†ã‹ã‚‹ã“ã¨
ãƒ»ç¾åœ¨ã®ä¾¡æ ¼å‹•å‘
ãƒ»ä¾¡æ ¼å¤‰å‹•ã®è¦å› åˆ†æ
ãƒ»ä»Šå¾Œã®äºˆæ¸¬ã¨æŠ•è³‡æˆ¦ç•¥
ãƒ»è²·ã„æ™‚ãƒ»å£²ã‚Šæ™‚ã®åˆ¤æ–­ãƒã‚¤ãƒ³ãƒˆ

ğŸ’° ç¾åœ¨ä¾¡æ ¼: Â¥{card_data.get('current_price', 0):,}
ğŸ“ˆ 24æ™‚é–“å¤‰å‹•: {card_data.get('price_change_24h', 0):+.1f}%

ğŸ”” ãƒãƒ£ãƒ³ãƒãƒ«ç™»éŒ²ã¨é«˜è©•ä¾¡ã‚’ãŠé¡˜ã„ã—ã¾ã™ï¼
ğŸ“± Twitter: @pokemoncard_jp
ğŸ’¬ ã‚³ãƒ¡ãƒ³ãƒˆæ¬„ã§è³ªå•ãŠå¾…ã¡ã—ã¦ã„ã¾ã™

#ãƒã‚±ã‚« #æŠ•è³‡ #ç›¸å ´åˆ†æ
"""
    
    def _generate_video_tags(self, card_data: Dict) -> List[str]:
        """å‹•ç”»ã‚¿ã‚°ç”Ÿæˆ"""
        tags = ['ãƒã‚±ã‚«', 'ãƒã‚±ãƒ¢ãƒ³ã‚«ãƒ¼ãƒ‰', 'æŠ•è³‡', 'ç›¸å ´', 'ä¾¡æ ¼åˆ†æ', 'TCG']
        if card_data.get('card_name'):
            tags.append(card_data['card_name'])
        return tags
    
    def _structure_youtube_script(self, script: str) -> List[Dict]:
        """YouTubeã‚¹ã‚¯ãƒªãƒ—ãƒˆã®æ§‹é€ åŒ–"""
        structured = []
        lines = script.split('\n')
        
        current_section = {
            'timestamp': '00:00',
            'content': '',
            'screen_notes': ''
        }
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ¤œå‡º
            if '[' in line and ']' in line and ':' in line:
                if current_section['content']:
                    structured.append(current_section.copy())
                
                timestamp = line[line.find('[')+1:line.find(']')]
                current_section = {
                    'timestamp': timestamp,
                    'content': line[line.find(']')+1:].strip(),
                    'screen_notes': ''
                }
            elif line.startswith('ç”»é¢ï¼š') or line.startswith('Screen:'):
                current_section['screen_notes'] = line
            else:
                current_section['content'] += line + ' '
        
        if current_section['content']:
            structured.append(current_section)
        
        return structured


class ContentQualityChecker:
    """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å“è³ªãƒã‚§ãƒƒã‚¯ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.client = openai.OpenAI(api_key=settings.OPENAI_API_KEY)
    
    def check_content_quality(self, content: str, content_type: str) -> Dict:
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å“è³ªã‚’ãƒã‚§ãƒƒã‚¯"""
        try:
            scores = {}
            
            # åŸºæœ¬å“è³ªãƒã‚§ãƒƒã‚¯
            scores['readability'] = self._check_readability(content)
            scores['uniqueness'] = self._check_uniqueness(content)
            scores['seo_score'] = self._check_seo_optimization(content, content_type)
            scores['ai_detection_risk'] = self._check_ai_detection_risk(content)
            
            # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—
            overall_score = sum(scores.values()) / len(scores)
            
            # æ”¹å–„ææ¡ˆç”Ÿæˆ
            suggestions = self._generate_improvement_suggestions(content, scores)
            
            return {
                'overall_score': overall_score,
                'detailed_scores': scores,
                'suggestions': suggestions,
                'quality_grade': self._get_quality_grade(overall_score),
                'checked_at': timezone.now()
            }
            
        except Exception as e:
            logger.error(f"å“è³ªãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'overall_score': 50.0,
                'detailed_scores': {},
                'suggestions': [],
                'quality_grade': 'C'
            }
    
    def _check_readability(self, content: str) -> float:
        """å¯èª­æ€§ãƒã‚§ãƒƒã‚¯"""
        # ç°¡æ˜“çš„ãªå¯èª­æ€§ã‚¹ã‚³ã‚¢
        sentences = content.count('ã€‚') + content.count('.')
        words = len(content.split())
        
        if sentences == 0:
            return 50.0
        
        avg_sentence_length = words / sentences
        
        # é©åˆ‡ãªæ–‡é•·ã¯15-25èªç¨‹åº¦
        if 15 <= avg_sentence_length <= 25:
            return 90.0
        elif 10 <= avg_sentence_length <= 30:
            return 75.0
        else:
            return 60.0
    
    def _check_uniqueness(self, content: str) -> float:
        """ç‹¬è‡ªæ€§ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã‚ˆã‚Šé«˜åº¦ãªé‡è¤‡ãƒã‚§ãƒƒã‚¯ãŒå¿…è¦
        unique_words = len(set(content.split()))
        total_words = len(content.split())
        
        if total_words == 0:
            return 50.0
        
        uniqueness_ratio = unique_words / total_words
        return min(100.0, uniqueness_ratio * 120)  # ã‚¹ã‚³ã‚¢èª¿æ•´
    
    def _check_seo_optimization(self, content: str, content_type: str) -> float:
        """SEOæœ€é©åŒ–ãƒã‚§ãƒƒã‚¯"""
        score = 0.0
        content_lower = content.lower()
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¯†åº¦ãƒã‚§ãƒƒã‚¯
        target_keywords = ['ãƒã‚±ã‚«', 'ãƒã‚±ãƒ¢ãƒ³ã‚«ãƒ¼ãƒ‰', 'ç›¸å ´', 'æŠ•è³‡', 'ä¾¡æ ¼']
        keyword_count = sum(content_lower.count(keyword) for keyword in target_keywords)
        
        total_words = len(content.split())
        if total_words > 0:
            keyword_density = keyword_count / total_words
            if 0.01 <= keyword_density <= 0.03:  # 1-3%ãŒç†æƒ³
                score += 30.0
            else:
                score += 15.0
        
        # è¦‹å‡ºã—æ§‹é€ ãƒã‚§ãƒƒã‚¯ï¼ˆmarkdownï¼‰
        if content_type == 'blog':
            h1_count = content.count('# ')
            h2_count = content.count('## ')
            
            if h1_count == 1 and h2_count >= 3:
                score += 25.0
            elif h1_count >= 1 and h2_count >= 1:
                score += 15.0
        
        # ãƒ¡ã‚¿æƒ…å ±ã®å­˜åœ¨
        if 'ã€‚' in content and len(content) > 1000:
            score += 20.0
        
        # å†…éƒ¨ãƒªãƒ³ã‚¯ã®å¯èƒ½æ€§
        if 'é–¢é€£è¨˜äº‹' in content or 'ã“ã¡ã‚‰ã‚‚' in content:
            score += 25.0
        
        return min(100.0, score)
    
    def _check_ai_detection_risk(self, content: str) -> float:
        """AIæ¤œå‡ºãƒªã‚¹ã‚¯ãƒã‚§ãƒƒã‚¯"""
        # AIç‰¹æœ‰ã®è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
        ai_phrases = [
            'ã¨ã—ã¦ã€', 'ã«ã¤ã„ã¦ã€', 'ã«é–¢ã—ã¦ã€',
            'ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™', 'ã¨è¨€ãˆã‚‹ã§ã—ã‚‡ã†',
            'é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ', 'ã¾ã¨ã‚ã‚‹ã¨'
        ]
        
        ai_phrase_count = sum(content.count(phrase) for phrase in ai_phrases)
        total_sentences = content.count('ã€‚') + 1
        
        if total_sentences == 0:
            return 50.0
        
        ai_ratio = ai_phrase_count / total_sentences
        
        # AIæ„ŸãŒä½ã„ã»ã©é«˜ã‚¹ã‚³ã‚¢
        if ai_ratio < 0.1:
            return 90.0
        elif ai_ratio < 0.2:
            return 70.0
        else:
            return 50.0
    
    def _generate_improvement_suggestions(self, content: str, scores: Dict) -> List[str]:
        """æ”¹å–„ææ¡ˆç”Ÿæˆ"""
        suggestions = []
        
        if scores.get('readability', 0) < 70:
            suggestions.append("æ–‡ç« ã®é•·ã•ã‚’èª¿æ•´ã—ã€èª­ã¿ã‚„ã™ã•ã‚’å‘ä¸Šã•ã›ã¾ã—ã‚‡ã†")
        
        if scores.get('seo_score', 0) < 70:
            suggestions.append("SEOã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ä½¿ç”¨é »åº¦ã‚’æœ€é©åŒ–ã—ã¾ã—ã‚‡ã†")
        
        if scores.get('ai_detection_risk', 0) < 70:
            suggestions.append("ã‚ˆã‚Šè‡ªç„¶ãªè¡¨ç¾ã«å¤‰æ›´ã—ã€AIæ„Ÿã‚’æ¸›ã‚‰ã—ã¾ã—ã‚‡ã†")
        
        if scores.get('uniqueness', 0) < 70:
            suggestions.append("ç‹¬è‡ªã®è¦–ç‚¹ã‚„å…·ä½“ä¾‹ã‚’è¿½åŠ ã—ã¦ç‹¬è‡ªæ€§ã‚’é«˜ã‚ã¾ã—ã‚‡ã†")
        
        return suggestions
    
    def _get_quality_grade(self, score: float) -> str:
        """å“è³ªã‚°ãƒ¬ãƒ¼ãƒ‰åˆ¤å®š"""
        if score >= 90:
            return 'A'
        elif score >= 80:
            return 'B'
        elif score >= 70:
            return 'C'
        else:
            return 'D'