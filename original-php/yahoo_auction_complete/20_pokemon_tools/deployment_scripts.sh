#!/bin/bash
# scripts/start-dev.sh - é–‹ç™ºç’°å¢ƒèµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

set -e

echo "ğŸš€ Pokemon Content System é–‹ç™ºç’°å¢ƒã‚’èµ·å‹•ã—ã¦ã„ã¾ã™..."

# ç’°å¢ƒå¤‰æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
if [ ! -f .env ]; then
    echo "âš ï¸  .envãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚.env.exampleã‹ã‚‰ã‚³ãƒ”ãƒ¼ã—ã¦ãã ã•ã„ã€‚"
    cp .env.example .env
    echo "âœ… .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸã€‚å¿…è¦ãªè¨­å®šã‚’è¡Œã£ã¦ãã ã•ã„ã€‚"
fi

# DockerãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
if ! command -v docker &> /dev/null; then
    echo "âŒ DockerãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
    exit 1
fi

if ! command -v docker-compose &> /dev/null; then
    echo "âŒ Docker ComposeãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
    exit 1
fi

# æ—¢å­˜ã®ã‚³ãƒ³ãƒ†ãƒŠã‚’åœæ­¢
echo "ğŸ›‘ æ—¢å­˜ã®ã‚³ãƒ³ãƒ†ãƒŠã‚’åœæ­¢ã—ã¦ã„ã¾ã™..."
docker-compose down

# ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ“ãƒ«ãƒ‰
echo "ğŸ”¨ Docker ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ“ãƒ«ãƒ‰ã—ã¦ã„ã¾ã™..."
docker-compose build

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®èµ·å‹•ã‚’å¾…ã¤
echo "ğŸ—„ï¸  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’èµ·å‹•ã—ã¦ã„ã¾ã™..."
docker-compose up -d db redis

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒèµ·å‹•ã™ã‚‹ã¾ã§å¾…æ©Ÿ
echo "â³ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®èµ·å‹•ã‚’å¾…ã£ã¦ã„ã¾ã™..."
sleep 10

# ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
echo "ğŸ”„ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™..."
docker-compose run --rm web python manage.py migrate

# ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ä½œæˆï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰
echo "ğŸ‘¤ ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ã„ã¾ã™..."
docker-compose run --rm web python manage.py shell -c "
from django.contrib.auth.models import User
if not User.objects.filter(username='admin').exists():
    User.objects.create_superuser('admin', 'admin@example.com', 'admin123')
    print('ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ admin ã‚’ä½œæˆã—ã¾ã—ãŸ (ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰: admin123)')
else:
    print('ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™')
"

# åˆæœŸãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
echo "ğŸ“Š åˆæœŸãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™..."
if [ -f "fixtures/pokemon_series.json" ]; then
    docker-compose run --rm web python manage.py loaddata fixtures/pokemon_series.json
fi

if [ -f "fixtures/content_templates.json" ]; then
    docker-compose run --rm web python manage.py loaddata fixtures/content_templates.json
fi

# é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†
echo "ğŸ“ é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†ã—ã¦ã„ã¾ã™..."
docker-compose run --rm web python manage.py collectstatic --noinput

# ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
echo "ğŸ“¦ ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ã„ã¾ã™..."
docker-compose run --rm frontend npm install

# å…¨ã‚µãƒ¼ãƒ“ã‚¹ã‚’èµ·å‹•
echo "ğŸš€ å…¨ã‚µãƒ¼ãƒ“ã‚¹ã‚’èµ·å‹•ã—ã¦ã„ã¾ã™..."
docker-compose up -d

# ãƒ­ã‚°ã‚’è¡¨ç¤º
echo "ğŸ“‹ ã‚µãƒ¼ãƒ“ã‚¹èµ·å‹•ãƒ­ã‚°ã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™..."
sleep 5
docker-compose logs --tail=50

echo ""
echo "âœ… é–‹ç™ºç’°å¢ƒã®èµ·å‹•ãŒå®Œäº†ã—ã¾ã—ãŸï¼"
echo ""
echo "ğŸŒ ã‚¢ã‚¯ã‚»ã‚¹æƒ…å ±:"
echo "   ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³: http://localhost:3000"
echo "   Djangoç®¡ç†ç”»é¢:       http://localhost:8000/admin"
echo "   API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:      http://localhost:8000/api/docs"
echo "   Flower (Celeryç›£è¦–):   http://localhost:5555"
echo ""
echo "ğŸ‘¤ ç®¡ç†è€…ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±:"
echo "   ãƒ¦ãƒ¼ã‚¶ãƒ¼å: admin"
echo "   ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰: admin123"
echo ""
echo "ğŸ“Š ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ­ã‚°ã®ç¢ºèª:"
echo "   docker-compose logs -f [service_name]"
echo ""
echo "ğŸ›‘ åœæ­¢ã™ã‚‹å ´åˆ:"
echo "   docker-compose down"

---

#!/bin/bash
# scripts/start-prod.sh - æœ¬ç•ªç’°å¢ƒèµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

set -e

echo "ğŸš€ Pokemon Content System æœ¬ç•ªç’°å¢ƒã‚’èµ·å‹•ã—ã¦ã„ã¾ã™..."

# å¿…è¦ãªç’°å¢ƒå¤‰æ•°ã‚’ãƒã‚§ãƒƒã‚¯
required_vars=(
    "SECRET_KEY"
    "DB_NAME"
    "DB_USER" 
    "DB_PASSWORD"
    "OPENAI_API_KEY"
    "ALLOWED_HOSTS"
)

for var in "${required_vars[@]}"; do
    if [ -z "${!var}" ]; then
        echo "âŒ å¿…è¦ãªç’°å¢ƒå¤‰æ•° $var ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
        exit 1
    fi
done

# SSLè¨¼æ˜æ›¸ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
if [ ! -f "nginx/ssl/cert.pem" ] || [ ! -f "nginx/ssl/key.pem" ]; then
    echo "âš ï¸  SSLè¨¼æ˜æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚HTTPSã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯è¨¼æ˜æ›¸ã‚’é…ç½®ã—ã¦ãã ã•ã„ã€‚"
fi

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ä½œæˆ
if [ -d "backups" ]; then
    echo "ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆã—ã¦ã„ã¾ã™..."
    timestamp=$(date +%Y%m%d_%H%M%S)
    docker-compose -f docker-compose.prod.yml exec -T db pg_dump -U ${DB_USER} ${DB_NAME} > "backups/backup_${timestamp}.sql"
fi

# æ—¢å­˜ã®ã‚³ãƒ³ãƒ†ãƒŠã‚’åœæ­¢
echo "ğŸ›‘ æ—¢å­˜ã®ã‚³ãƒ³ãƒ†ãƒŠã‚’åœæ­¢ã—ã¦ã„ã¾ã™..."
docker-compose -f docker-compose.prod.yml down

# ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ“ãƒ«ãƒ‰
echo "ğŸ”¨ æœ¬ç•ªç”¨ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ“ãƒ«ãƒ‰ã—ã¦ã„ã¾ã™..."
docker-compose -f docker-compose.prod.yml build --no-cache

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨Redisã‚’å…ˆã«èµ·å‹•
echo "ğŸ—„ï¸  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨Redisã‚’èµ·å‹•ã—ã¦ã„ã¾ã™..."
docker-compose -f docker-compose.prod.yml up -d db redis

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒèµ·å‹•ã™ã‚‹ã¾ã§å¾…æ©Ÿ
echo "â³ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®èµ·å‹•ã‚’å¾…ã£ã¦ã„ã¾ã™..."
sleep 15

# ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
echo "ğŸ”„ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™..."
docker-compose -f docker-compose.prod.yml run --rm web python manage.py migrate

# é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†
echo "ğŸ“ é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†ã—ã¦ã„ã¾ã™..."
docker-compose -f docker-compose.prod.yml run --rm web python manage.py collectstatic --noinput

# å…¨ã‚µãƒ¼ãƒ“ã‚¹ã‚’èµ·å‹•
echo "ğŸš€ å…¨ã‚µãƒ¼ãƒ“ã‚¹ã‚’èµ·å‹•ã—ã¦ã„ã¾ã™..."
docker-compose -f docker-compose.prod.yml up -d

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
echo "ğŸ¥ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™..."
sleep 30

if curl -f http://localhost/health/ > /dev/null 2>&1; then
    echo "âœ… ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯æ­£å¸¸ã«èµ·å‹•ã—ã¾ã—ãŸï¼"
else
    echo "âŒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
    docker-compose -f docker-compose.prod.yml logs web
    exit 1
fi

echo ""
echo "âœ… æœ¬ç•ªç’°å¢ƒã®èµ·å‹•ãŒå®Œäº†ã—ã¾ã—ãŸï¼"
echo ""
echo "ğŸŒ ã‚¢ã‚¯ã‚»ã‚¹æƒ…å ±:"
echo "   ãƒ¡ã‚¤ãƒ³ã‚µã‚¤ãƒˆ: http://your-domain.com"
echo "   HTTPS:       https://your-domain.com (SSLè¨¼æ˜æ›¸ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆ)"
echo "   Flower:      http://your-domain.com:5555"
echo ""
echo "ğŸ“Š ç›£è¦–ã‚³ãƒãƒ³ãƒ‰:"
echo "   docker-compose -f docker-compose.prod.yml logs -f [service_name]"
echo "   docker-compose -f docker-compose.prod.yml ps"

---

#!/bin/bash
# scripts/migrate.sh - ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

set -e

echo "ğŸ”„ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™..."

# é–‹ç™ºç’°å¢ƒã‹æœ¬ç•ªç’°å¢ƒã‹ã‚’åˆ¤å®š
if [ "${1}" == "prod" ]; then
    COMPOSE_FILE="docker-compose.prod.yml"
    echo "æœ¬ç•ªç’°å¢ƒã§ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã¾ã™"
else
    COMPOSE_FILE="docker-compose.yml"
    echo "é–‹ç™ºç’°å¢ƒã§ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã¾ã™"
fi

# ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
echo "ğŸ“ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™..."
docker-compose -f ${COMPOSE_FILE} run --rm web python manage.py makemigrations

# ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é©ç”¨
echo "âš¡ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é©ç”¨ã—ã¦ã„ã¾ã™..."
docker-compose -f ${COMPOSE_FILE} run --rm web python manage.py migrate

# ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’è¡¨ç¤º
echo "ğŸ“Š ç¾åœ¨ã®ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çŠ¶æ…‹:"
docker-compose -f ${COMPOSE_FILE} run --rm web python manage.py showmigrations

echo "âœ… ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒå®Œäº†ã—ã¾ã—ãŸï¼"

---

#!/bin/bash
# scripts/backup-db.sh - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

set -e

# è¨­å®š
BACKUP_DIR="./backups"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
KEEP_BACKUPS=7  # ä¿æŒã™ã‚‹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ•°

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
mkdir -p ${BACKUP_DIR}

echo "ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆã—ã¦ã„ã¾ã™..."

# æœ¬ç•ªç’°å¢ƒã‹é–‹ç™ºç’°å¢ƒã‹ã‚’åˆ¤å®š
if [ "${1}" == "prod" ]; then
    COMPOSE_FILE="docker-compose.prod.yml"
    DB_NAME="${DB_NAME}"
    DB_USER="${DB_USER}"
    BACKUP_FILE="${BACKUP_DIR}/prod_backup_${TIMESTAMP}.sql"
else
    COMPOSE_FILE="docker-compose.yml"
    DB_NAME="pokemon_card_db"
    DB_USER="postgres"
    BACKUP_FILE="${BACKUP_DIR}/dev_backup_${TIMESTAMP}.sql"
fi

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ãƒ€ãƒ³ãƒ—
docker-compose -f ${COMPOSE_FILE} exec -T db pg_dump -U ${DB_USER} -d ${DB_NAME} > ${BACKUP_FILE}

# åœ§ç¸®
gzip ${BACKUP_FILE}
BACKUP_FILE="${BACKUP_FILE}.gz"

echo "âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆã—ã¾ã—ãŸ: ${BACKUP_FILE}"

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’è¡¨ç¤º
echo "ğŸ“Š ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: $(du -h ${BACKUP_FILE} | cut -f1)"

# å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å‰Šé™¤
echo "ğŸ§¹ å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å‰Šé™¤ã—ã¦ã„ã¾ã™..."
cd ${BACKUP_DIR}
ls -t *.sql.gz | tail -n +$((KEEP_BACKUPS + 1)) | xargs -r rm --
echo "âœ… å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®å‰Šé™¤ãŒå®Œäº†ã—ã¾ã—ãŸ"

# åˆ©ç”¨å¯èƒ½ãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¸€è¦§ã‚’è¡¨ç¤º
echo ""
echo "ğŸ“ åˆ©ç”¨å¯èƒ½ãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—:"
ls -lh *.sql.gz | tail -n ${KEEP_BACKUPS}

---

#!/bin/bash
# scripts/restore-db.sh - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å¾©å…ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆ

set -e

# å¼•æ•°ãƒã‚§ãƒƒã‚¯
if [ $# -eq 0 ]; then
    echo "âŒ å¾©å…ƒã™ã‚‹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã—ã¦ãã ã•ã„"
    echo "ä½¿ç”¨æ³•: $0 <backup_file.sql.gz> [prod]"
    echo ""
    echo "åˆ©ç”¨å¯èƒ½ãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—:"
    ls -lh backups/*.sql.gz 2>/dev/null || echo "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
    exit 1
fi

BACKUP_FILE="$1"

# ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
if [ ! -f "${BACKUP_FILE}" ]; then
    echo "âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: ${BACKUP_FILE}"
    exit 1
fi

# æœ¬ç•ªç’°å¢ƒã‹é–‹ç™ºç’°å¢ƒã‹ã‚’åˆ¤å®š
if [ "${2}" == "prod" ]; then
    COMPOSE_FILE="docker-compose.prod.yml"
    DB_NAME="${DB_NAME}"
    DB_USER="${DB_USER}"
    echo "âš ï¸  æœ¬ç•ªç’°å¢ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å¾©å…ƒã—ã¾ã™"
else
    COMPOSE_FILE="docker-compose.yml"
    DB_NAME="pokemon_card_db"
    DB_USER="postgres"
    echo "é–‹ç™ºç’°å¢ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å¾©å…ƒã—ã¾ã™"
fi

# ç¢ºèªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
echo "å¾©å…ƒå¯¾è±¡: ${BACKUP_FILE}"
echo "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: ${DB_NAME}"
read -p "ç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/N): " -n 1 -r
echo
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
    echo "ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ"
    exit 1
fi

# ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
echo "ğŸ’¾ å¾©å…ƒå‰ã®ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã—ã¦ã„ã¾ã™..."
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
CURRENT_BACKUP="backups/before_restore_${TIMESTAMP}.sql"
docker-compose -f ${COMPOSE_FILE} exec -T db pg_dump -U ${DB_USER} -d ${DB_NAME} > ${CURRENT_BACKUP}
gzip ${CURRENT_BACKUP}
echo "âœ… ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã—ã¾ã—ãŸ: ${CURRENT_BACKUP}.gz"

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åœæ­¢
echo "ğŸ›‘ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åœæ­¢ã—ã¦ã„ã¾ã™..."
docker-compose -f ${COMPOSE_FILE} stop web worker beat

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å‰Šé™¤ãƒ»å†ä½œæˆ
echo "ğŸ—„ï¸  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å†ä½œæˆã—ã¦ã„ã¾ã™..."
docker-compose -f ${COMPOSE_FILE} exec db psql -U ${DB_USER} -c "DROP DATABASE IF EXISTS ${DB_NAME};"
docker-compose -f ${COMPOSE_FILE} exec db psql -U ${DB_USER} -c "CREATE DATABASE ${DB_NAME};"

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å¾©å…ƒ
echo "ğŸ“¥ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å¾©å…ƒã—ã¦ã„ã¾ã™..."
if [[ ${BACKUP_FILE} == *.gz ]]; then
    zcat ${BACKUP_FILE} | docker-compose -f ${COMPOSE_FILE} exec -T db psql -U ${DB_USER} -d ${DB_NAME}
else
    cat ${BACKUP_FILE} | docker-compose -f ${COMPOSE_FILE} exec -T db psql -U ${DB_USER} -d ${DB_NAME}
fi

# ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œï¼ˆå¿µã®ãŸã‚ï¼‰
echo "ğŸ”„ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™..."
docker-compose -f ${COMPOSE_FILE} run --rm web python manage.py migrate

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å†èµ·å‹•
echo "ğŸš€ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å†èµ·å‹•ã—ã¦ã„ã¾ã™..."
docker-compose -f ${COMPOSE_FILE} up -d web worker beat

echo ""
echo "âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å¾©å…ƒãŒå®Œäº†ã—ã¾ã—ãŸï¼"
echo "ğŸ“Š å¾©å…ƒå‰ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: ${CURRENT_BACKUP}.gz"

---

#!/bin/bash
# scripts/deploy.sh - æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

set -e

echo "ğŸš€ Pokemon Content System ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¦ã„ã¾ã™..."

# å¿…è¦ãªãƒ„ãƒ¼ãƒ«ã®ãƒã‚§ãƒƒã‚¯
command -v git >/dev/null 2>&1 || { echo "gitãŒå¿…è¦ã§ã™" >&2; exit 1; }
command -v docker >/dev/null 2>&1 || { echo "dockerãŒå¿…è¦ã§ã™" >&2; exit 1; }
command -v docker-compose >/dev/null 2>&1 || { echo "docker-composeãŒå¿…è¦ã§ã™" >&2; exit 1; }

# ç’°å¢ƒå¤‰æ•°ã®è¨­å®šãƒã‚§ãƒƒã‚¯
if [ -z "$DEPLOY_ENV" ]; then
    DEPLOY_ENV="production"
fi

echo "ãƒ‡ãƒ—ãƒ­ã‚¤ç’°å¢ƒ: ${DEPLOY_ENV}"

# Git ãƒªãƒã‚¸ãƒˆãƒªã®çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯
if [ -d ".git" ]; then
    echo "ğŸ“Š GitçŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ã„ã¾ã™..."
    
    # æœªã‚³ãƒŸãƒƒãƒˆã®å¤‰æ›´ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    if ! git diff-index --quiet HEAD --; then
        echo "âš ï¸  æœªã‚³ãƒŸãƒƒãƒˆã®å¤‰æ›´ãŒã‚ã‚Šã¾ã™"
        read -p "ç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/N): " -n 1 -r
        echo
        if [[ ! $REPLY =~ ^[Yy]$ ]]; then
            exit 1
        fi
    fi
    
    # ç¾åœ¨ã®ãƒ–ãƒ©ãƒ³ãƒã¨ã‚³ãƒŸãƒƒãƒˆãƒãƒƒã‚·ãƒ¥ã‚’è¨˜éŒ²
    CURRENT_BRANCH=$(git rev-parse --abbrev-ref HEAD)
    CURRENT_COMMIT=$(git rev-parse HEAD)
    echo "ç¾åœ¨ã®ãƒ–ãƒ©ãƒ³ãƒ: ${CURRENT_BRANCH}"
    echo "ç¾åœ¨ã®ã‚³ãƒŸãƒƒãƒˆ: ${CURRENT_COMMIT}"
fi

# ãƒ‡ãƒ—ãƒ­ã‚¤å‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
echo "ğŸ’¾ ãƒ‡ãƒ—ãƒ­ã‚¤å‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆã—ã¦ã„ã¾ã™..."
./scripts/backup-db.sh prod

# æ–°ã—ã„ã‚³ãƒ¼ãƒ‰ã‚’ãƒ—ãƒ«ï¼ˆGitãƒªãƒã‚¸ãƒˆãƒªã®å ´åˆï¼‰
if [ -d ".git" ]; then
    echo "ğŸ“¥ æœ€æ–°ã®ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã¦ã„ã¾ã™..."
    git pull origin ${CURRENT_BRANCH}
fi

# ç’°å¢ƒå›ºæœ‰ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
if [ ! -f ".env.production" ]; then
    echo "âŒ .env.productionãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
    exit 1
fi

# .env.productionã‚’.envã¨ã—ã¦ã‚³ãƒ”ãƒ¼
cp .env.production .env

# Docker ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ“ãƒ«ãƒ‰
echo "ğŸ”¨ æ–°ã—ã„Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ“ãƒ«ãƒ‰ã—ã¦ã„ã¾ã™..."
docker-compose -f docker-compose.prod.yml build --no-cache

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
echo "ğŸ”„ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™..."
docker-compose -f docker-compose.prod.yml run --rm web python manage.py migrate

# é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã®åé›†
echo "ğŸ“ é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†ã—ã¦ã„ã¾ã™..."
docker-compose -f docker-compose.prod.yml run --rm web python manage.py collectstatic --noinput

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã‚¼ãƒ­ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ã§å†èµ·å‹•
echo "ğŸ”„ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ãƒ­ãƒ¼ãƒªãƒ³ã‚°å†èµ·å‹•ã—ã¦ã„ã¾ã™..."

# æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒŠã‚’èµ·å‹•
docker-compose -f docker-compose.prod.yml up -d --force-recreate --no-deps web worker beat

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚’å¾…ã¤
echo "ğŸ¥ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™..."
for i in {1..30}; do
    if curl -f http://localhost/health/ > /dev/null 2>&1; then
        echo "âœ… ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯æ­£å¸¸ã«èµ·å‹•ã—ã¾ã—ãŸ"
        break
    fi
    if [ $i -eq 30 ]; then
        echo "âŒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ"
        echo "ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„:"
        docker-compose -f docker-compose.prod.yml logs --tail=50 web
        exit 1
    fi
    echo "ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ä¸­... (${i}/30)"
    sleep 2
done

# å¤ã„ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’å‰Šé™¤
echo "ğŸ§¹ å¤ã„Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’å‰Šé™¤ã—ã¦ã„ã¾ã™..."
docker image prune -f

# ãƒ‡ãƒ—ãƒ­ã‚¤æƒ…å ±ã‚’ãƒ­ã‚°ã«è¨˜éŒ²
DEPLOY_LOG="deploy.log"
echo "$(date '+%Y-%m-%d %H:%M:%S') - ãƒ‡ãƒ—ãƒ­ã‚¤å®Œäº† - ãƒ–ãƒ©ãƒ³ãƒ: ${CURRENT_BRANCH}, ã‚³ãƒŸãƒƒãƒˆ: ${CURRENT_COMMIT}" >> ${DEPLOY_LOG}

echo ""
echo "âœ… ãƒ‡ãƒ—ãƒ­ã‚¤ãŒå®Œäº†ã—ã¾ã—ãŸï¼"
echo ""
echo "ğŸŒ ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹:"
docker-compose -f docker-compose.prod.yml ps

echo ""
echo "ğŸ“Š ç›£è¦–ã‚³ãƒãƒ³ãƒ‰:"
echo "   docker-compose -f docker-compose.prod.yml logs -f"
echo "   docker-compose -f docker-compose.prod.yml top"
echo ""
echo "ğŸ”„ ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒå¿…è¦ãªå ´åˆ:"
echo "   git reset --hard <previous_commit>"
echo "   ./scripts/restore-db.sh <backup_file>"
echo "   ./scripts/deploy.sh"

---

#!/bin/bash
# scripts/health-check.sh - ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

set -e

# è‰²ä»˜ããƒ­ã‚°ç”¨ã®é–¢æ•°
red() { echo -e "\033[31m$1\033[0m"; }
green() { echo -e "\033[32m$1\033[0m"; }
yellow() { echo -e "\033[33m$1\033[0m"; }
blue() { echo -e "\033[34m$1\033[0m"; }

echo "ğŸ¥ Pokemon Content System ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚’é–‹å§‹ã—ã¾ã™..."

# ç’°å¢ƒåˆ¤å®š
if [ "${1}" == "prod" ]; then
    COMPOSE_FILE="docker-compose.prod.yml"
    BASE_URL="http://localhost"
    echo "æœ¬ç•ªç’°å¢ƒã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™"
else
    COMPOSE_FILE="docker-compose.yml"
    BASE_URL="http://localhost:8000"
    echo "é–‹ç™ºç’°å¢ƒã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™"
fi

# ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯
echo ""
blue "ğŸ” ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯ä¸­..."
if docker-compose -f ${COMPOSE_FILE} ps | grep -q "Up"; then
    green "âœ… Dockerã‚µãƒ¼ãƒ“ã‚¹ãŒç¨¼åƒä¸­"
    docker-compose -f ${COMPOSE_FILE} ps
else
    red "âŒ ä¸€éƒ¨ã¾ãŸã¯ã™ã¹ã¦ã®ã‚µãƒ¼ãƒ“ã‚¹ãŒåœæ­¢ä¸­"
    docker-compose -f ${COMPOSE_FILE} ps
fi

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒã‚§ãƒƒã‚¯
echo ""
blue "ğŸ—„ï¸  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’ãƒã‚§ãƒƒã‚¯ä¸­..."
if docker-compose -f ${COMPOSE_FILE} exec -T db psql -U postgres -d pokemon_card_db -c "SELECT 1;" > /dev/null 2>&1; then
    green "âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šæ­£å¸¸"
else
    red "âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼"
fi

# Redisæ¥ç¶šãƒã‚§ãƒƒã‚¯
echo ""
blue "ğŸ“¦ Redisæ¥ç¶šã‚’ãƒã‚§ãƒƒã‚¯ä¸­..."
if docker-compose -f ${COMPOSE_FILE} exec -T redis redis-cli ping | grep -q "PONG"; then
    green "âœ… Redisæ¥ç¶šæ­£å¸¸"
else
    red "âŒ Redisæ¥ç¶šã‚¨ãƒ©ãƒ¼"
fi

# Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
echo ""
blue "ğŸŒ Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯ä¸­..."
if curl -f -s "${BASE_URL}/health/" > /dev/null; then
    green "âœ… Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ­£å¸¸"
    
    # APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãƒã‚§ãƒƒã‚¯
    if curl -f -s "${BASE_URL}/api/v1/cards/" > /dev/null; then
        green "âœ… APIæ­£å¸¸"
    else
        yellow "âš ï¸ APIæ¥ç¶šã«å•é¡ŒãŒã‚ã‚Šã¾ã™"
    fi
else
    red "âŒ Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ¥ç¶šã‚¨ãƒ©ãƒ¼"
fi

# Celeryãƒ¯ãƒ¼ã‚«ãƒ¼ãƒã‚§ãƒƒã‚¯
echo ""
blue "âš™ï¸  Celeryãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯ä¸­..."
ACTIVE_WORKERS=$(docker-compose -f ${COMPOSE_FILE} exec -T worker celery -A config inspect active 2>/dev/null | grep -c "worker" || echo "0")
if [ "${ACTIVE_WORKERS}" -gt "0" ]; then
    green "âœ… Celeryãƒ¯ãƒ¼ã‚«ãƒ¼æ­£å¸¸ (${ACTIVE_WORKERS}å€‹ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–)"
else
    yellow "âš ï¸ Celeryãƒ¯ãƒ¼ã‚«ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
fi

# ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯
echo ""
blue "ğŸ’¾ ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡ã‚’ãƒã‚§ãƒƒã‚¯ä¸­..."
DISK_USAGE=$(df -h . | awk 'NR==2 {print $5}' | sed 's/%//')
if [ "${DISK_USAGE}" -lt "80" ]; then
    green "âœ… ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡æ­£å¸¸ (${DISK_USAGE}%)"
elif [ "${DISK_USAGE}" -lt "90" ]; then
    yellow "âš ï¸ ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡æ³¨æ„ (${DISK_USAGE}%)"
else
    red "âŒ ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡å±é™º (${DISK_USAGE}%)"
fi

# ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯
echo ""
blue "ğŸ§  ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ãƒã‚§ãƒƒã‚¯ä¸­..."
MEM_USAGE=$(free | grep Mem | awk '{printf "%.1f", $3/$2 * 100.0}')
MEM_USAGE_INT=${MEM_USAGE%.*}
if [ "${MEM_USAGE_INT}" -lt "80" ]; then
    green "âœ… ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ­£å¸¸ (${MEM_USAGE}%)"
elif [ "${MEM_USAGE_INT}" -lt "90" ]; then
    yellow "âš ï¸ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ³¨æ„ (${MEM_USAGE}%)"
else
    red "âŒ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å±é™º (${MEM_USAGE}%)"
fi

# ãƒ­ã‚°ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
echo ""
blue "ğŸ“‹ æœ€è¿‘ã®ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’ãƒã‚§ãƒƒã‚¯ä¸­..."
ERROR_COUNT=$(docker-compose -f ${COMPOSE_FILE} logs --since="1h" 2>&1 | grep -i error | wc -l)
if [ "${ERROR_COUNT}" -eq "0" ]; then
    green "âœ… éå»1æ™‚é–“ã«ã‚¨ãƒ©ãƒ¼ã¯ã‚ã‚Šã¾ã›ã‚“"
elif [ "${ERROR_COUNT}" -lt "10" ]; then
    yellow "âš ï¸ éå»1æ™‚é–“ã«${ERROR_COUNT}ä»¶ã®ã‚¨ãƒ©ãƒ¼"
else
    red "âŒ éå»1æ™‚é–“ã«${ERROR_COUNT}ä»¶ã®ã‚¨ãƒ©ãƒ¼ï¼ˆè¦èª¿æŸ»ï¼‰"
fi

echo ""
echo "ğŸ¥ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Œäº†"
echo ""

# è©³ç´°ãƒ­ã‚°ã‚ªãƒ—ã‚·ãƒ§ãƒ³
read -p "è©³ç´°ãªãƒ­ã‚°ã‚’è¡¨ç¤ºã—ã¾ã™ã‹ï¼Ÿ (y/N): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    echo ""
    blue "ğŸ“‹ æœ€æ–°ã®ãƒ­ã‚° (æœ€æ–°50è¡Œ):"
    docker-compose -f ${COMPOSE_FILE} logs --tail=50
fi

---

#!/bin/bash
# scripts/update-system.sh - ã‚·ã‚¹ãƒ†ãƒ æ›´æ–°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

set -e

echo "ğŸ”„ Pokemon Content System ã‚’æ›´æ–°ã—ã¦ã„ã¾ã™..."

# ç¾åœ¨ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’è¨˜éŒ²
if [ -f "VERSION" ]; then
    OLD_VERSION=$(cat VERSION)
    echo "ç¾åœ¨ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³: ${OLD_VERSION}"
fi

# æ›´æ–°å‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
echo "ğŸ’¾ æ›´æ–°å‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆä¸­..."
BACKUP_DIR="backups/update_$(date +%Y%m%d_%H%M%S)"
mkdir -p ${BACKUP_DIR}

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
./scripts/backup-db.sh prod
cp backups/prod_backup_*.sql.gz ${BACKUP_DIR}/

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
cp .env ${BACKUP_DIR}/.env.backup 2>/dev/null || true
cp docker-compose.prod.yml ${BACKUP_DIR}/ 2>/dev/null || true

echo "âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆå®Œäº†: ${BACKUP_DIR}"

# Gitæ›´æ–°
if [ -d ".git" ]; then
    echo "ğŸ“¥ æœ€æ–°ã®ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—ä¸­..."
    git fetch origin
    git pull origin main
fi

# ä¾å­˜é–¢ä¿‚ã®æ›´æ–°
echo "ğŸ“¦ ä¾å­˜é–¢ä¿‚ã‚’æ›´æ–°ä¸­..."
docker-compose -f docker-compose.prod.yml run --rm web pip install --upgrade -r requirements/production.txt

# ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®ä¾å­˜é–¢ä¿‚æ›´æ–°
if [ -d "frontend" ]; then
    echo "ğŸ“¦ ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ä¾å­˜é–¢ä¿‚ã‚’æ›´æ–°ä¸­..."
    cd frontend
    npm update
    npm audit fix
    cd ..
fi

# Docker ã‚¤ãƒ¡ãƒ¼ã‚¸å†ãƒ“ãƒ«ãƒ‰
echo "ğŸ”¨ Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’å†ãƒ“ãƒ«ãƒ‰ä¸­..."
docker-compose -f docker-compose.prod.yml build --no-cache

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
echo "ğŸ”„ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œä¸­..."
docker-compose -f docker-compose.prod.yml run --rm web python manage.py migrate

# é™çš„ãƒ•ã‚¡ã‚¤ãƒ«å†åé›†
echo "ğŸ“ é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†åé›†ä¸­..."
docker-compose -f docker-compose.prod.yml run --rm web python manage.py collectstatic --noinput

# ã‚µãƒ¼ãƒ“ã‚¹å†èµ·å‹•
echo "ğŸ”„ ã‚µãƒ¼ãƒ“ã‚¹ã‚’å†èµ·å‹•ä¸­..."
docker-compose -f docker-compose.prod.yml restart

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
echo "ğŸ¥ æ›´æ–°å¾Œãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œä¸­..."
sleep 10
./scripts/health-check.sh prod

# ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±æ›´æ–°
if [ -f "VERSION" ]; then
    NEW_VERSION=$(cat VERSION)
    echo "æ›´æ–°å®Œäº†: ${OLD_VERSION} â†’ ${NEW_VERSION}"
else
    echo "æ›´æ–°å®Œäº†"
fi

echo ""
echo "âœ… ã‚·ã‚¹ãƒ†ãƒ æ›´æ–°ãŒå®Œäº†ã—ã¾ã—ãŸï¼"
echo "ğŸ“Š ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¿å­˜å ´æ‰€: ${BACKUP_DIR}"

---

#!/bin/bash
# scripts/monitoring-setup.sh - ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

set -e

echo "ğŸ“Š ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã¦ã„ã¾ã™..."

# Prometheusãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
mkdir -p monitoring/{prometheus,grafana,alertmanager}

# Prometheusè¨­å®š
cat > monitoring/prometheus/prometheus.yml << 'EOF'
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  - job_name: 'pokemon-content-system'
    static_configs:
      - targets: ['web:8000']
    metrics_path: '/metrics'
    scrape_interval: 30s

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']

  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']

  - job_name: 'nginx'
    static_configs:
      - targets: ['nginx-exporter:9113']
EOF

# ã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«
cat > monitoring/prometheus/alert_rules.yml << 'EOF'
groups:
  - name: pokemon_content_system
    rules:
      - alert: HighCPUUsage
        expr: rate(process_cpu_seconds_total[5m]) * 100 > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "é«˜CPUä½¿ç”¨ç‡æ¤œå‡º"
          description: "CPUä½¿ç”¨ç‡ãŒ5åˆ†é–“80%ã‚’è¶…ãˆã¦ã„ã¾ã™"

      - alert: HighMemoryUsage
        expr: process_resident_memory_bytes / (1024 * 1024 * 1024) > 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "é«˜ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¤œå‡º"
          description: "ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒ2GBã‚’è¶…ãˆã¦ã„ã¾ã™"

      - alert: DatabaseConnectionError
        expr: up{job="postgres"} == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼"
          description: "PostgreSQLã«æ¥ç¶šã§ãã¾ã›ã‚“"

      - alert: RedisConnectionError
        expr: up{job="redis"} == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Redisæ¥ç¶šã‚¨ãƒ©ãƒ¼"
          description: "Redisã«æ¥ç¶šã§ãã¾ã›ã‚“"

      - alert: HighErrorRate
        expr: rate(django_http_responses_total_by_status_total{status=~"5.."}[5m]) > 0.1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "é«˜ã‚¨ãƒ©ãƒ¼ç‡æ¤œå‡º"
          description: "5xxã‚¨ãƒ©ãƒ¼ãŒ5åˆ†é–“ã§10%ã‚’è¶…ãˆã¦ã„ã¾ã™"
EOF

# Alertmanagerè¨­å®š
cat > monitoring/alertmanager/alertmanager.yml << 'EOF'
global:
  smtp_smarthost: 'localhost:587'
  smtp_from: 'alerts@pokemon-content-system.com'

route:
  group_by: ['alertname']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'

receivers:
  - name: 'web.hook'
    email_configs:
      - to: 'admin@pokemon-content-system.com'
        subject: '[ALERT] {{ .GroupLabels.alertname }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          {{ end }}

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'dev', 'instance']
EOF

# Grafanaãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¨­å®š
cat > monitoring/grafana/dashboard.json << 'EOF'
{
  "dashboard": {
    "title": "Pokemon Content System Dashboard",
    "panels": [
      {
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(django_http_requests_total[5m])",
            "legendFormat": "{{method}} {{handler}}"
          }
        ]
      },
      {
        "title": "Response Time",
        "type": "graph", 
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(django_http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          }
        ]
      },
      {
        "title": "Error Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(django_http_responses_total_by_status_total{status=~\"5..\"}[5m])",
            "legendFormat": "5xx errors"
          }
        ]
      }
    ]
  }
}
EOF

# ç›£è¦–ç”¨docker-composeè¿½åŠ 
cat > monitoring/docker-compose.monitoring.yml << 'EOF'
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    networks:
      - monitoring

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana:/etc/grafana/provisioning
    networks:
      - monitoring

  alertmanager:
    image: prom/alertmanager:latest
    ports:
      - "9093:9093"
    volumes:
      - ./alertmanager:/etc/alertmanager
    networks:
      - monitoring

  postgres-exporter:
    image: prometheuscommunity/postgres-exporter
    environment:
      - DATA_SOURCE_NAME=postgresql://postgres:password@db:5432/pokemon_card_db?sslmode=disable
    networks:
      - monitoring
      - pokemon_network

  redis-exporter:
    image: oliver006/redis_exporter
    environment:
      - REDIS_ADDR=redis://redis:6379
    networks:
      - monitoring
      - pokemon_network

  nginx-exporter:
    image: nginx/nginx-prometheus-exporter
    command:
      - -nginx.scrape-uri=http://nginx:80/nginx_status
    networks:
      - monitoring
      - pokemon_network

volumes:
  prometheus_data:
  grafana_data:

networks:
  monitoring:
    driver: bridge
  pokemon_network:
    external: true
EOF

echo "âœ… ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãŒå®Œäº†ã—ã¾ã—ãŸï¼"
echo ""
echo "ğŸš€ ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã‚’èµ·å‹•ã™ã‚‹ã«ã¯:"
echo "   cd monitoring"
echo "   docker-compose -f docker-compose.monitoring.yml up -d"
echo ""
echo "ğŸŒ ã‚¢ã‚¯ã‚»ã‚¹æƒ…å ±:"
echo "   Prometheus: http://localhost:9090"
echo "   Grafana:    http://localhost:3001 (admin/admin)"
echo "   Alertmanager: http://localhost:9093"

---

#!/bin/bash
# scripts/performance-test.sh - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

set -e

echo "ğŸš€ Pokemon Content System ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹ã—ã¾ã™..."

# ãƒ†ã‚¹ãƒˆè¨­å®š
BASE_URL="http://localhost:8000"
CONCURRENT_USERS=10
TEST_DURATION=60
RESULTS_DIR="performance_results/$(date +%Y%m%d_%H%M%S)"

mkdir -p ${RESULTS_DIR}

# å¿…è¦ãªãƒ„ãƒ¼ãƒ«ã®ãƒã‚§ãƒƒã‚¯
if ! command -v ab &> /dev/null; then
    echo "Apache Bench (ab) ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ã„ã¾ã™..."
    if command -v apt-get &> /dev/null; then
        sudo apt-get update && sudo apt-get install -y apache2-utils
    elif command -v brew &> /dev/null; then
        brew install apache-bench
    else
        echo "âŒ Apache Bench (ab) ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã«å¤±æ•—ã—ã¾ã—ãŸ"
        exit 1
    fi
fi

# ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’è¨˜éŒ²
echo "ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’è¨˜éŒ²ä¸­..."
cat > ${RESULTS_DIR}/system_info.txt << EOF
ãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ™‚åˆ»: $(date)
ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±: $(uname -a)
CPUæƒ…å ±: $(nproc) cores
ãƒ¡ãƒ¢ãƒªæƒ…å ±: $(free -h | grep Mem)
DockerçŠ¶æ…‹:
$(docker-compose ps)
EOF

echo "ğŸ¥ ãƒ†ã‚¹ãƒˆå‰ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯..."
./scripts/health-check.sh

# APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
echo ""
echo "ğŸ” APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãƒ†ã‚¹ãƒˆé–‹å§‹..."

# 1. ã‚«ãƒ¼ãƒ‰ä¸€è¦§API
echo "ãƒ†ã‚¹ãƒˆä¸­: ã‚«ãƒ¼ãƒ‰ä¸€è¦§API..."
ab -n 1000 -c ${CONCURRENT_USERS} -g ${RESULTS_DIR}/cards_list.tsv \
   "${BASE_URL}/api/v1/cards/" > ${RESULTS_DIR}/cards_list.txt 2>&1

# 2. äººæ°—ã‚«ãƒ¼ãƒ‰API  
echo "ãƒ†ã‚¹ãƒˆä¸­: äººæ°—ã‚«ãƒ¼ãƒ‰API..."
ab -n 500 -c ${CONCURRENT_USERS} -g ${RESULTS_DIR}/popular_cards.tsv \
   "${BASE_URL}/api/v1/cards/popular_cards/" > ${RESULTS_DIR}/popular_cards.txt 2>&1

# 3. ã‚«ãƒ¼ãƒ‰è©³ç´°API
echo "ãƒ†ã‚¹ãƒˆä¸­: ã‚«ãƒ¼ãƒ‰è©³ç´°API..."
# ã¾ãšã€ãƒ†ã‚¹ãƒˆç”¨ã®ã‚«ãƒ¼ãƒ‰IDã‚’å–å¾—
CARD_ID=$(curl -s "${BASE_URL}/api/v1/cards/" | python3 -c "
import sys, json
data = json.load(sys.stdin)
if data['results']:
    print(data['results'][0]['id'])
else:
    print('test-id')
")

if [ "${CARD_ID}" != "test-id" ]; then
    ab -n 300 -c ${CONCURRENT_USERS} -g ${RESULTS_DIR}/card_detail.tsv \
       "${BASE_URL}/api/v1/cards/${CARD_ID}/" > ${RESULTS_DIR}/card_detail.txt 2>&1
fi

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
echo ""
echo "ğŸ—„ï¸  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ..."
docker-compose exec -T db psql -U postgres -d pokemon_card_db -c "
EXPLAIN ANALYZE SELECT * FROM pokemon_cards 
WHERE is_popular = true 
ORDER BY popularity_score DESC 
LIMIT 20;
" > ${RESULTS_DIR}/db_popular_cards.txt

docker-compose exec -T db psql -U postgres -d pokemon_card_db -c "
EXPLAIN ANALYZE SELECT 
    c.name, c.card_number, s.name as series_name,
    AVG(p.price) as avg_price
FROM pokemon_cards c
LEFT JOIN pokemon_series s ON c.series_id = s.id
LEFT JOIN price_data p ON c.id = p.card_id
WHERE p.collected_at > NOW() - INTERVAL '30 days'
GROUP BY c.id, c.name, c.card_number, s.name
ORDER BY avg_price DESC
LIMIT 10;
" > ${RESULTS_DIR}/db_price_analysis.txt

# ãƒ¡ãƒ¢ãƒªãƒ»CPUä½¿ç”¨é‡ã®ç›£è¦–
echo ""
echo "ğŸ’» ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ã‚’ç›£è¦–ä¸­..."
{
    echo "æ™‚åˆ»,CPUä½¿ç”¨ç‡,ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡"
    for i in {1..60}; do
        CPU=$(docker stats --no-stream --format "{{.CPUPerc}}" pokemon_content_system_web_1 | sed 's/%//')
        MEM=$(docker stats --no-stream --format "{{.MemPerc}}" pokemon_content_system_web_1 | sed 's/%//')
        echo "$(date '+%H:%M:%S'),${CPU},${MEM}"
        sleep 1
    done
} > ${RESULTS_DIR}/resource_usage.csv &

MONITOR_PID=$!

# åŒæ™‚æ¥ç¶šæ•°ãƒ†ã‚¹ãƒˆ
echo ""
echo "ğŸ“ˆ åŒæ™‚æ¥ç¶šæ•°ãƒ†ã‚¹ãƒˆ..."
for users in 5 10 20 50; do
    echo "åŒæ™‚æ¥ç¶šæ•°: ${users}..."
    ab -n 100 -c ${users} "${BASE_URL}/api/v1/cards/" \
       > ${RESULTS_DIR}/concurrent_${users}.txt 2>&1
    sleep 5
done

# ç›£è¦–ãƒ—ãƒ­ã‚»ã‚¹åœæ­¢
kill ${MONITOR_PID} 2>/dev/null || true

# çµæœã®åˆ†æã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
echo ""
echo "ğŸ“Š çµæœã‚’åˆ†æä¸­..."
cat > ${RESULTS_DIR}/summary.md << EOF
# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆçµæœ

## ãƒ†ã‚¹ãƒˆç’°å¢ƒ
- å®Ÿè¡Œæ—¥æ™‚: $(date)
- åŒæ™‚æ¥ç¶šæ•°: ${CONCURRENT_USERS}
- ã‚·ã‚¹ãƒ†ãƒ : $(uname -a)

## API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãƒ†ã‚¹ãƒˆçµæœ

### ã‚«ãƒ¼ãƒ‰ä¸€è¦§API
\`\`\`
$(grep -A 10 "Requests per second" ${RESULTS_DIR}/cards_list.txt)
\`\`\`

### äººæ°—ã‚«ãƒ¼ãƒ‰API  
\`\`\`
$(grep -A 10 "Requests per second" ${RESULTS_DIR}/popular_cards.txt)
\`\`\`

## æ¨å¥¨æ”¹å–„ç‚¹
1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æœ€é©åŒ–
2. Redis ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æ´»ç”¨
3. CDN ã®å°å…¥æ¤œè¨
4. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ—ãƒ¼ãƒ«ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

## è©³ç´°çµæœãƒ•ã‚¡ã‚¤ãƒ«
- cards_list.txt: ã‚«ãƒ¼ãƒ‰ä¸€è¦§APIã®è©³ç´°çµæœ
- popular_cards.txt: äººæ°—ã‚«ãƒ¼ãƒ‰APIã®è©³ç´°çµæœ
- resource_usage.csv: ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡å±¥æ­´
- db_*.txt: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªåˆ†æ
EOF

echo ""
echo "âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Œäº†ï¼"
echo ""
echo "ğŸ“ çµæœä¿å­˜å ´æ‰€: ${RESULTS_DIR}/"
echo "ğŸ“Š ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ: ${RESULTS_DIR}/summary.md"
echo ""
echo "ğŸ” ä¸»è¦ãªçµæœ:"
echo "ã‚«ãƒ¼ãƒ‰ä¸€è¦§API RPS: $(grep "Requests per second" ${RESULTS_DIR}/cards_list.txt | awk '{print $4}')"
echo "äººæ°—ã‚«ãƒ¼ãƒ‰API RPS: $(grep "Requests per second" ${RESULTS_DIR}/popular_cards.txt | awk '{print $4}')"

---

# Makefile - é–‹ç™ºãƒ»é‹ç”¨ã‚³ãƒãƒ³ãƒ‰ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆ
.PHONY: help dev prod stop clean test deploy backup restore health update monitor performance

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
help:
	@echo "Pokemon Content System - åˆ©ç”¨å¯èƒ½ãªã‚³ãƒãƒ³ãƒ‰:"
	@echo ""
	@echo "é–‹ç™ºç’°å¢ƒ:"
	@echo "  make dev         - é–‹ç™ºç’°å¢ƒã‚’èµ·å‹•"
	@echo "  make dev-logs    - é–‹ç™ºç’°å¢ƒãƒ­ã‚°ã‚’è¡¨ç¤º"
	@echo "  make dev-shell   - é–‹ç™ºç’°å¢ƒã§Djangoã‚·ã‚§ãƒ«ã‚’èµ·å‹•"
	@echo ""
	@echo "æœ¬ç•ªç’°å¢ƒ:"
	@echo "  make prod        - æœ¬ç•ªç’°å¢ƒã‚’èµ·å‹•"  
	@echo "  make prod-logs   - æœ¬ç•ªç’°å¢ƒãƒ­ã‚°ã‚’è¡¨ç¤º"
	@echo "  make deploy      - æœ¬ç•ªç’°å¢ƒã«ãƒ‡ãƒ—ãƒ­ã‚¤"
	@echo ""
	@echo "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹:"
	@echo "  make migrate     - ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"
	@echo "  make backup      - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"
	@echo "  make restore     - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å¾©å…ƒ"
	@echo ""
	@echo "ä¿å®ˆãƒ»ç›£è¦–:"
	@echo "  make health      - ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"
	@echo "  make update      - ã‚·ã‚¹ãƒ†ãƒ æ›´æ–°"
	@echo "  make monitor     - ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•"
	@echo "  make performance - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"
	@echo ""
	@echo "ãã®ä»–:"
	@echo "  make stop        - å…¨ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢"
	@echo "  make clean       - ä¸è¦ãªãƒªã‚½ãƒ¼ã‚¹å‰Šé™¤"
	@echo "  make test        - ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"

# é–‹ç™ºç’°å¢ƒ
dev:
	@./scripts/start-dev.sh

dev-logs:
	@docker-compose logs -f

dev-shell:
	@docker-compose exec web python manage.py shell

# æœ¬ç•ªç’°å¢ƒ
prod:
	@./scripts/start-prod.sh

prod-logs:
	@docker-compose -f docker-compose.prod.yml logs -f

deploy:
	@./scripts/deploy.sh

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
migrate:
	@./scripts/migrate.sh

migrate-prod:
	@./scripts/migrate.sh prod

backup:
	@./scripts/backup-db.sh

backup-prod:
	@./scripts/backup-db.sh prod

restore:
	@echo "ä½¿ç”¨æ³•: make restore BACKUP_FILE=path/to/backup.sql.gz"
	@if [ -z "$(BACKUP_FILE)" ]; then echo "BACKUP_FILE ã‚’æŒ‡å®šã—ã¦ãã ã•ã„"; exit 1; fi
	@./scripts/restore-db.sh $(BACKUP_FILE)

# ä¿å®ˆãƒ»ç›£è¦–
health:
	@./scripts/health-check.sh

health-prod:
	@./scripts/health-check.sh prod

update:
	@./scripts/update-system.sh

monitor:
	@./scripts/monitoring-setup.sh
	@cd monitoring && docker-compose -f docker-compose.monitoring.yml up -d

performance:
	@./scripts/performance-test.sh

# ãã®ä»–
stop:
	@docker-compose down
	@docker-compose -f docker-compose.prod.yml down 2>/dev/null || true
	@cd monitoring && docker-compose -f docker-compose.monitoring.yml down 2>/dev/null || true

clean:
	@echo "ä¸è¦ãªDockerãƒªã‚½ãƒ¼ã‚¹ã‚’å‰Šé™¤ä¸­..."
	@docker system prune -f
	@docker volume prune -f
	@docker image prune -f

test:
	@echo "ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œä¸­..."
	@docker-compose exec web python manage.py test
	@cd frontend && npm test

# ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰
frontend-install:
	@cd frontend && npm install

frontend-build:
	@cd frontend && npm run build

frontend-dev:
	@cd frontend && npm start